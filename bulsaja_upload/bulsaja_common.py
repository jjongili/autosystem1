# -*- coding: utf-8 -*-
"""
ë¶ˆì‚¬ì ê³µí†µ ëª¨ë“ˆ (bulsaja_common.py)

ëª¨ë“  ë¶ˆì‚¬ì ê´€ë ¨ í”„ë¡œê·¸ë¨ì—ì„œ ê³µìœ í•˜ëŠ”:
- í‚¤ì›Œë“œ (ê¸ˆì§€/ì˜ˆì™¸/ì œê±°/ë¯¸ë¼ì˜µì…˜)
- API í´ë¼ì´ì–¸íŠ¸
- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜

ì‚¬ìš©:
    from bulsaja_common import *

by í”„ì½”ë…¸ë¯¸
"""

import os
import json
import requests
import websocket
from typing import List, Dict, Tuple, Optional, Set
from urllib.parse import urlparse

# ==================== íŒŒì¼ ê²½ë¡œ ====================
BANNED_WORDS_FILE = "banned_words.json"      # ê¸ˆì§€ë‹¨ì–´ (ë¸Œëœë“œ/ìœ„í—˜ìƒí’ˆ)
EXCLUDED_WORDS_FILE = "excluded_words.json"  # ì˜ˆì™¸ë‹¨ì–´ (íƒì§€ ì œì™¸)
REMOVE_WORDS_FILE = "remove_words.json"      # ì œê±°ë‹¨ì–´ (ìƒí’ˆëª…ì—ì„œ ì‚­ì œ)
BAIT_KEYWORDS_FILE = "bait_keywords.json"    # ë¯¸ë¼ì˜µì…˜ í‚¤ì›Œë“œ

# ==================== ìƒí’ˆëª… ê´€ë ¨ í‚¤ì›Œë“œ (title_maker) ====================

# ì„±ì¸/ì„±ê´€ë ¨ ë‹¨ì–´
ADULT_KEYWORDS = {
    "ì„±ì¸ìš©í’ˆ", "ì„¹ì‹œì†ì˜·", "ì„¹ì‹œë€ì œë¦¬", "ë€ì œë¦¬", "ê°€í„°ë²¨íŠ¸",
    "ì½”ë¥´ì…‹", "ë‚˜ì´íŠ¸ì›¨ì–´", "ë² ì´ë¹„ëŒ",
    "ì‹œìŠ¤ë£¨", "ì•¼í•œ", "ì—ë¡œí‹±", "19ê¸ˆ",
    "ì½˜ë”", "ëŸ¬ë¸Œì ¤", "ë°”ì´ë¸Œë ˆì´í„°", "ë”œë„", "ì˜¤ë‚˜í™€", "ë¦¬ì–¼ëŒ",
    "ë³¸ë””ì§€", "í˜í‹°ì‰¬", "ì½”ìŠ¤í”„ë ˆì˜ìƒ",
    "ëˆíŒ¬í‹°", "í‹°íŒ¬í‹°", "ëˆ„ë“œ",
    # 'SM', 'í…Œë””', 'ìºë¯¸ì†”', 'ë…¸ì¶œ', 'ì±„ì°', 'ë©”ì´ë“œë³µ' ì œê±° - ì˜¤íƒ ê°€ëŠ¥
}

# ì˜ë£Œê¸°ê¸°/ì˜ë£Œ ê´€ë ¨ ë‹¨ì–´
MEDICAL_KEYWORDS = {
    "ì˜ë£Œê¸°ê¸°", "ì˜ë£Œìš©", "ì˜ì•½í’ˆ", "ì²˜ë°©ì „", "í˜ˆì••ê³„", "í˜ˆë‹¹ê³„",
    "ì²´ì˜¨ê³„", "ì‚°ì†Œí¬í™”ë„", "ì‹¬ì „ë„", "ì—‘ìŠ¤ë ˆì´",
    "ì£¼ì‚¬ê¸°", "ì£¼ì‚¬ë°”ëŠ˜", "ìˆ˜ì•¡ì„¸íŠ¸", "ë§ê±°", "ì¹´í…Œí„°", "ìŠ¤í…íŠ¸",
    "ë³´ì²­ê¸°", "ì½˜íƒíŠ¸ë Œì¦ˆ", "ì‹œë ¥êµì •",
    "íœ ì²´ì–´", "ëª©ë°œ", "ì˜ì¡±", "ì˜ìˆ˜", "ê¹ìŠ¤",
    "ì§„í†µì œ", "í•´ì—´ì œ", "í•­ìƒì œ",
    "ìŠ¤í…Œë¡œì´ë“œ", "í˜¸ë¥´ëª¬ì œ", "í”¼ì„ì•½", "ë°œê¸°ë¶€ì „ì•½", "íƒˆëª¨ì•½", "ë‹¤ì´ì–´íŠ¸ì•½",
    "ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ", "ì˜ì–‘ì œ", "í”„ë¡œí´ë¦¬ìŠ¤", "ì˜¤ë©”ê°€3",
    "ìœ ì‚°ê· ", "í”„ë¡œë°”ì´ì˜¤í‹±ìŠ¤", "ê¸€ë£¨ì½”ì‚¬ë¯¼",
    "LEDë§ˆìŠ¤í¬", "í”¼ë¶€ê´€ë¦¬ê¸°",
    # ë ˆì´ì €/IPL ë¯¸ìš©ê¸°ê¸° (ì˜ë£Œê¸°ê¸°ë²• ìœ„ë°˜)
    "ë ˆì´ì €ì œëª¨ê¸°", "IPLì œëª¨ê¸°", "ì œëª¨ê¸°", "ë¬¸ì‹ ì œê±°ê¸°", "íƒ€íˆ¬ì œê±°ê¸°",
    # 'MRI', 'CT', 'IPL', 'ì•½í’ˆ', 'ë§¥ë°•', 'ì„í”Œë€íŠ¸', 'ì¹˜ê³¼', 'êµì •ê¸°', 'í‹€ë‹ˆ', 'ì˜ì¹˜',
    # 'ì†Œë…ì œ', 'ì‚´ê· ì œ', 'ë©¸ê· ', 'ìˆ˜ìˆ ', 'ë§ˆì·¨', 'ë¹„íƒ€ë¯¼', 'í™ì‚¼', 'ì½œë¼ê²', 'íˆì•Œë£¨ë¡ ì‚°' ì œê±°
    # - ì¼ë°˜ ì œí’ˆëª…ì—ì„œ ì˜¤íƒ ê°€ëŠ¥
}

# ìœ ì•„/ì•„ë™ ê´€ë ¨ (êµ¬ë§¤ëŒ€í–‰ ê¸ˆì§€)
# â€» ì•ˆì „ ì»¨í…ìŠ¤íŠ¸(ì±…ìƒ, ì˜ì, ë¬¸êµ¬ ë“±)ê°€ ìˆìœ¼ë©´ ë¬´ì‹œë¨
CHILD_KEYWORDS = {
    "ìœ ì•„ìš©í’ˆ", "ìœ ì•„ìš©", "ì‹ ìƒì•„ìš©", "ì˜ì•„ìš©",
    "ì –ë³‘", "ë¶„ìœ ", "ì´ìœ ì‹", "ê¸°ì €ê·€",
    "ì•„ê¸°ë ", "ì¹´ì‹œíŠ¸", "ë°”ìš´ì„œ", "ë³´í–‰ê¸°", "ì í¼ë£¨",
    "ìœ ì•„ë³µ", "ì•„ê¸°ì˜·", "ë°°ëƒ‡ì €ê³ ë¦¬",
    "ìˆ˜ìœ ì¿ ì…˜", "ìˆ˜ìœ ë¸Œë¼", "ìœ ì¶•ê¸°",
    "ì¹˜ë°œê¸°", "ê³µê°ˆì –ê¼­ì§€", "ë”¸ë‘ì´",
    # 'ìœ ì•„', 'ì•„ê¸°', 'ë² ì´ë¹„', 'baby', 'infant' ì œê±° - ë² ì´ë¹„íŒŒìš°ë”, ì•„ê¸°í”¼ë¶€ ë“± ì˜¤íƒ
    # 'ë¬¼í‹°ìŠˆ', 'ìºë¦¬ì–´', 'í„±ë°›ì´', 'ì†ì‹¸ê°œ', 'ë°œì‹¸ê°œ' ì œê±° - ì¼ë°˜ ì œí’ˆì—ì„œ ì˜¤íƒ
    # 'ì¥ë‚œê°', 'í† ì´', 'ì¸í˜•', 'ë ˆê³ ' ì œê±° - ì„±ì¸ìš© í”¼ê·œì–´, ì¸í˜• ë“± ì˜¤íƒ
    # 'ìˆ˜ìœ ', 'ëª¨ìœ ', 'ì –ê¼­ì§€', 'ë…¸ë¦¬ê°œ', 'ëª¨ë¹Œ' ì œê±° - ì˜¤íƒ ê°€ëŠ¥
    # 'ì•„ë™ë³µ', 'í‚¤ì¦ˆ', 'ì£¼ë‹ˆì–´', 'ì–´ë¦°ì´', 'ì´ˆë“±', 'ìœ ì¹˜ì›' ì œê±° - ì±…ìƒ, ê°€êµ¬ ë“± ì˜¤íƒ (ì•ˆì „ì»¨í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬)
}

# íŒë§¤ê¸ˆì§€/ê·œì œ ìƒí’ˆ
# â€» ì•ˆì „ ì»¨í…ìŠ¤íŠ¸(ë™, ì”, ì„ ë°˜ ë“±)ê°€ ìˆìœ¼ë©´ ë¬´ì‹œë¨
# â€» 2026-01-15 PPT "ì§€ì¬ê¶Œ ìœ„í—˜ ë¦¬ìŠ¤íŠ¸" ê¸°ë°˜ ëŒ€í­ ì—…ë°ì´íŠ¸
PROHIBITED_KEYWORDS = {
    # ==================== ìì „ê±° ê´€ë ¨ ====================
    "í”½ì‹œìì „ê±°", "ê³ ì •ê¸°ì–´ìì „ê±°", "ë¸Œë ˆì´í¬ì—†ëŠ”ìì „ê±°",

    # ==================== ì•ˆì „ì¸ì¦ í•„ìš” ê°€ì „ ====================
    "ê°€ìŠ¤ë Œì§€", "ê°€ìŠ¤ë ˆì¸ì§€", "ì „ê¸°ì¥íŒ", "ì „ê¸°ë§¤íŠ¸", "ì „ê¸°ë‹´ìš”",
    "ì˜¨ìˆ˜ë§¤íŠ¸", "ì „ê¸°íˆí„°", "ì„ìœ ë‚œë¡œ", "ê°€ìŠ¤ë‚œë¡œ",

    # ==================== í™”ì¥í’ˆ ====================
    "í™”ì¥í’ˆ", "ìŠ¤í‚¨ì¼€ì–´", "ë§ˆìŠ¤í¬íŒ©",
    "ìƒ´í‘¸", "ë¦°ìŠ¤", "íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸", "ë°”ë””ì›Œì‹œ",

    # ==================== ë¬´ê¸°ë¥˜ (PPT ìŠ¬ë¼ì´ë“œ 5,6) ====================
    "ë„ê²€", "ê¶Œì´", "ì†Œì´", "ë¹„ë¹„íƒ„ì´", "ì—ì–´ê±´", "ì„ê¶",
    "í™”ì•½", "í­ì£½", "ë¶ˆê½ƒë†€ì´",
    "ì¹¼", "ì‚¬ì‹œë¯¸ì¹¼", "íšŒì¹¼", "ì‹ì¹¼", "ê³¼ë„",  # ì¹¼ ì¢…ë¥˜
    "ëª¨í˜•ì´", "BBíƒ„ì´", "BBíƒ„", "ë„ˆí´", "ì „íˆ¬ì¹¼", "ë‚˜ì´í”„",
    "ì†ŒìŒê¸°", "ë ˆì´ì €ì¡°ì¤€ê¸°", "ì¡°ì¤€ê²½", "ë„íŠ¸ì‚¬ì´íŠ¸",  # ì´í¬ë¥˜ ê´€ë ¨

    # ==================== íƒ€ì •ê¸°/ì „ê¸°ì¶©ê²©ê¸° (PPT ìŠ¬ë¼ì´ë“œ 2,3) ====================
    "íƒ€ì •ì´", "íƒ€ì •ê¸°", "íƒ€ì¹´ì´", "íƒ€ì¹´ê±´", "íƒ€ì¹´",
    "ì „ê¸°ì¶©ê²©ê¸°", "ìŠ¤í„´ê±´", "í˜¸ì‹ ìš©ì¶©ê²©ê¸°",
    # ë™ë¬¼í•™ëŒ€ ë„êµ¬ (ì „ê¸°ì±„, ì „ê¸°ë´‰)
    "ì „ê¸°ì±„", "ì „ê¸°ë´‰", "ë¼ì§€ëª°ì´", "ì†Œëª°ì´", "ê°€ì¶•ëª°ì´", "ì¶•ì‚°ì „ê¸°ë´‰",

    # ==================== ê²½ì°°/êµ°ìš©í’ˆ (PPT ìŠ¬ë¼ì´ë“œ 7) ====================
    # ì „íˆ¬ë³µ/ìœ„ì¥ë³µ/êµ°ìš©ì€ ë°€ë¦¬í„°ë¦¬ íŒ¨ì…˜ìœ¼ë¡œ í—ˆìš© (ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬)
    "ê²½ì°°ì œë³µ", "ê²½ì°°ë³µ", "ìˆ˜ê°‘", "ê²½ì°°ë´‰", "ì‚¼ë‹¨ë´‰",
    "êµ°ë³µ",  # ì‹¤ì œ êµ°ë³µë§Œ ê¸ˆì§€ (ì „íˆ¬ë³µ, ìœ„ì¥ë³µ, êµ°ìš©ì€ íŒ¨ì…˜ìœ¼ë¡œ í—ˆìš©)

    # ==================== ë ˆì´ì € ê´€ë ¨ (PPT ìŠ¬ë¼ì´ë“œ 8) ====================
    # ë ˆì´ì €í¬ì¸í„°ë§Œ ê¸ˆì§€ (ë ˆì´ì €ë ˆë²¨ê¸°/ì¤„ì/ì¸¡ì •ê¸°ëŠ” ê³µêµ¬ì´ë¯€ë¡œ í—ˆìš©)
    "ë ˆì´ì €í¬ì¸í„°",

    # ==================== ê°€ìŠ¤/ì—°ë£Œ ê´€ë ¨ (PPT ìŠ¬ë¼ì´ë“œ 19,20) ====================
    "ê°€ìŠ¤í†µ", "ê°€ìŠ¤ë²„ë„ˆ", "ë¶€íƒ„ê°€ìŠ¤", "í”„ë¡œíŒê°€ìŠ¤",
    "íœ´ëŒ€ìš©ê°€ìŠ¤", "ìº í•‘ê°€ìŠ¤", "ê°€ìŠ¤í† ì¹˜",
    "ì—ì–´ì»¨ëƒ‰ë§¤", "ëƒ‰ë§¤ê°€ìŠ¤", "í”„ë ˆì˜¨ê°€ìŠ¤",

    # ==================== ì–´ì—…/í¬íš ë„êµ¬ (PPT ìŠ¬ë¼ì´ë“œ 16,17) ====================
    "ì‘ì‚´ì´", "ì‘ì‚´", "ì–´ë§", "íˆ¬ë§", "ìë§", "ê·¸ë¬¼",
    "ë™ë¬¼ë«", "í¬íšë§", "ì˜¬ë¬´", "ì¥ë«",

    # ==================== ë‹´ë°°/ì£¼ë¥˜ ====================
    "ë‹´ë°°", "ì „ìë‹´ë°°", "ë‹ˆì½”í‹´", "ë² ì´í”„",

    # ==================== ë„ë°• ====================
    "ë„ë°•", "ìŠ¬ë¡¯ë¨¸ì‹ ", "ë² íŒ…",

    # ==================== ë³µì œí’ˆ ====================
    "ì§í‰", "ì´ë¯¸í…Œì´ì…˜", "ë ˆí”Œë¦¬ì¹´",

    # ==================== ë°°í„°ë¦¬ (PPT ìŠ¬ë¼ì´ë“œ 27) ====================
    "ë¦¬íŠ¬ë°°í„°ë¦¬", "ëŒ€ìš©ëŸ‰ë°°í„°ë¦¬", "ë³´ì¡°ë°°í„°ë¦¬íŒ©",

    # ==================== ìƒí™œí™”í•™ (PPT ìŠ¬ë¼ì´ë“œ 26) ====================
    "ì ‘ì°©ì œ", "ì—í­ì‹œ", "ë³¸ë“œ", "ê¸€ë£¨ê±´ì‹¬",
    "í˜ì¸íŠ¸", "ë½ì¹´", "ë„ë£Œ", "ì‹œë„ˆ",
    "ì„¸ì œ", "í‘œë°±ì œ", "ì‚´ì¶©ì œ", "ì œì´ˆì œ",
    # ì œìŠµì œ/ë°©ìŠµì œ (ìƒí™œí™”í•™ì œí’ˆ)
    "ì œìŠµì œ", "ë°©ìŠµì œ", "ì‹¤ë¦¬ì¹´ê²”", "ìŠµê¸°ì œê±°ì œ",

    # ==================== ì›ë¬¼/ìì—°ë¬¼ (PPT ìŠ¬ë¼ì´ë“œ 25) ====================
    "ì›ëª©í†µë‚˜ë¬´", "ì›ì„", "í™", "ëª¨ë˜",  # ê°€ê³µë˜ì§€ ì•Šì€ ìì—°ë¬¼

    # ==================== ì°¨ëŸ‰ìš© ë¶ˆë²•ì¡°ëª… (PPT ìŠ¬ë¼ì´ë“œ 28) ====================
    "íŠ¸ëŸ­ì¡°ëª…", "í™”ë¬¼ì°¨ì¡°ëª…", "ë¶ˆë²•ì¡°ëª…",

    # ==================== ì˜ë£Œê¸°ê¸°/ìì„¸êµì • (PPT ìŠ¬ë¼ì´ë“œ 34) ====================
    # ì¹˜ë£Œ ëª©ì  í‚¤ì›Œë“œ (ë§ˆì‚¬ì§€ê¸°ì™€ êµ¬ë¶„)
    "í†µì¦ì™„í™”", "ë””ìŠ¤í¬ì™„í™”", "ì¹˜ë£Œìš©", "êµì •ê¸°", "ìì„¸êµì •ê¸°",
    "ì²™ì¶”êµì •", "ê³¨ë°˜êµì •", "ê±°ë¶ëª©êµì •",
    # í…Œë¼í—¤ë¥´ì¸ /ê³ ì£¼íŒŒ ì˜ë£Œê¸°ê¸° (í—ˆìœ„/ê³¼ëŒ€ê´‘ê³  + ì˜ë£Œê¸°ê¸°ë²• ìœ„ë°˜)
    "í…Œë¼í—¤ë¥´ì¸ ", "í…Œë¼í—¤ë¥´ì¯”", "ê³ ì£¼íŒŒì¹˜ë£Œ", "ê³ ì£¼íŒŒì¹˜ë£Œê¸°",
    "ì˜¬ë¦¬ë¼ì´í”„", "olylife", "P100",
    "ì›ì ì™¸ì„ ì¹˜ë£Œ", "ì ì™¸ì„ ì¹˜ë£Œê¸°", "ë°”ì´ì˜¤ë§¤íŠ¸",

    # ==================== ì„±ì¸ìš©í’ˆ (PPT ìŠ¬ë¼ì´ë“œ 24) ====================
    "ì„±ì¸ìš©í’ˆ", "ì„±ì¸í† ì´",

    # ==================== ì†ì˜·/ì˜ë¥˜ (ìœ„ìƒ/ë°˜í’ˆ ë¬¸ì œ) ====================
    # "ë¸Œë¼"ëŠ” ë¸Œë¼ì¼“/ë¸Œë¼ì´ëœ/ë˜ë¸Œë¼ë„ ë“± ì˜¤íƒ ë§ì•„ì„œ ì œê±°
    # "ë¸Œë˜ì§€ì–´", "ë¹µë¸Œë¼", "ë…¸ì™€ì´ì–´ë¸Œë¼", "ìŠ¤í¬ì¸ ë¸Œë¼"ëŠ” ìœ ì§€
    "ë¸Œë˜ì§€ì–´", "íŒ¬í‹°", "ì†ì˜·", "ì–¸ë”ì›¨ì–´", "underwear",
    "ë¹µë¸Œë¼", "ë…¸ì™€ì´ì–´ë¸Œë¼", "ìŠ¤í¬ì¸ ë¸Œë¼",
    "ì‚¼ê°íŒ¬í‹°", "ì‚¬ê°íŒ¬í‹°", "ë“œë¡œì¦ˆ",

    # ==================== ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ (ì¤‘êµ­ ìˆ˜ì…ê¸ˆì§€) ====================
    "ê±´ê¸°ì‹", "ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ", "ì˜ì–‘ì œ", "ë³´ì¶©ì œ", "ì„œí”Œë¦¬ë¨¼íŠ¸", "supplement",
    "í”„ë¡œí‹´", "protein", "ìœ ì²­ë‹¨ë°±", "íƒ„ìˆ˜í™”ë¬¼ë³´ì¶©ì œ", "ê²Œì´ë„ˆ", "carb",
    "ë¹„íƒ€ë¯¼", "vitamin", "ì˜¤ë©”ê°€3", "ìœ ì‚°ê· ", "í”„ë¡œë°”ì´ì˜¤í‹±ìŠ¤",
    "ì½œë¼ê²", "ê¸€ë£¨ì½”ì‚¬ë¯¼", "ë°€í¬ì”¨ìŠ¬", "í¬ë ˆì•„í‹´", "bcaa", "ì•„ë¯¸ë…¸ì‚°",
    "ë‰´íŠ¸ë¼ë°”ì´ì˜¤", "nutrabio", "ì˜µí‹°ë©ˆ", "optimum", "ë¨¸ìŠ¬íŒœ", "bsn",
}

# ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ (ì´ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìœ„í—˜ í‚¤ì›Œë“œ ë¬´ì‹œ)
# ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ë°˜ì˜: ì™€ì¸ë™, ì‚¬íƒ•ìíŒê¸°, ì´ˆë“±ì±…ìƒ ë“± ì˜¤íƒ ë°©ì§€
SAFE_CONTEXT_KEYWORDS = {
    # ê°€êµ¬/ìˆ˜ë‚©
    'ë™', 'ì„ ë°˜', 'ê±°ì¹˜ëŒ€', 'í™€ë”', 'ìŠ¤íƒ ë“œ', 'ë°›ì¹¨ëŒ€', 'ë°›ì¹¨',
    'ë³´ê´€í•¨', 'ìˆ˜ë‚©í•¨', 'ì •ë¦¬í•¨', 'ì¼€ì´ìŠ¤', 'ë°•ìŠ¤', 'ë°”êµ¬ë‹ˆ',
    'ê°€êµ¬', 'í…Œì´ë¸”', 'ì±…ìƒ', 'ì˜ì', 'ì„œë', 'ìºë¹„ë„·',

    # ì»µ/ìš©ê¸°ë¥˜ (ì™€ì¸ì”, ë§¥ì£¼ì” ë“±)
    'ì”', 'ì»µ', 'ê¸€ë¼ìŠ¤', 'í…€ë¸”ëŸ¬', 'ë¨¸ê·¸', 'ê³ ë¸”ë ›',
    'íŠ¸ë ˆì´', 'ì ‘ì‹œ', 'ê·¸ë¦‡', 'ìš©ê¸°', 'ë³¼', 'í”Œë ˆì´íŠ¸',

    # ì£¼ë°©/ì¡°ë¦¬ë„êµ¬
    'ì˜¤í”„ë„ˆ', 'ë”°ê°œ', 'ë³‘ë”°ê°œ', 'ì½”ë¥´í¬',
    'ì¿¨ëŸ¬', 'ì•„ì´ìŠ¤ë°•ìŠ¤', 'ë³´ëƒ‰', 'ì•„ì´ìŠ¤ë²„í‚·',
    'ë””ìŠ¤íœì„œ', 'ìíŒê¸°', 'ë³´í‹€',
    'ì£¼ë°©', 'í‚¤ì¹œ', 'ì¡°ë¦¬', 'ìš”ë¦¬', 'ë² ì´í‚¹',

    # ì¸í…Œë¦¬ì–´/ì¥ì‹
    'ì¸í…Œë¦¬ì–´', 'ì¥ì‹', 'ë°ì½”', 'ì†Œí’ˆ', 'ë””ìì¸',
    'ì¡°ëª…', 'ë¨í”„', 'ë¬´ë“œë“±', 'ìº”ë“¤',

    # ê¸°ê³„/ë„êµ¬
    'ê¸°ê³„', 'ë¨¸ì‹ ', 'ì¥ì¹˜', 'ê¸°ê¸°', 'ë„êµ¬', 'íˆ´',
    'ì„¸ì²™ê¸°', 'ì²­ì†Œê¸°', 'ë¶„ì‡„ê¸°', 'ë¯¹ì„œ',

    # í•™ìš©í’ˆ/ì‚¬ë¬´ìš©í’ˆ (ì´ˆë“±, ìœ ì¹˜ì› ì˜¤íƒ ë°©ì§€)
    'ì±…ê½‚ì´', 'í•„í†µ', 'ì—°í•„ê½‚ì´', 'ë¬¸êµ¬',

    # ìŠ¤í¬ì¸ /ë ˆì € (í‚¥ë³´ë“œ ë“± ì˜¤íƒ ë°©ì§€)
    'ë³´í˜¸ëŒ€', 'í—¬ë©§', 'ì•ˆì „ì¥ë¹„',

    # ê±´ì„¤/ê³µêµ¬ (ë°”ì´ë¸Œë ˆì´í„° ë“± ì˜¤íƒ ë°©ì§€)
    'ì½˜í¬ë¦¬íŠ¸', 'ê±´ì„¤', 'ê³µêµ¬', 'ì‹œë©˜íŠ¸', 'ì§„ë™ê¸°', 'ë‹¤ì§', 'ê±´ì¶•',
    'ì² ê·¼', 'ê±°í‘¸ì§‘', 'ë ˆë¯¸ì½˜', 'ê³µì‚¬', 'í˜„ì¥',

    # ë°˜ë ¤ë™ë¬¼ (ì¹´ì‹œíŠ¸, ìœ ëª¨ì°¨ ë“± ì˜¤íƒ ë°©ì§€)
    'ê°•ì•„ì§€', 'ì• ê²¬', 'ë°˜ë ¤ê²¬', 'í«', 'pet', 'ë°˜ë ¤ë™ë¬¼', 'ê³ ì–‘ì´', 'ì• ì™„',

    # ì—°ë£Œ/ê¸°ê³„ (ë””ì ¤ ë¸Œëœë“œ ì˜¤íƒ ë°©ì§€)
    'ì˜¤ì¼', 'íŒí”„', 'ì—”ì§„', 'ì—°ë£Œ', 'ê²½ìœ ', 'ê¸°ë¦„', 'ì£¼ìœ ', 'í•„í„°',
    'ë¶„ì‚¬', 'ë…¸ì¦', 'ë°œì „ê¸°', 'ë³´ì¼ëŸ¬', 'oil', 'pump', 'engine', 'fuel',

    # íŒ¨í„´/ìŠ¤íƒ€ì¼ (ë²„ë²„ë¦¬, í´ë¡œ ë“± ì˜¤íƒ ë°©ì§€)
    'ì²´í¬', 'íŒ¨í„´', 'ë¬´ëŠ¬', 'ì›ë‹¨', 'ì²œ', 'ì…”ì¸ ', 'ì¹´ë¼',

    # ì‹í’ˆ/ë””ì €íŠ¸ (ëª½ë¸”ë‘ ì¼€ì´í¬ ë“± ì˜¤íƒ ë°©ì§€)
    'ì¼€ì´í¬', 'ë””ì €íŠ¸', 'ì¼€ìµ', 'ë¹µ', 'ë² ì´ì»¤ë¦¬',
}

# í‚¤ì›Œë“œë³„ ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ ë§¤í•‘
# íŠ¹ì • ìœ„í—˜ í‚¤ì›Œë“œê°€ ì´ ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ìˆìœ¼ë©´ â†’ ì •ìƒ
# ì˜ˆ: "ë°”ì´ë¸Œë ˆì´í„°" + "ì½˜í¬ë¦¬íŠ¸" â†’ ê±´ì„¤ ê³µêµ¬ì´ë¯€ë¡œ ì •ìƒ
# ì˜ˆ: "ì¹´ì‹œíŠ¸" + "ê°•ì•„ì§€" â†’ ë°˜ë ¤ë™ë¬¼ìš©ì´ë¯€ë¡œ ì •ìƒ
KEYWORD_SAFE_CONTEXT_MAP = {
    # ì„±ì¸ í‚¤ì›Œë“œ â†’ ê³µêµ¬/ì‚°ì—… ì»¨í…ìŠ¤íŠ¸
    'ë°”ì´ë¸Œë ˆì´í„°': {'ì½˜í¬ë¦¬íŠ¸', 'ê±´ì„¤', 'ê³µêµ¬', 'ì‹œë©˜íŠ¸', 'ì§„ë™ê¸°', 'ë‹¤ì§', 'ê±´ì¶•', 'ì² ê·¼'},
    'ì§„ë™ê¸°': {'ì½˜í¬ë¦¬íŠ¸', 'ê±´ì„¤', 'ê³µêµ¬', 'ì‹œë©˜íŠ¸', 'ë§ˆì‚¬ì§€', 'ì•ˆë§ˆ', 'ê±´ê°•'},

    # ì„±ì¸ í‚¤ì›Œë“œ â†’ ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ (í•­ìƒ ìœ„í—˜)
    'ë”œë„': set(),

    # ì•„ë™ìš©í’ˆ í‚¤ì›Œë“œ â†’ ë°˜ë ¤ë™ë¬¼/ë…¸ì¸/ê¸°ê¸° ì»¨í…ìŠ¤íŠ¸
    'ì¹´ì‹œíŠ¸': {'ê°•ì•„ì§€', 'ì• ê²¬', 'ë°˜ë ¤ê²¬', 'í«', 'pet', 'ë°˜ë ¤ë™ë¬¼', 'ê³ ì–‘ì´', 'ì• ì™„', 'ì¤‘í˜•ê²¬', 'ëŒ€í˜•ê²¬'},
    'ìœ ëª¨ì°¨': {'ê°•ì•„ì§€', 'ì• ê²¬', 'ë°˜ë ¤ê²¬', 'í«', 'pet', 'ë°˜ë ¤ë™ë¬¼', 'ê³ ì–‘ì´', 'ì• ì™„'},
    'ì –ë³‘': {'ê°•ì•„ì§€', 'ì• ê²¬', 'ë°˜ë ¤ê²¬', 'í«', 'pet', 'ë°˜ë ¤ë™ë¬¼', 'ê³ ì–‘ì´', 'ì• ì™„', 'ìƒˆë¼', 'ì†Œë…', 'ì‚´ê· ', 'í”¼ë”©'},
    'ë³´í–‰ê¸°': {'ë…¸ì¸', 'í• ë¨¸ë‹ˆ', 'í• ì•„ë²„ì§€', 'ì–´ë¥´ì‹ ', 'í™˜ì', 'ì¬í™œ', 'ì›Œì»¤', 'ìš”ì–‘', 'ê±¸ìŒë§ˆ'},  # ì•„ê¸° ê±¸ìŒë§ˆ ì œì™¸
    'ì´ìœ ì‹': {'ì œì¡°ê¸°', 'ë©”ì´ì»¤', 'ë¸”ë Œë”', 'ë¯¹ì„œ', 'ë‘ìœ ', 'ì½©ë¬¼', 'ê±´ê°•',
               'ì €ìš¸', 'ë°”ë¦¬ìŠ¤íƒ€', 'ì»¤í”¼', 'ì „ìì €ìš¸', 'ì£¼ë°©ì €ìš¸', 'ê³„ëŸ‰'},  # ì´ìœ ì‹ ì œì¡°ê¸°, ë°”ë¦¬ìŠ¤íƒ€ ì €ìš¸ OK
    'ìœ ì•„ìš©': {'ì•…ê¸°', 'í”¼ì•„ë…¸', 'ì‹¤ë¡œí°', 'ë§ˆë¦¼ë°”', 'ê±´ë°˜', 'êµêµ¬', 'ì„¸ë°œìì „ê±°', 'ìì „ê±°'},  # ìœ ì•„ìš© ì•…ê¸°/êµêµ¬ëŠ” OK

    # ========== ë¸Œëœë“œ í‚¤ì›Œë“œ (ì¼ë°˜ ë‹¨ì–´ë¡œë„ ì‚¬ìš©ë˜ëŠ” ê²½ìš°) ==========
    # "ë””ì ¤ ì˜¤ì¼íŒí”„" â†’ ê²½ìœ  ê´€ë ¨ â†’ ì •ìƒ
    # "ë””ì ¤ ì²­ë°”ì§€" â†’ DIESEL ë¸Œëœë“œ â†’ ìœ„í—˜ (ê°€í’ˆ)
    'ë””ì ¤': {'ì˜¤ì¼', 'íŒí”„', 'ì—”ì§„', 'ì—°ë£Œ', 'ê²½ìœ ', 'ê¸°ë¦„', 'ì£¼ìœ ', 'í•„í„°', 'ë¶„ì‚¬', 'ë…¸ì¦', 'ë°œì „ê¸°', 'ë³´ì¼ëŸ¬'},
    'diesel': {'oil', 'pump', 'engine', 'fuel', 'filter', 'injection', 'generator'},

    # "í´ë¡œ ì…”ì¸ " â†’ í´ë¡œ ìŠ¤íƒ€ì¼ â†’ ì •ìƒ (ì¹´ë¼ ìˆëŠ” ì…”ì¸  ìŠ¤íƒ€ì¼)
    'í´ë¡œ': {'ì…”ì¸ ', 'í‹°ì…”ì¸ ', 'ì¹´ë¼', 'ë°˜íŒ”', 'ê¸´íŒ”', 'ë‹ˆíŠ¸', 'ìŠ¤íƒ€ì¼'},

    # "ëª½ë¸”ë‘ ì¼€ì´í¬" â†’ ë””ì €íŠ¸ â†’ ì •ìƒ
    'ëª½ë¸”ë‘': {'ì¼€ì´í¬', 'ë””ì €íŠ¸', 'ì¼€ìµ', 'ë¹µ', 'ë² ì´ì»¤ë¦¬', 'ì‚°', 'ë“±ì‚°'},

    # "ìƒ¤ë„¬ ì—¼ìƒ‰" â†’ ì—¼ìƒ‰ ê¸°ë²• â†’ ì •ìƒ
    'ìƒ¤ë„¬': {'ì—¼ìƒ‰', 'ì˜´ë¸Œë ˆ', 'í—¤ì–´', 'ë¯¸ìš©'},

    # "ë²„ë²„ë¦¬ ì²´í¬" â†’ ì²´í¬ë¬´ëŠ¬ íŒ¨í„´ â†’ ì •ìƒ
    'ë²„ë²„ë¦¬': {'ì²´í¬', 'íŒ¨í„´', 'ë¬´ëŠ¬', 'ì›ë‹¨', 'ì²œ'},

    # ========== ê¸ˆì§€ í‚¤ì›Œë“œ â†’ ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ ==========
    # "ì—ì–´ê±´ ì†¡í’ê¸°" â†’ ì²­ì†Œìš© â†’ ì •ìƒ
    'ì—ì–´ê±´': {'ì†¡í’ê¸°', 'ì†¡í’', 'ë¸”ë¡œì›Œ', 'ë¸Œë¡œì›Œ', 'ì²­ì†Œ', 'ë¨¼ì§€ì œê±°', 'ì„¸ì°¨', 'ë‚™ì—½', 'ë¬´ì„ ', 'ì¶©ì „ì‹'},

    # "ìƒ´í‘¸ë² ë“œ" â†’ ë¯¸ìš©ì‹¤ ê¸°êµ¬ â†’ ì •ìƒ
    'ìƒ´í‘¸': {'ë² ë“œ', 'ì¹¨ëŒ€', 'ë¯¸ìš©ì‹¤', 'í—¤ì–´ìƒµ', 'ì„¸ë©´ëŒ€', 'ìƒ´í‘¸ëŒ€'},

    # "í™”ì¥í’ˆ ìˆ˜ë‚©" â†’ ìˆ˜ë‚©ê°€êµ¬ â†’ ì •ìƒ
    'í™”ì¥í’ˆ': {'ìˆ˜ë‚©', 'ë³´ê´€', 'ì •ë¦¬', 'ì¼€ì´ìŠ¤', 'íŒŒìš°ì¹˜', 'ê°€ë°©', 'íŠ¸ë¡¤ë¦¬', 'í™”ì¥ëŒ€', 'ì½˜ì†”'},

    # "ì „ê¸°íˆí„° ë¶€í’ˆ" â†’ ìˆ˜ë¦¬ìš© ë¶€í’ˆ â†’ ì •ìƒ
    'ì „ê¸°íˆí„°': {'ë¶€í’ˆ', 'êµì²´', 'ìˆ˜ë¦¬', 'ë¶€ì†', 'ë¦¬ë¯¸í„°', 'ì§€ì§€ëŒ€', 'ë¸Œë˜í‚·', 'ë°”í€´'},

    # "ì „ë™íœ ì²´ì–´" â†’ ì˜ë£Œê¸°ê¸° â†’ ì •ìƒ (ì „ë™íœ ê³¼ êµ¬ë¶„)
    'ì „ë™íœ ': {'íœ ì²´ì–´', 'ì˜ì', 'ì¥ì• ì¸', 'ë…¸ì¸', 'í™˜ì'},

    # "ì½”ë¥´ì…‹ ë³´ì •ì†ì˜·" â†’ ì¼ë°˜ ì†ì˜· â†’ ì •ìƒ
    # "ì¤‘ì„¸ ì½”ë¥´ì…‹ ë“œë ˆìŠ¤" â†’ ì˜ìƒ/ì½”ìŠ¤íŠ¬ â†’ ì •ìƒ
    'ì½”ë¥´ì…‹': {'ë³´ì •', 'ê±°ë“¤', 'ì†ì˜·', 'ì••ë°•', 'í—ˆë¦¬', 'ë³µëŒ€', 'ì›¨ì´ìŠ¤íŠ¸', 'ë‹¤ì´ì–´íŠ¸', 'ë±ƒì‚´', 'ë˜¥ë°°',
               'ì¤‘ì„¸', 'ë“œë ˆìŠ¤', 'ì˜ìƒ', 'ë¹…í† ë¦¬ì•„', 'ë¥´ë„¤ìƒìŠ¤', 'ë¬´ëŒ€', 'ë¬´ëŒ€ì˜ìƒ', 'ê³µì—°', 'íŒŒí‹°', 'ì›¨ë”©'},

    # ========== PPT ê¸°ë°˜ ì¶”ê°€ ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ (2026-01-15) ==========

    # "ëƒ‰ë§¤ ì¶©ì „ê¸°" â†’ OK (PPT ìŠ¬ë¼ì´ë“œ 20)
    'ëƒ‰ë§¤': {'ì¶©ì „ê¸°', 'ì¶©ì „', 'ê²Œì´ì§€', 'ë§¤ë‹ˆí´ë“œ', 'í˜¸ìŠ¤'},

    # "ë§ˆì‚¬ì§€ê¸°", "ë³´í˜¸ëŒ€" â†’ OK (PPT ìŠ¬ë¼ì´ë“œ 34: ë‹¨ìˆœ ë§ˆì‚¬ì§€ê¸°, ë³´í˜¸ëŒ€ëŠ” OK)
    # ë‹¨, "í†µì¦ì™„í™”", "ë””ìŠ¤í¬ì™„í™”" í‚¤ì›Œë“œ ìˆìœ¼ë©´ ìœ„í—˜
    'ë§ˆì‚¬ì§€ê¸°': {'ì•ˆë§ˆ', 'ë§ˆì‚¬ì§€', 'ì§„ë™', 'ì§€ì••', 'ë¦´ë ‰ìŠ¤', 'í”¼ë¡œ', 'ê·¼ìœ¡'},
    'ë³´í˜¸ëŒ€': {'ì†ëª©', 'ë°œëª©', 'ë¬´ë¦', 'íŒ”ê¿ˆì¹˜', 'ì–´ê¹¨', 'ë“±', 'í—ˆë¦¬'},

    # "ì¬ë–¨ì´", "ë‹´ë°°ì¼€ì´ìŠ¤" â†’ OK (PPT ìŠ¬ë¼ì´ë“œ 24)
    'ë‹´ë°°': {'ì¬ë–¨ì´', 'ì¼€ì´ìŠ¤', 'ë³´ê´€í•¨'},

    # "ì¹¼" â†’ ì£¼ë°©/ê³µì˜ˆ/ì‚°ì—…ìš©í’ˆ ì»¨í…ìŠ¤íŠ¸ (PPT ìŠ¬ë¼ì´ë“œ 5)
    # ì˜¤íƒ ìˆ˜ì •: ì±„ì¹¼, êµ¬ë‘ì¹¼, ì¬ë‹¨ì¹¼, ì¹¼êµ­ìˆ˜, ì¹¼ë¼ ë“±
    'ì¹¼': {'ì£¼ë°©', 'ìš”ë¦¬', 'ê³¼ì¼', 'ì±„ì†Œ', 'ë¹µì¹¼', 'í”¼ìì»¤í„°', 'ë„ë§ˆ', 'ì¹¼ê°ˆì´', 'ì¹¼ê½‚ì´',
           'ì±„ì¹¼', 'ìŠ¬ë¼ì´ì„œ', 'êµ¬ë‘', 'ì£¼ê±±', 'ì¬ë‹¨', 'ì»¤íŒ…ê¸°', 'ì ˆë‹¨ê¸°', 'ì»¤í„°',
           'ì¹¼êµ­ìˆ˜', 'êµ­ìˆ˜', 'ì¹¼ë¼', 'ì»¬ëŸ¬', 'ë¬´ì±„', 'ë§ŒëŠ¥ì±„', 'ì›ë‹¨', 'ì„¬ìœ '},
    'ë‚˜ì´í”„': {'ë²„í„°', 'ì¹˜ì¦ˆ', 'ìŠ¤í…Œì´í¬', 'í”¼ì', 'í…Œì´ë¸”', 'ì£¼ë°©', 'ì»¤íŠ¸ëŸ¬ë¦¬'},

    # "ë ˆì´ì €" â†’ ê³µêµ¬/ì‚°ì—…ìš© ì¥ë¹„ëŠ” ì•ˆì „ (ë ˆì´ì €í¬ì¸í„°, ë ˆì´ì €ì œëª¨ê¸°ëŠ” ê¸ˆì§€)
    'ë ˆì´ì €': {'í”„ë¦°í„°', 'ë³µí•©ê¸°', 'ê°ì¸ê¸°', 'ë§ˆí‚¹ê¸°', 'ì»¤íŒ…ê¸°', 'ìš©ì ‘ê¸°', 'ìš©ì ‘',
               'ë ˆë²¨ê¸°', 'ë ˆë²¨', 'ì¤„ì', 'ì¸¡ì •ê¸°', 'ê±°ë¦¬ì¸¡ì •', 'ìˆ˜í‰', 'ê³µêµ¬'},

    # "ê°€ìŠ¤í†µ" â†’ ìš´ë°˜/ê±°ì¹˜ ì¥ë¹„
    'ê°€ìŠ¤í†µ': {'ìš´ë°˜ê¸°', 'ì¹´íŠ¸', 'í•¸ë“œì¹´', 'ê±°ì¹˜ëŒ€', 'ë°›ì¹¨ëŒ€', 'íŠ¸ë¡¤ë¦¬'},

    # "ì ‘ì°©ì œ" â†’ ê³µì˜ˆ/DIY ìš©ë„ (PPT ìŠ¬ë¼ì´ë“œ 26)
    'ì ‘ì°©ì œ': {'ê³µì˜ˆ', 'DIY', 'ìˆ˜ê³µì˜ˆ', 'ë¯¸ë‹ˆì–´ì²˜', 'ëª¨í˜•', 'í”„ë¼ëª¨ë¸'},
    'ë³¸ë“œ': {'ê³µì˜ˆ', 'DIY', 'ìˆ˜ê³µì˜ˆ', 'ëª©ê³µ', 'ì¢…ì´'},

    # "ë°°í„°ë¦¬" â†’ ì†Œí˜•/êµì²´ìš© (PPT ìŠ¬ë¼ì´ë“œ 27)
    'ë°°í„°ë¦¬': {'AA', 'AAA', 'ê±´ì „ì§€', 'êµì²´ìš©', 'ë¦¬ëª¨ì»¨', 'ì‹œê³„'},

    # "íƒ€ì¹´" â†’ ìŠ¤í…Œì´í”ŒëŸ¬ ìœ í˜• (PPT ìŠ¬ë¼ì´ë“œ 2: íƒ€ì¹´ê±´ì€ ìœ„í—˜, ì¼ë°˜ ìŠ¤í…Œì´í”ŒëŸ¬ëŠ” OK)
    'íƒ€ì¹´': {'ìŠ¤í…Œì´í”Œ', 'ì œë³¸', 'ì‚¬ë¬´ìš©'},

    # "ê·¸ë¬¼" â†’ ìŠ¤í¬ì¸ /ì¸í…Œë¦¬ì–´ ìš©ë„ (PPT ìŠ¬ë¼ì´ë“œ 16)
    # ì˜¤íƒ ìˆ˜ì •: ì˜ìê·¸ë¬¼, íƒêµ¬ê·¸ë¬¼ë§ ë“±
    'ê·¸ë¬¼': {'ë°°êµ¬', 'ì¶•êµ¬', 'ê³¨ëŒ€', 'í…Œë‹ˆìŠ¤', 'ë°°ë“œë¯¼í„´', 'í•´ë¨¹', 'ì¸í…Œë¦¬ì–´', 'ì •ë¦¬ë§',
             'ì˜ì', 'ê·¸ë„¤', 'ì²œì¥', 'íƒêµ¬', 'ìˆ˜ì§‘ë§', 'ê°€ë¦¼ë§‰'},

    # "ë«" â†’ ë¹„ìœ ì  ì‚¬ìš©
    'ë«': {'ê²Œì„', 'ë³´ë“œê²Œì„', 'í¼ì¦'},

    # ========== ì‹œë®¬ë ˆì´ì…˜ ì˜¤íƒ ê¸°ë°˜ ì¶”ê°€ (2026-01-15, 2026-01-16 ì—…ë°ì´íŠ¸) ==========

    # "ì†ŒìŒê¸°" â†’ í™˜ê¸°/ë•íŠ¸/ì˜¤í† ë°”ì´/ë¨¸í”ŒëŸ¬/íˆí„° ë¶€í’ˆ (ì´ê¸° ì†ŒìŒê¸° ì•„ë‹˜)
    'ì†ŒìŒê¸°': {'ë•íŠ¸', 'í™˜ê¸°', 'í¡ìŒ', 'ë°°ê´€', 'ì—ì–´ì»¨', 'í™˜í’ê¸°', 'ë¨¸í”ŒëŸ¬', 'ë°°ê¸°', 'ì˜¤í† ë°”ì´', 'ì‹¤ë¦°ë”', 'ë°¸ë¸Œ', 'ê³µì••',
               'íˆí„°', 'ë¬´ì‹œë™íˆí„°', 'ê²½ìœ íˆí„°', 'ì˜¨í’ê´€', 'ì°¨ëŸ‰', 'ë¶€í’ˆ', 'í™”ë¬¼ì°¨'},

    # "ì›ì„" â†’ ë³´ì„ìˆ˜ì§‘/í‘œë³¸/ì—°ë²¼ë£¨/íŒ”ì°Œ
    'ì›ì„': {'ì •ì›', 'ì¡°ê²½', 'ì •ì›ì„', 'ì¡°ê²½ì„', 'í™”ë‹¨', 'í‘œë³¸', 'ê´‘ë¬¼', 'ì»¬ë ‰ì…˜', 'íŒ¬ë˜íŠ¸', 'íŒ”ì°Œ',
             'ë³´ê´€í•¨', 'ì •ë¦¬í•¨', 'ë””ìŠ¤í”Œë ˆì´', 'íŠ¸ë ˆì´', 'ì—°ë²¼ë£¨', 'ë²¼ë£¨', 'ì„œì˜ˆ'},

    # "í˜ì¸íŠ¸" â†’ ë„ë°°/ìŠ¤í”„ë ˆì´ê±´/ë¶„ì‚¬ê¸°/ì—ì–´ë¦¬ìŠ¤/ë„ì¥ê¸°/ì°¨ëŸ‰ë„ìƒ‰/ë§ˆí‚¹/ì‘ì—…ëŒ€/ë…¹ì œê±°/ì…€í”„
    'í˜ì¸íŠ¸': {'ë¡¤ëŸ¬', 'ë¶“', 'ë„ë°°', 'ë²½ì§€', 'ë¦¬í¼', 'íŒê¸ˆ', 'í•„ë¦„', 'ì¬íŒ…', 'ë¯¹ì„œ', 'êµë°˜ê¸°',
               'ë¬´í˜ì¸íŠ¸', 'ì¹œí™˜ê²½', 'ì›ëª©', 'ì˜ì', 'ê°€êµ¬', 'ë¨í”„', 'ê²½í™”', 'ë ˆì§„', 'UV',
               'ìŠ¤í”„ë ˆì´ê±´', 'ë¶„ì‚¬ê¸°', 'ì—ì–´ë¦¬ìŠ¤', 'ë„ì¥ê¸°', 'ë¿œì¹ ', 'ì‘ì—…ë³µ', 'ë©œë¹µ', 'ì •ë¹„ë³µ',
               'íŒ¬í†¤', 'ì»¬ëŸ¬ì¹©', 'ìƒ‰ìƒí‘œ', 'ìº”', 'ë¹ˆìº”', 'ë“œëŸ¼í†µ', 'ì–‘ì² í†µ', 'í›„ë¼', 'ë¸ŒëŸ¬ì‰¬',
               'ì°¨ëŸ‰', 'ë„ìƒ‰', 'ë§ˆí‚¹', 'ì£¼ì°¨ì„ ', 'ìŠ¤í”„ë ˆì´', 'ìë™ì°¨', 'ë°”ë””', 'ë³´ìˆ˜',
               'ëŒë¦¼íŒ', 'ì‘ì—…ëŒ€', 'íšŒì „', 'ìš©ì ‘', 'ê±´ì¡°ë™', 'ê±´ì¡°ëŒ€',
               'ë…¹ì œê±°', 'ë…¹ë°©ì§€', 'ë°©ì²­', 'ì…€í”„', 'ìˆ˜ì„±', 'ì² íŒ', 'ê³°íŒ¡ì´', 'ë²½ì¹ ', 'ëˆ„ìˆ˜'},

    # "í™" â†’ ì •ì›/ì²­ì†Œ/ì²´/í¬í¬/ìˆ˜ì¤‘íŒí”„/ë„ìê¸°
    'í™': {'ì •ì›', 'í™”ë‹¨', 'í…Œë‘ë¦¬', 'ì—£ì§€', 'í„¸ì´', 'ë¸ŒëŸ¬ì‹œ', 'ë¨¼ì§€', 'í´ë¦¬ë„ˆ',
           'ì²´', 'ë¦¬ë“¤', 'ë©”ì‰¬', 'ì„ ë³„', 'ë°›ì´', 'íŠ¸ëŸ­', 'ì»¤ë²„', 'ê°€ë“œ', 'ë§¤íŠ¸',
           'í¬í¬', 'ì‚½', 'ë†ê¸°êµ¬', 'ê²½ì‘', 'íŒí”„', 'ë°°ìˆ˜', 'ì–‘ìˆ˜', 'ìŠ¬ëŸ¬ì§€',
           'í¼í‹°', 'ì„ê³ ', 'ìŠ¤í¬ë˜í¼', 'ë¯¸ì¥', 'ë„ìê¸°', 'ë„ì˜ˆ', 'ëª°ë“œ', 'ì„¸ë¼ë¯¹', 'ì†'},

    # "ëª¨ë˜" â†’ í•´ë³€/ë†€ì´/ì²´/ì½˜í™€/ìƒŒë“œì•„íŠ¸/ìƒ‰ìƒ
    'ëª¨ë˜': {'í•´ë³€', 'ìˆ˜ì˜ì¥', 'ë†€ì´', 'ìŠ¤í…', 'ì‚½', 'êµ´ì‚­ê¸°', 'í¬í¬ë ˆì¸',
             'ì½©ì£¼ë¨¸ë‹ˆ', 'ë˜ì§€ê¸°', 'ê²Œì„', 'ì£¼ë¨¸ë‹ˆ', 'ì²´', 'ê±°ë¦„', 'ì„ ë³„',
             'ê·¸ëŠ˜ë§‰', 'íƒ€í”„', 'ì•ˆì „í™”', 'í„¸ì´', 'ë¸ŒëŸ¬ì‹œ', 'ì½˜í™€', 'ë³´ë“œ',
             'ìƒŒë“œì•„íŠ¸', 'ìŠ¤í¬ë¦°', 'LED', 'ì—°ìŠµ', 'ë“±ì‚°í™”', 'ì–‘ë§', 'ë§¨ë°œ',
             'ìƒ‰', 'ìƒ‰ìƒ', 'ë² ì´ì§€', 'íƒ„ìƒ‰', 'ê°œë¨¸ë¦¬íŒ', 'ë¸”ë™', 'ê·¸ë¦°'},

    # "êµ°ìš©" â†’ ë°€ë¦¬í„°ë¦¬ ìŠ¤íƒ€ì¼/ê°€ë°©/ì›Œì¹˜/ë¶€ì¸ /ëª¨í˜•
    'êµ°ìš©': {'ìŠ¤íƒ€ì¼', 'íŒ¨ì…˜', 'íŒŒì¹´', 'ì í¼', 'ë°”ëŒë§‰ì´', 'ì¬í‚·', 'ìºì£¼ì–¼',
             'ë°°ë‚­', 'ë°±íŒ©', 'ê°€ë°©', 'ëŒ€ìš©ëŸ‰', 'ì„œë°”ì´ë²Œ', 'ì „ìˆ ë°°ë‚­', 'ë‚šì‹œ',
             'ì›Œì¹˜', 'ìŠ¤ë§ˆíŠ¸ì›Œì¹˜', 'ë‚¨ì„±ìš©', 'ìš¸íŠ¸ë¼', 'ë¶€ì¸ ', 'ì „íˆ¬í™”', 'ì‘ì—…í™”', 'ì •ê¸€í™”',
             'ê¹”ê¹”ì´', 'ë‚´í”¼', 'íŒ¨ë”©', 'ëˆ„ë¹”', 'í—¬ë¦¬ì½¥í„°', 'ëª¨í˜•', 'ë‹¤ì´ìºìŠ¤íŠ¸', 'í”¼ê·œì–´'},

    # "ì–´ë§" â†’ ì—ì–´ë§ì¹˜(ê³µêµ¬)ë§Œ í—ˆìš©
    # â€» ë¬¼ê³ ê¸° ì¡ëŠ” ì–´ë§/íˆ¬ë§/ì •ì¹˜ë§ì€ ìœ„í—˜ (ë¶ˆë²•ì–´íš ê°€ëŠ¥)
    'ì–´ë§': {'ì—ì–´ë§ì¹˜', 'ë§ì¹˜', 'í•¨ë§ˆ', 'ê³µêµ¬', 'ëª©ê³µ'},

    # "ê·¸ë¬¼" â†’ ìŠ¤í¬ì¸ /íŠ¸ë í¬/í™”ë¬¼/ì˜ë¥˜/í¬ì¥ì¬ í—ˆìš©
    # â€» ë¬¼ê³ ê¸°/ìƒˆìš°/ê³ ê¸°ì¡ì´ìš© ê·¸ë¬¼ì€ ìœ„í—˜ (ë¶ˆë²•ì–´íš ê°€ëŠ¥)
    # â€» ë†ì—…ìš©(ë…¸ë£¨ë§, ë‹­ì¥), í¬ì¥ì¬(ê³¼ì¼ë§) í—ˆìš©
    'ê·¸ë¬¼': {'ë°°êµ¬', 'ì¶•êµ¬', 'ê³¨ëŒ€', 'í…Œë‹ˆìŠ¤', 'ë°°ë“œë¯¼í„´', 'í•´ë¨¹', 'ì¸í…Œë¦¬ì–´', 'ì •ë¦¬ë§',
             'ì˜ì', 'ê·¸ë„¤', 'ì²œì¥', 'íƒêµ¬', 'ìˆ˜ì§‘ë§', 'ê°€ë¦¼ë§‰', 'ìŠ¤ìœ™', 'ì—°ìŠµë§', 'ê³¨í”„',
             'íŠ¸ë í¬', 'ë„¤íŠ¸', 'ë²¤ì¸ ', 'í™”ë¬¼', 'í¬ë ˆì¸', 'í˜¸ì´ìŠ¤íŠ¸', 'ê²©ì',
             'ë§ì‚¬', 'ë©”ì‰¬', 'ì‹œìŠ¤ë£¨', 'ë‹ˆíŠ¸', 'í‹°ì…”ì¸ ', 'ì–‡ì€',
             'ë…¸ë£¨ë§', 'ë‹­ì¥', 'ì–‘ê³„ì¥', 'ë©§ë¼ì§€', 'ë‚˜ì¼ë¡ ', 'ì•ˆì „',
             'ê³¼ì¼ë§', 'í¬ì¥ì¬', 'í¬ì¥', 'íƒë°°', 'ì™„ì¶©', 'ë³´í˜¸', 'ë§¤ì‰¬'},
    # â€» ì œì™¸: ì„ ë°•, ë¬¼ê³ ê¸°, ëœ°ì±„, ìƒˆìš°, ë¯¼ë¬¼, ë°”ë‹¤ ë“± ì–´ì—… ê´€ë ¨

    # "ì¹´ì‹œíŠ¸" ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ â†’ ì„±ì¸ìš© ì°¨ëŸ‰ì‹œíŠ¸, íŠ¸ëŸ­/í™”ë¬¼ì°¨ ì‹œíŠ¸êµì²´
    'ì¹´ì‹œíŠ¸': {'ê°•ì•„ì§€', 'ì• ê²¬', 'ë°˜ë ¤ê²¬', 'í«', 'pet', 'ë°˜ë ¤ë™ë¬¼', 'ê³ ì–‘ì´', 'ì• ì™„', 'ì¤‘í˜•ê²¬', 'ëŒ€í˜•ê²¬',
               'íšŒì „', 'ë¦¬ë¬´ì§„', 'ì¹´ë‹ˆë°œ', 'ì„±ì¸', 'ì°¨ëŸ‰ìš©', 'ì‹œíŠ¸ì»¤ë²„',
               'íŠ¸ëŸ­', 'í™”ë¬¼ì°¨', 'ì…€í”„êµì²´', 'ì¢Œì„', 'êµì²´', 'ìë™ì°¨ì‹œíŠ¸'},

    # "ê°€ìŠ¤í†µ" â†’ ë‚œë¡œ/ë³´ê´€í•¨/ê±°ì¹˜ëŒ€/ìš©ì ‘/ëŒ€ì°¨
    'ê°€ìŠ¤í†µ': {'ìš´ë°˜ê¸°', 'ì¹´íŠ¸', 'í•¸ë“œì¹´', 'ê±°ì¹˜ëŒ€', 'ë°›ì¹¨ëŒ€', 'íŠ¸ë¡¤ë¦¬',
               'ë‚œë¡œ', 'í™”ë¡œ', 'ë¶ˆë©', 'ë“œëŸ¼í†µ', 'ë³´ê´€í•¨', 'ì•ˆì „', 'ì„ ë°˜',
               'ì ˆë‹¨ê¸°', 'ìš©ì ‘', 'í† ì¹˜', 'ì‚°ì†Œí†µ', 'ì‹¤ë¦°ë”', 'ëŒ€ì°¨', 'ìˆ˜ë ˆ',
               'íˆí„°', 'ê°€ì—´', 'ë³´ì˜¨'},

    # "ì¹¼" â†’ ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (ë¯¹ì„œì¹¼,ë©´ë„ì¹¼ê°ˆì´,íšŸì¹¼ì—°ë§ˆ,ì¡°í”¼ì¹¼,ì „ì •ê°€ìœ„,ì—¼í™”ì¹¼ìŠ˜,ì•Œì¹¼ë¦¬,ì™€ì¸ì¹¼,ì°¨ì¹¼,ì¥ë‚œê°ì¹¼)
    'ì¹¼': {'ì£¼ë°©', 'ìš”ë¦¬', 'ê³¼ì¼', 'ì±„ì†Œ', 'ë¹µì¹¼', 'í”¼ìì»¤í„°', 'ë„ë§ˆ', 'ì¹¼ê°ˆì´', 'ì¹¼ê½‚ì´',
           'ì±„ì¹¼', 'ìŠ¬ë¼ì´ì„œ', 'êµ¬ë‘', 'ì£¼ê±±', 'ì¬ë‹¨', 'ì»¤íŒ…ê¸°', 'ì ˆë‹¨ê¸°', 'ì»¤í„°',
           'ì¹¼êµ­ìˆ˜', 'êµ­ìˆ˜', 'ì¹¼ë¼', 'ì»¬ëŸ¬', 'ë¬´ì±„', 'ë§ŒëŠ¥ì±„', 'ì›ë‹¨', 'ì„¬ìœ ',
           'ë¯¹ì„œê¸°', 'ë¯¹ì„œ', 'ë¸”ë Œë”', 'ë©´ë„', 'ìˆ«ëŒ', 'ì—°ë§ˆ', 'ìƒ¤í”„ë„ˆ', 'íšŸì¹¼', 'íšŒì¹¼',
           'ì¡°ê²½', 'ë¬˜ëª©', 'í•„ë§', 'ì „ì •', 'ê°€ìœ„', 'ì¶©ì „ì‹', 'ì„œê°', 'ì¡°ê°ë„', 'ì¡°ê°ê¸°',
           'ì—¼í™”ì¹¼ìŠ˜', 'ì‚´í¬ê¸°', 'íŒŒì¢…', 'ì•Œì¹¼ë¦¬', 'ì‚°ì„±', 'í•„í„°', 'ì—¬ê³¼ê¸°',
           'ì™€ì¸', 'ì˜¤í”„ë„ˆ', 'ì½”ë¥´í¬', 'ë³‘ë”°ê°œ', 'ì†Œë¯ˆë¦¬ì—', 'ì™€ì¸ì˜¤í”„ë„ˆ',
           'ì°¨ì¹¼', 'ë‹¤ë„', 'ë³´ì´ì°¨', 'ì°»ì', 'í‹°ë‚˜ì´í”„', 'ì¥ë‚œê°', 'ë°©íŒ¨', 'ì¹¼ë‚ '},

    # "ëª©ë°œ" â†’ ë°œíŒ/ë‚˜ë¬´ë°œíŒ/ì›ëª©ë°œíŒ (ì˜ë£Œê¸°ê¸° ì•„ë‹˜)
    'ëª©ë°œ': {'ë°œíŒ', 'ë‚˜ë¬´', 'ì›ëª©', 'ì‹±í¬ëŒ€', 'ê³„ë‹¨', 'ë””ë”¤ëŒ€', 'ìŠ¤í…', 'ì‚¬ë‹¤ë¦¬', 'ìš•ì‹¤'},

    # ========== ì‹œë®¬ë ˆì´ì…˜ AI ê²€ì¦ ì˜¤íƒ ìˆ˜ì • (2026-01-16) ==========

    # "ì‹œìŠ¤ë£¨" â†’ íŒ¨ì…˜/ë©”ì‰¬/ëŒ„ìŠ¤ ì»¨í…ìŠ¤íŠ¸ (ì„±ì¸ìš©í’ˆ ì•„ë‹˜)
    'ì‹œìŠ¤ë£¨': {'íŒ¨ì…˜', 'ë©”ì‰¬', 'ë§ì‚¬', 'ë‹ˆíŠ¸', 'ì›í”¼ìŠ¤', 'ë“œë ˆìŠ¤', 'ë¸”ë¼ìš°ìŠ¤', 'ë ˆì´ìŠ¤', 'íƒ‘', 'ê°€ë””ê±´',
               'ì‹œìŠ¤ë£¨íƒ‘', 'ì‹œìŠ¤ë£¨ì›í”¼ìŠ¤', 'ì‹œìŠ¤ë£¨ë‹ˆíŠ¸', 'ì‰¬í°', 'ì‰¬ì–´',
               'ë¼í‹´', 'ëŒ„ìŠ¤', 'ëŒ„ìŠ¤ë³µ', 'ìƒì˜', 'ê¸´íŒ”', 'ìŠ¤í¬ì¸ '},

    # "êµì •ê¸°" â†’ ìë™ì°¨ íŒê¸ˆ/íœ€ë‹¤, ê³¨í”„, ë°œëª© ì»¨í…ìŠ¤íŠ¸ (ì¹˜ì•„êµì •ê¸°/ìì„¸êµì •ê¸° ì•„ë‹˜)
    'êµì •ê¸°': {'íœ€ë‹¤', 'íœë‹¤', 'íŒê¸ˆ', 'ìë™ì°¨', 'ì°¨ëŸ‰', 'ë°”ë””', 'ë´íŠ¸', 'ë³µì›', 'ìˆ˜ë¦¬', 'ë²”í¼',
               'ê³¨í”„', 'ìŠ¤ìœ™', 'ì—°ìŠµ', 'ì–´í”„ë¡œì¹˜', 'í¼íŒ…', 'ì‹¤ë‚´', 'ê°€ì •ìš©',
               'ë°œëª©', 'ì†ëª©', 'ë¬´ë¦', 'ë³´ì¡°ê¸°', 'ë³´í˜¸ëŒ€', 'ì¡±ë¶€', 'ê·¼ë§‰ì—¼'},

    # "ìŠ¤í…íŠ¸" â†’ í…íŠ¸ ì˜¤íƒ€ ì»¨í…ìŠ¤íŠ¸ (ì˜ë£Œìš© ìŠ¤í…íŠ¸ ì•„ë‹˜)
    'ìŠ¤í…íŠ¸': {'í…íŠ¸', 'ë¹™ì–´', 'ë‚šì‹œ', 'ìº í•‘', 'ì–¼ìŒ', 'ì›í„°ì¹˜', 'íë¸Œ'},

    # "ë„ˆí´" â†’ ì˜¤í† ë°”ì´ í•¸ë“¤ê°€ë“œ ì»¨í…ìŠ¤íŠ¸ (ë„ˆí´ ë¬´ê¸° ì•„ë‹˜)
    'ë„ˆí´': {'í•¸ë“¤ê°€ë“œ', 'í•¸ë“¤', 'ì˜¤í† ë°”ì´', 'ë°”ì´í¬', 'ìŠ¤ì¿ í„°', 'ê°€ë“œ', 'í”„ë¡œí…í„°', 'ìœˆë“œìŠ¤í¬ë¦°'},

    # ========== ë¸Œëœë“œ í‚¤ì›Œë“œ â†’ ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ (í•­ìƒ ìœ„í—˜) ==========
    # ì´ ë¸Œëœë“œë“¤ì€ ì œí’ˆ ìœ í˜•ê³¼ ì¼ì¹˜í•˜ëŠ” ì¼ë°˜ ë‹¨ì–´ê°€ ìƒí’ˆëª…ì— ìˆì–´ë„ ìœ„í—˜
    # ì˜ˆ: "ì¼€ì´ìŠ¤í‹°íŒŒì´ ì¼€ì´ìŠ¤" â†’ ì¼€ì´ìŠ¤ ë¸Œëœë“œì´ë¯€ë¡œ ë‹¹ì—°íˆ 'ì¼€ì´ìŠ¤' ë‹¨ì–´ í¬í•¨
    # ì˜ˆ: "ìŠ¤íƒ ë¦¬ í…€ë¸”ëŸ¬" â†’ í…€ë¸”ëŸ¬ ë¸Œëœë“œì´ë¯€ë¡œ ë‹¹ì—°íˆ 'í…€ë¸”ëŸ¬' ë‹¨ì–´ í¬í•¨
    'ì¼€ì´ìŠ¤í‹°íŒŒì´': set(),
    'casetify': set(),
    'ìŠ¤íƒ ë¦¬': set(),
    'stanley': set(),
    'ì˜ˆí‹°': set(),
    'yeti': set(),
    'í•˜ì´ë“œë¡œí”Œë¼ìŠ¤í¬': set(),
    'ë¦¬ëª¨ì™€': set(),
    'rimowa': set(),
    # ë¸”ë™ë…, ë„¤ì´ì²˜í•˜ì´í¬ëŠ” ì¤‘êµ­ ë¸Œëœë“œ - ì§€ì¬ê¶Œ ë¬¸ì œ ì—†ì–´ì„œ ì œê±°
}

# ==================== ìºë¦­í„°/ë¸Œëœë“œ ìœ„í—˜ í‚¤ì›Œë“œ ====================
# PPT ìŠ¬ë¼ì´ë“œ 9,10,11,12,13,15,22,23,35,36 ì°¸ì¡°
# ìºë¦­í„° ìƒí’ˆ, ë¸Œëœë“œ ìƒí’ˆì€ ì§€ì¬ê¶Œ ìœ„í—˜ì´ ë†’ìŒ

# ìºë¦­í„° ê´€ë ¨ (PPT ìŠ¬ë¼ì´ë“œ 9)
CHARACTER_KEYWORDS = {
    'ë””ì¦ˆë‹ˆ', 'ë§ˆë¸”', 'í”½ì‚¬', 'í¬ì¼“ëª¬', 'í”¼ì¹´ì¸„',
    'ì‚°ë¦¬ì˜¤', 'í—¬ë¡œí‚¤í‹°', 'ì‹œë‚˜ëª¨ë¡¤', 'ì¿ ë¡œë¯¸', 'ë§ˆì´ë©œë¡œë””',
    'ì§±êµ¬', 'ë½€ë¡œë¡œ', 'íƒ€ìš”', 'í•‘í¬í', 'ì•„ê¸°ìƒì–´',
    'ì›í”¼ìŠ¤', 'ë‚˜ë£¨í† ', 'ê·€ë©¸ì˜ì¹¼ë‚ ', 'ì£¼ìˆ íšŒì „', 'ìŠ¤íŒŒì´íŒ¨ë°€ë¦¬',
    'ë¯¸í‚¤ë§ˆìš°ìŠ¤', 'ë¯¸ë‹ˆë§ˆìš°ìŠ¤', 'ë„ë‚ ë“œë•', 'ê³°ëŒì´í‘¸',
    'ìŠ¤í°ì§€ë°¥', 'íŒ¨íŠ¸ë¦­', 'ë¯¸ë‹ˆì–¸ì¦ˆ', 'ìŠˆí¼ë§ˆë¦¬ì˜¤',
    'ì§±êµ¬ëŠ”ëª»ë§ë ¤', 'ë„ë¼ì—ëª½', 'ì•™íŒ¡ë§¨', 'í˜¸ë¹µë§¨',
    # ê²Œì„ IP (ë¸”ë¦¬ìë“œ, ë‹Œí…ë„ ë“±)
    'ìŠ¤íƒ€í¬ë˜í”„íŠ¸', 'starcraft', 'ì €ê·¸', 'í”„ë¡œí† ìŠ¤', 'í…Œë€',
    'ì›Œí¬ë˜í”„íŠ¸', 'warcraft', 'ì›”ë“œì˜¤ë¸Œì›Œí¬ë˜í”„íŠ¸', 'wow',
    'ë””ì•„ë¸”ë¡œ', 'diablo', 'ì˜¤ë²„ì›Œì¹˜', 'overwatch',
    'ë¸”ë¦¬ìë“œ', 'blizzard',
    'ì ¤ë‹¤', 'ì ¤ë‹¤ì˜ì „ì„¤',  # ë‹Œí…ë„ (ë§í¬ ì œê±° - ì˜¤íƒ)
    'ë§ˆì¸í¬ë˜í”„íŠ¸', 'minecraft',
    'ë¦¬ê·¸ì˜¤ë¸Œë ˆì „ë“œ', 'lol', 'ë¡¤',
    # ì¤‘êµ­ ê²Œì„ IP
    'ì›ì‹ ', 'genshin', 'ë¶•ê´´', 'ëª…ì¼ë°©ì£¼', 'ì•„í¬ë‚˜ì´ì¸ ',
    # í•´ë¦¬í¬í„° (ì›Œë„ˆë¸Œë¼ë”ìŠ¤ ì§€ì¬ê¶Œ)
    'í•´ë¦¬í¬í„°', 'harrypotter', 'í˜¸ê·¸ì™€íŠ¸', 'hogwarts', 'ê·¸ë¦¬í•€ë„ë¥´', 'ìŠ¬ë¦¬ë°ë¦°', 'í›„í”Œí‘¸í”„', 'ë˜ë²ˆí´ë¡œ',
    # ì½”ìŠ¤í”„ë ˆ (ìºë¦­í„° ì§€ì¬ê¶Œ ì¹¨í•´)
    'ì½”ìŠ¤í”„ë ˆ', 'cosplay', 'ì½”ìŠ¤íŠ¬',
}

# ì—°ì˜ˆì¸/ë°©ì†¡ ê´€ë ¨ í‚¤ì›Œë“œ (PPT ìŠ¬ë¼ì´ë“œ 35 - í¼ë¸”ë¦¬ì‹œí‹°ê¶Œ ì¹¨í•´)
# ìƒí’ˆëª…ì— ì—°ì˜ˆì¸ ì´ë¦„, TV/ìœ íŠœë¸Œ ì±„ë„ ì´ë¦„ ì‚¬ìš© ê¸ˆì§€
CELEBRITY_KEYWORDS = {
    # TV í”„ë¡œê·¸ë¨ (ì˜ˆì‹œ)
    'ë‚˜í˜¼ìì‚°ë‹¤', 'ë‚˜í˜¼ì‚°', 'ì „ì°¸ì‹œ', 'ì „ì§€ì ì°¸ê²¬ì‹œì ',
    'ì‹ ì„œìœ ê¸°', 'ì‚¼ì‹œì„¸ë¼', 'ìœ¤ì‹ë‹¹', 'ê°•ì‹ë‹¹', 'ë°±ì¢…ì›',
    'ëŸ°ë‹ë§¨', 'ë¬´í•œë„ì „', 'ë†€ë©´ë­í•˜ë‹ˆ', 'ìœ í€´ì¦ˆ', 'ìœ ì¬ì„',
    'í­ì‚­ì†ì•˜ìˆ˜ë‹¤', 'ì• ìˆœì´',  # PPT ì˜ˆì‹œ

    # ìœ íŠœë²„/ì¸í”Œë£¨ì–¸ì„œ (ì˜ˆì‹œ)
    'ë¹ ë‹ˆë³´í‹€', 'ì¯”ì–‘', 'ì¹¨ì°©ë§¨', 'í’ì›”ëŸ‰', 'ìš°ì™êµ³',
    'ì´ì‚¬ë°°', 'íšŒì‚¬ì›ì—ì´', 'í¬ë‹ˆ', 'í™ì§„ê²½',

    # ì•„ì´ëŒ/ì—°ì˜ˆì¸ (ì£¼ìš”)
    'BTS', 'ë°©íƒ„ì†Œë…„ë‹¨', 'ë¸”ë™í•‘í¬', 'blackpink',
    'ì•„ì´ìœ ', 'iu', 'ë‰´ì§„ìŠ¤', 'newjeans',
}

# ==================== ì¹´í…Œê³ ë¦¬ë³„ ê²€ìˆ˜ ì„¤ì • ====================
# ê²€ìˆ˜ ë ˆë²¨: "strict" (ì—„ê²©-AIí™•ì¸), "normal" (ë³´í†µ-í”„ë¡œê·¸ë¨), "skip" (ê²€ìˆ˜ì œì™¸)

# ìœ„í—˜ ì¹´í…Œê³ ë¦¬ (ê¸°ë³¸: ì—„ê²© ê²€ìˆ˜)
# - ì§€ì¬ê¶Œ ì¹¨í•´ ìœ„í—˜ (íŒ¨ì…˜, íŒ¨ì…˜ì¡í™”)
# - íŒë§¤ê¸ˆì§€ í’ˆëª© (ìœ ì•„ìš©í’ˆ, ì˜ë£Œê¸°ê¸°)
# - ì¸ì¦ í•„ìš” í’ˆëª© (ê°€ì „, ìƒí™œê°€ì „)
DEFAULT_CATEGORY_RISK_SETTINGS = {
    # ==================== ì—„ê²© ê²€ìˆ˜ (strict) ====================
    # PPT "ì§€ì¬ê¶Œ ìœ„í—˜ ë¦¬ìŠ¤íŠ¸" ê¸°ë°˜ ì—…ë°ì´íŠ¸ (2026-01-15)

    # íŒ¨ì…˜ - ì§€ì¬ê¶Œ(ê°€í’ˆ) ìœ„í—˜ ë†’ìŒ (PPT ìŠ¬ë¼ì´ë“œ 10)
    'íŒ¨ì…˜ì˜ë¥˜': 'strict',
    'ë‚¨ì„±ì˜ë¥˜': 'strict',
    'ì—¬ì„±ì˜ë¥˜': 'strict',
    'íŒ¨ì…˜ì¡í™”': 'strict',
    'ê°€ë°©': 'strict',
    'ì§€ê°‘': 'strict',
    'ì‹œê³„': 'strict',
    'ì£¼ì–¼ë¦¬': 'strict',
    'ì•¡ì„¸ì„œë¦¬': 'strict',
    'ì‹ ë°œ': 'strict',
    'ìŠ¤ë‹ˆì»¤ì¦ˆ': 'strict',

    # ìœ ì•„/ì•„ë™ - íŒë§¤ê¸ˆì§€ í’ˆëª© (PPT ìŠ¬ë¼ì´ë“œ 1)
    'ìœ ì•„ë™': 'strict',
    'ìœ ì•„ìš©í’ˆ': 'strict',
    'ì¶œì‚°/ìœ¡ì•„': 'strict',
    'ì•„ë™ë³µ': 'strict',
    'ìœ ì•„': 'strict',
    'ì•„ë™': 'strict',
    'í‚¤ì¦ˆ': 'strict',

    # ì˜ë£Œ/ê±´ê°• - ê·œì œ í’ˆëª© (PPT ìŠ¬ë¼ì´ë“œ 34)
    'ì˜ë£Œê¸°ê¸°': 'strict',
    'ê±´ê°•ì‹í’ˆ': 'strict',
    'ê±´ê°•ìš©í’ˆ': 'strict',
    'ì˜ë£Œ': 'strict',

    # ì‹í’ˆ - ìˆ˜ì… ê·œì œ
    'ì‹í’ˆ': 'strict',

    # í™”ì¥í’ˆ - ê·œì œ í’ˆëª©
    'í™”ì¥í’ˆ': 'strict',
    'ë·°í‹°': 'strict',
    'ìŠ¤í‚¨ì¼€ì–´': 'strict',

    # ìŠ¤í¬ì¸ ìš©í’ˆ - ë¸Œëœë“œ ìœ„í—˜ ë†’ìŒ (PPT ìŠ¬ë¼ì´ë“œ 36)
    'ìŠ¤í¬ì¸ ì˜ë¥˜': 'strict',
    'ìŠ¤í¬ì¸ ì¡í™”': 'strict',
    'ê³¨í”„': 'strict',
    'ìŠ¹ë§ˆ': 'strict',

    # ë‚šì‹œ - ë¸Œëœë“œ ìœ„í—˜ (PPT ìŠ¬ë¼ì´ë“œ 4)
    'ë‚šì‹œ': 'strict',
    'ë‚šì‹œìš©í’ˆ': 'strict',

    # ìº í•‘ - ë¸Œëœë“œ ìœ„í—˜ (PPT ìŠ¬ë¼ì´ë“œ 15)
    'ìº í•‘': 'strict',
    'ìº í•‘ìš©í’ˆ': 'strict',

    # ë””ì§€í„¸/íœ´ëŒ€í° ê´€ë ¨ (PPT ìŠ¬ë¼ì´ë“œ 11,12,14,31)
    'í°ì¼€ì´ìŠ¤': 'strict',
    'íœ´ëŒ€í°ì¼€ì´ìŠ¤': 'strict',
    'ê²Œì´ë°': 'strict',
    'ê²Œì´ë°ê¸°ì–´': 'strict',
    'ì¤‘ê³ í°': 'strict',
    'íƒœë¸”ë¦¿': 'strict',

    # ìºë¦¬ì–´/ì—¬í–‰ê°€ë°© (PPT ìŠ¬ë¼ì´ë“œ 23)
    'ìºë¦¬ì–´': 'strict',
    'ì—¬í–‰ê°€ë°©': 'strict',

    # í…€ë¸”ëŸ¬ (PPT ìŠ¬ë¼ì´ë“œ 13)
    'í…€ë¸”ëŸ¬': 'strict',

    # ì´ë¶ˆ/ì¿ ì…˜ ì»¤ë²„ (PPT ìŠ¬ë¼ì´ë“œ 30 - ëª…í’ˆ íŒ¨í„´)
    'ì´ë¶ˆ': 'strict',
    'ì¹¨êµ¬': 'strict',
    'ì¿ ì…˜ì»¤ë²„': 'strict',

    # ìºë¦­í„° ìƒí’ˆ (PPT ìŠ¬ë¼ì´ë“œ 9)
    'ìºë¦­í„°': 'strict',
    'ì¸í˜•': 'strict',
    'í”¼ê·œì–´': 'strict',

    # ì•ˆì „ê´€ë ¨ (PPT ìŠ¬ë¼ì´ë“œ 18)
    'ì•ˆì „ìš©í’ˆ': 'strict',
    'êµ¬ëª…ìš©í’ˆ': 'strict',

    # ==================== ë³´í†µ ê²€ìˆ˜ (normal) ====================

    # ê°€ì „ - KCì¸ì¦ í•„ìš”
    'ê°€ì „': 'normal',
    'ìƒí™œê°€ì „': 'normal',
    'ì£¼ë°©ê°€ì „': 'normal',
    'ê³„ì ˆê°€ì „': 'normal',

    # ì¼ë°˜ ìƒí™œìš©í’ˆ
    'ìƒí™œìš©í’ˆ': 'normal',
    'ì£¼ë°©ìš©í’ˆ': 'normal',
    'ì¸í…Œë¦¬ì–´': 'normal',
    'ìˆ˜ë‚©': 'normal',
    'ì‚¬ë¬´ìš©í’ˆ': 'normal',
    'ë¬¸êµ¬': 'normal',

    # ë””ì§€í„¸ (ì¼ë°˜)
    'ë””ì§€í„¸': 'normal',
    'ì»´í“¨í„°': 'normal',
    'ëª¨ë°”ì¼': 'normal',
    'ì¹´ë©”ë¼': 'normal',

    # ìŠ¤í¬ì¸ /ë ˆì € (ì¼ë°˜)
    'ìŠ¤í¬ì¸ ': 'normal',
    'ë ˆì €': 'normal',
    'ì•„ì›ƒë„ì–´': 'normal',

    # ìë™ì°¨/ê³µêµ¬
    'ìë™ì°¨ìš©í’ˆ': 'normal',
    'ê³µêµ¬': 'normal',
    'ì‚°ì—…ìš©í’ˆ': 'normal',

    # ê°€êµ¬ - ë””ìì¸ê¶Œ ì£¼ì˜ (PPT ìŠ¬ë¼ì´ë“œ 33)
    'ê°€êµ¬': 'normal',
    'ì˜ì': 'normal',
}

# ì¹´í…Œê³ ë¦¬ ê²€ìˆ˜ ì„¤ì • íŒŒì¼
CATEGORY_RISK_FILE = "category_risk_settings.json"


def load_category_risk_settings() -> dict:
    """ì¹´í…Œê³ ë¦¬ë³„ ê²€ìˆ˜ ì„¤ì • ë¡œë“œ"""
    if os.path.exists(CATEGORY_RISK_FILE):
        try:
            with open(CATEGORY_RISK_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return DEFAULT_CATEGORY_RISK_SETTINGS.copy()


def save_category_risk_settings(settings: dict) -> bool:
    """ì¹´í…Œê³ ë¦¬ë³„ ê²€ìˆ˜ ì„¤ì • ì €ì¥"""
    try:
        with open(CATEGORY_RISK_FILE, 'w', encoding='utf-8') as f:
            json.dump(settings, f, ensure_ascii=False, indent=2)
        return True
    except:
        return False


def get_category_risk_level(category_name: str, settings: dict = None) -> str:
    """ì¹´í…Œê³ ë¦¬ì˜ ê²€ìˆ˜ ë ˆë²¨ ë°˜í™˜ (strict/normal/skip)"""
    if settings is None:
        settings = load_category_risk_settings()

    # ì •í™•í•œ ë§¤ì¹­
    if category_name in settings:
        return settings[category_name]

    # ë¶€ë¶„ ë§¤ì¹­ (ì¹´í…Œê³ ë¦¬ëª…ì— í‚¤ì›Œë“œ í¬í•¨)
    category_lower = category_name.lower()
    for key, level in settings.items():
        if key.lower() in category_lower or category_lower in key.lower():
            return level

    # ê¸°ë³¸ê°’: ë³´í†µ ê²€ìˆ˜
    return 'normal'


# ë¸Œëœë“œ í‚¤ì›Œë“œ (ê°€í’ˆ ìœ„í—˜) - í•­ìƒ ìœ„í—˜ (ì¼ë°˜ ë‹¨ì–´ë¡œ ì•ˆ ì“°ì„)
# PPT ìŠ¬ë¼ì´ë“œ 10,11,12,13,15,22,23,36 ê¸°ë°˜ ëŒ€í­ ì—…ë°ì´íŠ¸ (2026-01-15)
BRAND_KEYWORDS = {
    # ==================== ëª…í’ˆ ë¸Œëœë“œ ====================
    'êµ¬ì°Œ', 'gucci', 'ë£¨ì´ë¹„í†µ', 'louisvuitton', 'lvë°±', 'ì—ë¥´ë©”ìŠ¤', 'hermes',
    'í”„ë¼ë‹¤', 'prada', 'ë°œë Œì‹œì•„ê°€', 'balenciaga', 'ë³´í…Œê°€ë² ë„¤íƒ€', 'bottegaveneta',
    'ì…€ë¦°ëŠ', 'celine', 'ë””ì˜¬', 'dior', 'íœë””', 'fendi',
    'ì…ìƒë¡œë‘', 'ysl', 'ìƒë¡œë‘', 'ì§€ë°©ì‹œ', 'givenchy',
    'ë°œë Œí‹°ë…¸', 'valentino', 'í†°ë¸Œë¼ìš´', 'thombrowne',
    'ë§‰ìŠ¤ë§ˆë¼', 'maxmara', 'ëª½í´ë ˆì–´', 'moncler', 'ìºë‚˜ë‹¤êµ¬ìŠ¤', 'canadagoose',

    # ==================== ì‹œê³„ ë¸Œëœë“œ ====================
    'ë¡¤ë ‰ìŠ¤', 'rolex', 'ê¹Œë¥´ë ì—', 'cartier', 'íŒŒí…í•„ë¦½', 'patekphilippe',
    'ì˜¤ë°ë§ˆí”¼ê²Œ', 'audemarspiguet', 'íŒŒë„¤ë¼ì´', 'panerai',
    'ì˜¤ë©”ê°€', 'omega', 'íƒœê·¸í˜¸ì´ì–´', 'tagheuer', 'ë¸Œë¼ì´í‹€ë§', 'breitling',

    # ==================== ìŠ¤í¬ì¸ /ìŠ¤íŠ¸ë¦¿ ë¸Œëœë“œ (ê°€í’ˆ ë§ìŒ) ====================
    'ìŠ¤íˆ¬ì‹œ', 'stussy', 'ìŠˆí”„ë¦¼', 'supreme', 'ì˜¤í”„í™”ì´íŠ¸', 'offwhite',
    'ë‚˜ì´í‚¤', 'nike', 'ì•„ë””ë‹¤ìŠ¤', 'adidas', 'í“¨ë§ˆ', 'puma',
    'ë‰´ë°œë€ìŠ¤', 'newbalance', 'ì•„ì‹ìŠ¤', 'asics', 'ë¦¬ë³µ', 'reebok',
    'ë…¸ìŠ¤í˜ì´ìŠ¤', 'northface', 'íŒŒíƒ€ê³ ë‹ˆì•„', 'patagonia', 'ì•„í¬í…Œë¦­ìŠ¤', 'arcteryx',

    # ==================== í°ì¼€ì´ìŠ¤ ë¸Œëœë“œ (PPT ìŠ¬ë¼ì´ë“œ 11) ====================
    'ì¼€ì´ìŠ¤í‹°íŒŒì´', 'casetify',

    # ==================== ê²Œì´ë° ì£¼ë³€ê¸°ê¸° ë¸Œëœë“œ (PPT ìŠ¬ë¼ì´ë“œ 12) ====================
    'ë¡œì§€í…', 'logitech', 'ë ˆì´ì €', 'razer', 'ìŠ¤í‹¸ì‹œë¦¬ì¦ˆ', 'steelseries',
    'ì»¤ì„¸ì–´', 'corsair', 'í•˜ì´í¼ì—‘ìŠ¤', 'hyperx',

    # ==================== í…€ë¸”ëŸ¬ ë¸Œëœë“œ (PPT ìŠ¬ë¼ì´ë“œ 13) ====================
    'ìŠ¤íƒ ë¦¬', 'stanley', 'ì˜ˆí‹°', 'yeti', 'í•˜ì´ë“œë¡œí”Œë¼ìŠ¤í¬', 'hydroflask',
    'ìŠ¤íƒ€ë²…ìŠ¤', 'starbucks', 'ì¨ëª¨ìŠ¤', 'thermos', 'ì¡°ì•½ëŒ',

    # ==================== ìº í•‘ ë¸Œëœë“œ (PPT ìŠ¬ë¼ì´ë“œ 15) ====================
    # ë¸”ë™ë…, ë„¤ì´ì²˜í•˜ì´í¬ëŠ” ì¤‘êµ­ ë¸Œëœë“œ - ì œê±°
    'íë ˆë² ë¥´ê·¸', 'hilleberg',
    'ìŠ¤ë…¸ìš°í”¼í¬', 'snowpeak', 'msr', 'ë¹…ì•„ê·¸ë„¤ìŠ¤', 'bigagnes',
    'í—¬ë¦¬ë…¹ìŠ¤', 'helinox', 'ì½”ë² ì•„', 'kovea',

    # ==================== ìºë¦¬ì–´ ë¸Œëœë“œ (PPT ìŠ¬ë¼ì´ë“œ 23) ====================
    'ë¦¬ëª¨ì™€', 'rimowa', 'íˆ¬ë¯¸', 'tumi', 'ìƒ˜ì†Œë‚˜ì´íŠ¸', 'samsonite',

    # ==================== ë‚šì‹œ ë¸Œëœë“œ (PPT ìŠ¬ë¼ì´ë“œ 4) ====================
    'ì‹œë§ˆë…¸', 'shimano', 'ë‹¤ì´ì™€', 'daiwa', 'ì•„ë¶€ê°€ë¥´ì‹œì•„', 'abugarcia',

    # ==================== ê³¨í”„ ë¸Œëœë“œ (PPT ìŠ¬ë¼ì´ë“œ 36) ====================
    'íƒ€ì´í‹€ë¦¬ìŠ¤íŠ¸', 'titleist', 'ìº˜ëŸ¬ì›¨ì´', 'callaway', 'í…Œì¼ëŸ¬ë©”ì´ë“œ', 'taylormade',
    # 'í•‘' ì œê±° - "ìº í•‘", "ì‡¼í•‘" ë“±ì—ì„œ ì˜¤íƒ ë°œìƒ
    'pingê³¨í”„', 'ì½”ë¸Œë¼ê³¨í”„', 'ìŠ¤ë¦­ìŠ¨', 'srixon',

    # ==================== í˜¸í™˜ ìƒí’ˆ ê´€ë ¨ í‚¤ì›Œë“œ (PPT ìŠ¬ë¼ì´ë“œ 22) ====================
    # "~í˜¸í™˜", "~ìš©" í‚¤ì›Œë“œê°€ ë¸Œëœë“œëª…ê³¼ í•¨ê»˜ ìˆìœ¼ë©´ ìœ„í—˜
    'ì• í”Œí˜¸í™˜', 'ì‚¼ì„±í˜¸í™˜', 'ë‹¤ì´ìŠ¨í˜¸í™˜', 'ì•„ì´í°í˜¸í™˜', 'ê°¤ëŸ­ì‹œí˜¸í™˜',

    # ==================== IT ë¸Œëœë“œ (ì§€ì¬ê¶Œ ìœ„í—˜) ====================
    # ì• í”Œ
    'ë§¥ë¶', 'macbook', 'ì•„ì´ë§¥', 'imac', 'ì•„ì´í°', 'iphone',
    'ì•„ì´íŒ¨ë“œ', 'ipad', 'ì—ì–´íŒŸ', 'airpods', 'ì• í”Œì›Œì¹˜', 'applewatch',
    # ì‚¼ì„±
    'ê°¤ëŸ­ì‹œ', 'galaxy', 'ê°¤ëŸ­ì‹œë¶', 'galaxybook',
    # ë‹¤ì´ìŠ¨
    'ë‹¤ì´ìŠ¨', 'dyson',
    # ì†Œë‹ˆ
    'í”Œë ˆì´ìŠ¤í…Œì´ì…˜', 'playstation', 'ps5',
    # ë§ˆì´í¬ë¡œì†Œí”„íŠ¸
    'ì—‘ìŠ¤ë°•ìŠ¤', 'xbox', 'ì„œí”¼ìŠ¤', 'surface',
    # ì˜¤ë””ì˜¤ ë¸Œëœë“œ
    'ìƒ¥ì¦ˆ', 'ìƒ¥ìŠ¤', 'shokz', 'ì˜¤í”ˆëŸ°', 'openrun',  # ê³¨ì „ë„ ì´ì–´í°
    'ì—ì–´íŒŸ', 'airpods', 'ë²„ì¦ˆ', 'buds',  # ë¬´ì„ ì´ì–´í°
}

# ==================== ì˜µì…˜ ë¯¸ë¼ í‚¤ì›Œë“œ (uploader) ====================

# ê¸°ë³¸ ë¯¸ë¼ í‚¤ì›Œë“œ (íƒ€ì˜¤ë°”ì˜¤ íŒë§¤ì ë¯¸ë¼ íŒ¨í„´)
# â€» ì£¼ì˜: ì‹¤ì œ ìƒí’ˆëª…/ì˜µì…˜ëª…ì— ìì£¼ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ëŠ” ì œì™¸í•´ì•¼ í•¨
DEFAULT_BAIT_KEYWORDS = [
    # ë§ì¶¤/ì£¼ë¬¸ì œì‘ ê´€ë ¨ (í™•ì‹¤í•œ ë¯¸ë¼)
    'ë§ì¶¤ì œì‘', 'ì£¼ë¬¸ì œì‘', 'ì£¼ë¬¸ ì œì‘', 'ì œì‘ë¬¸ì˜', 'ë³„ë„ì œì‘', 'íŠ¹ë³„ì œì‘',
    'ì»¤ìŠ¤í…€ì£¼ë¬¸', 'ë§ì¶¤ì£¼ë¬¸',

    # ê³„ì•½/ì˜ˆì•½ê¸ˆ ê´€ë ¨ (í™•ì‹¤í•œ ë¯¸ë¼)
    'ê³„ì•½ê¸ˆ', 'ì„ ê¸ˆ', 'ì˜ˆì•½ê¸ˆ', 'ë³´ì¦ê¸ˆ', 'ì°©ìˆ˜ê¸ˆ',
    'ì •ê¸ˆ', 'ì”ê¸ˆ', 'ì¶”ê°€ê¸ˆ', 'ì°¨ì•¡ê²°ì œ',

    # ë¬¸ì˜/ìƒë‹´ ê´€ë ¨ - ë” êµ¬ì²´ì ìœ¼ë¡œ (ì˜¤íƒ ë°©ì§€)
    'ê³ ê°ì„¼í„°ë¬¸ì˜', 'ì—°ë½ì£¼ì„¸ìš”', 'ì „í™”ì£¼ì„¸ìš”', 'ì¹´í†¡ë¬¸ì˜',
    'ì±„íŒ…ë¬¸ì˜', 'ë¬¸ì˜ìš”ë§', 'ë¬¸ì˜í•„ìˆ˜', 'ë¨¼ì €ë¬¸ì˜', 'ìƒë‹´í›„êµ¬ë§¤',
    'ë¬¸ì˜í›„ê²°ì œ', 'ìƒë‹´í•„ìˆ˜',

    # ë¹„ê³ /ì•ˆë‚´ ê´€ë ¨ - êµ¬ì²´ì  ë¯¸ë¼ íŒ¨í„´ë§Œ
    'í•„ë…ì‚¬í•­', 'í™•ì¸í•„ìˆ˜', 'ì£¼ì˜ì‚¬í•­í•„ë…', 'ê³µì§€ì‚¬í•­',
    'ë°°ì†¡ì•ˆë‚´', 'êµí™˜ì•ˆë‚´', 'ë°˜í’ˆì•ˆë‚´', 'ì£¼ì˜ì•ˆë‚´', 'í•„ë…ì•ˆë‚´',
    'ì°¸ê³ ì‚¬í•­', 'ì•ˆë‚´ì‚¬í•­', 'ìœ ì˜ì‚¬í•­',
    # 'ì°¸ê³ ', 'ì•ˆë‚´', 'ë¹„ê³ ' ë‹¨ë…ì€ ì œê±° - ì •ìƒ ì˜µì…˜ëª…ì— ìì£¼ ë‚˜ì˜´

    # ë¶€í’ˆ/ì•¡ì„¸ì„œë¦¬ ë¯¸ë¼ - ë” êµ¬ì²´ì ìœ¼ë¡œ
    'ë¶€í’ˆë§Œ', 'ë¶€ì†í’ˆë§Œ', 'êµì²´ìš©ë¶€í’ˆ', 'ë¦¬í•„ìš©',
    'ì¶©ì „ê¸°ë§Œ', 'ì–´ëŒ‘í„°ë§Œ', 'ì„ ë§Œ', 'ì  ë”ë§Œ',
    # 'ì•¡ì„¸ì„œë¦¬' ì œê±° - ì‹¤ì œ ì•¡ì„¸ì„œë¦¬ ìƒí’ˆê³¼ í˜¼ë™

    # ìƒ˜í”Œ/í…ŒìŠ¤íŠ¸
    'ìƒ˜í”Œìš©', 'í…ŒìŠ¤íŠ¸ìš©', 'ë¬´ë£Œì²´í—˜', 'ì²´í—˜íŒ', 'ì‹œí—˜ìš©',
    # 'sample', 'test' ì œê±° - ì˜ë¬¸ ì œí’ˆëª…ì— ìì£¼ ë‚˜ì˜´

    # ì˜µì…˜ ì„ íƒ ìœ ë„ (í™•ì‹¤í•œ ë¯¸ë¼)
    'ì˜µì…˜ì„ íƒí•„ìˆ˜', 'í•„ìˆ˜ì„ íƒ', 'ì„ íƒí•„ìˆ˜', 'ìƒ‰ìƒì„ íƒí•„ìˆ˜', 'ì‚¬ì´ì¦ˆì„ íƒí•„ìˆ˜',
    'ì˜µì…˜ë¬¸ì˜', 'ì„ íƒì•ˆí•¨', 'í•´ë‹¹ì—†ìŒ', 'ì„ íƒí•˜ì„¸ìš”',

    # ë°°ì†¡/ì¶”ê°€ë¹„ìš© ê´€ë ¨
    'ë°°ì†¡ë¹„ë³„ë„', 'ì¶”ê°€ë°°ì†¡ë¹„', 'ë„ì„œì‚°ê°„ì¶”ê°€', 'ì œì£¼ì¶”ê°€',
    'ì„¤ì¹˜ë¹„ë³„ë„', 'ì¡°ë¦½ë¹„ë³„ë„', 'ì¶œì¥ë¹„ë³„ë„',

    # ê°€ê²© ë¯¸ë¼ (í™•ì‹¤í•œ ë¯¸ë¼)
    '1ì›', '10ì›', '100ì›', '0ì›',
    'ì¿ í°ì „ìš©', 'ì ë¦½ê¸ˆì „ìš©',
    # 'ë¬´ë£Œ', 'free' ì œê±° - ì •ìƒ í”„ë¡œëª¨ì…˜ê³¼ í˜¼ë™

    # ì¤‘êµ­ì–´ ë¯¸ë¼ (íƒ€ì˜¤ë°”ì˜¤) - í™•ì‹¤í•œ ê²ƒë§Œ
    'å®šåˆ¶', 'å®šåš', 'è®¢åˆ¶', 'è®¢åš',  # ë§ì¶¤ì œì‘
    'è”ç³»å®¢æœ', 'å’¨è¯¢å®¢æœ',  # ë¬¸ì˜/ìƒë‹´
    'é‚®è´¹', 'è¿è´¹',  # ë°°ì†¡ë¹„
    'æ ·å“',  # ìƒ˜í”Œ

    # ì¶”ê°€: ë²ˆì—­ ì˜¤ë¥˜/ì´ìƒí•œ ì˜µì…˜
    'í’ˆì ˆ', 'ì¬ê³ ì—†ìŒ', 'ë‹¨ì¢…', 'íŒë§¤ì¢…ë£Œ',
    'ì‚¬ì§„ì°¸ê³ ', 'ì´ë¯¸ì§€ì°¸ê³ ', 'ìƒì„¸ì°¸ê³ ',

    # ì•ˆë‚´ë¬¸/í™ë³´ë¬¸êµ¬ (ì˜µì…˜ì´ ì•„ë‹Œ í…ìŠ¤íŠ¸)
    'ì•½ì†ë“œë¦½ë‹ˆë‹¤', 'ì§„ì‹¬ìœ¼ë¡œ', 'ê°ì‚¬í•©ë‹ˆë‹¤', 'í™˜ì˜í•©ë‹ˆë‹¤',
    'ê³µì§€ì…ë‹ˆë‹¤', 'ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤', 'ì•Œë ¤ë“œë¦½ë‹ˆë‹¤', 'ë“œë¦½ë‹ˆë‹¤',
    'ê¼­ì½ì–´ì£¼ì„¸ìš”', 'ì½ì–´ì£¼ì„¸ìš”', 'í™•ì¸ë°”ëë‹ˆë‹¤', 'ë¶€íƒë“œë¦½ë‹ˆë‹¤',
    'ë§í¬ì°¸ê³ ', 'ìƒì„¸í˜ì´ì§€', 'ìƒì„¸í™•ì¸', 'í˜ì´ì§€ì°¸ê³ ',

    # íŒë§¤ì í™ë³´/ë§ˆì¼€íŒ… ë¬¸êµ¬
    'íŒ”ë¡œìš°', 'ì¦ê²¨ì°¾ê¸°', 'êµ¬ë…', 'ì¢‹ì•„ìš”', 'ì¶”ì²œì¸',
    'í• ì¸ì¿ í°', 'ì¿ í°ë°›ê¸°', 'í˜œíƒë°›ê¸°', 'ì´ë²¤íŠ¸ì°¸ì—¬',
    'ë¦¬ë·°ì´ë²¤íŠ¸', 'í¬í† ë¦¬ë·°', 'ë² ìŠ¤íŠ¸ë¦¬ë·°',
]

# ë¯¸ë¼ ì˜ˆì™¸ í‚¤ì›Œë“œ (ì´ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë¯¸ë¼ë¡œ íŒë‹¨í•˜ì§€ ì•ŠìŒ)
# "ì•ˆë‚´ì„œ í¬í•¨", "ì„¤ëª…ì„œ ì œê³µ" ë“± ì‹¤ì œ êµ¬ì„±í’ˆì„ ë‚˜íƒ€ë‚´ëŠ” ê²½ìš°
# ê²€ì¦ ê²°ê³¼ (2026-01-14): "ë°°í„°ë¦¬ 2ê°œë§Œ" = ë¯¸ë¼, "ë³¸í’ˆ + ë°°í„°ë¦¬ 2ê°œ" = ì •ìƒ
BAIT_EXCEPTION_KEYWORDS = [
    # êµ¬ì„±í’ˆ í‘œì‹œ (ì •ìƒ ì˜µì…˜)
    'í¬í•¨', 'ì œê³µ', 'ë™ë´‰', 'ì¦ì •', 'ì„¸íŠ¸', 'êµ¬ì„±', 'ì¶”ê°€', 'í•¨ê»˜',
    'í¬í•¨ëœ', 'ì œê³µë˜ëŠ”', 'ë™ë´‰ë˜ëŠ”', 'êµ¬ì„±ëœ',
    'ìˆëŠ”', 'ìˆìŒ', 'ê°–ì¶˜',
    # ì¤‘êµ­ì–´: í¬í•¨
    'ä»˜', 'å«', 'å¥—è£…', 'é…',
    # ìˆ˜ëŸ‰ í‘œí˜„ (ë³¸í’ˆê³¼ í•¨ê»˜ ì œê³µ)
    '1ê°œ', '2ê°œ', '3ê°œ', '4ê°œ', '5ê°œ',
    'ê°œì…', 'ê°œì„¸íŠ¸', 'ìŒ',
]

# ë¬¸ë§¥ ì˜ì¡´ í‚¤ì›Œë“œ (ë‹¨ë… ì‚¬ìš© ì‹œì—ë§Œ ë¯¸ë¼ë¡œ íŒì •)
# ê²€ì¦ ê²°ê³¼: "ì¼€ì´ë¸” ì •ë¦¬í•¨" = ì •ìƒ, "ì¼€ì´ë¸”ë§Œ" = ë¯¸ë¼
CONTEXT_DEPENDENT_BAIT_KEYWORDS = [
    'ì¼€ì´ë¸”', 'ì¶©ì „ê¸°', 'ì–´ëŒ‘í„°', 'ë¶€í’ˆ', 'ì•¡ì„¸ì„œë¦¬',
    'ë°°í„°ë¦¬', 'ê±°ì¹˜ëŒ€', 'ë¸Œë¼ì¼“', 'ì»¤ë„¥í„°', 'ì  ë”',
]

# ë‹¨ë… ì‚¬ìš© íŒ¨í„´ (ì´ íŒ¨í„´ì´ ìˆìœ¼ë©´ ë¯¸ë¼)
BAIT_ONLY_PATTERNS = [
    'ë§Œ', 'ìš©', 'ì „ìš©', 'ë³„ë„', 'ë‹¨í’ˆ', 'ê°œë³„',
    'ë§Œêµ¬ë§¤', 'ë§ŒíŒë§¤', 'ë§Œì£¼ë¬¸', 'ì¶”ê°€êµ¬ë§¤',
]

# ê°•ë ¥ ë¯¸ë¼ í‚¤ì›Œë“œ (ì˜ˆì™¸ ì²´í¬ ì—†ì´ ë°”ë¡œ ë¯¸ë¼ ì²˜ë¦¬)
# ì•ˆë‚´ë¬¸/í™ë³´ë¬¸êµ¬ëŠ” "ì¶”ê°€", "í¬í•¨" ë“± ì˜ˆì™¸ í‚¤ì›Œë“œê°€ ìˆì–´ë„ ë¯¸ë¼ì„
STRONG_BAIT_KEYWORDS = {
    # ì•ˆë‚´ë¬¸/í™ë³´ (ì ˆëŒ€ ë¯¸ë¼)
    'ì•½ì†ë“œë¦½ë‹ˆë‹¤', 'ì§„ì‹¬ìœ¼ë¡œ', 'ê°ì‚¬í•©ë‹ˆë‹¤', 'í™˜ì˜í•©ë‹ˆë‹¤',
    'ê³µì§€ì…ë‹ˆë‹¤', 'ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤', 'ì•Œë ¤ë“œë¦½ë‹ˆë‹¤',
    'ê¼­ì½ì–´ì£¼ì„¸ìš”', 'ì½ì–´ì£¼ì„¸ìš”', 'í™•ì¸ë°”ëë‹ˆë‹¤', 'ë¶€íƒë“œë¦½ë‹ˆë‹¤',
    # íŒë§¤ì í™ë³´/ë§ˆì¼€íŒ… (ì ˆëŒ€ ë¯¸ë¼)
    'íŒ”ë¡œìš°', 'ì¦ê²¨ì°¾ê¸°', 'êµ¬ë…í•˜ì‹œë©´', 'ì¶”ì²œì¸',
    'ì¿ í°ë°›ê¸°', 'í˜œíƒë°›ê¸°', 'ì´ë²¤íŠ¸ì°¸ì—¬',
    'ë¦¬ë·°ì´ë²¤íŠ¸', 'í¬í† ë¦¬ë·°', 'ë² ìŠ¤íŠ¸ë¦¬ë·°',
    # ë§ˆì¼€íŒ… ë¬¸êµ¬ (ì ˆëŒ€ ë¯¸ë¼)
    'í•œì •ì œì¡°', 'í•œì • ì œì¡°', 'ì†í•´ë³´ëŠ”', 'ì†í•´íŒë§¤', 'ì¸ë¯¼ë³´í—˜', 'í™˜ë¶ˆë³´ì¥',
    'ì œì¡°ì‚¬ì†í•´', 'ì œì¡°ì‚¬ ì†í•´', 'í•œì •íŒë§¤', 'ì˜ìˆ˜ì¦í™•ì¸', 'ì˜ìˆ˜ì¦ í™•ì¸',
}


# ==================== í‚¤ì›Œë“œ íŒŒì¼ ê´€ë¦¬ ====================

def load_banned_words() -> Tuple[Set[str], dict]:
    """ê¸ˆì§€ë‹¨ì–´ íŒŒì¼ ë¡œë“œ (ì—¬ëŸ¬ JSON í˜•íƒœ ì§€ì›)"""
    if os.path.exists(BANNED_WORDS_FILE):
        try:
            with open(BANNED_WORDS_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                all_words = set()

                # Case 1: ë‹¨ìˆœ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ
                if isinstance(data, list):
                    all_words.update(data)
                    return all_words, {"words": data}

                # Case 2: {"words": [...]} í˜•íƒœ
                if isinstance(data, dict) and 'words' in data:
                    words = data.get('words', [])
                    if isinstance(words, list):
                        all_words.update(words)

                # Case 3: {"categories": {...}} í˜•íƒœ
                if isinstance(data, dict) and 'categories' in data:
                    categories = data.get('categories', {})
                    if isinstance(categories, dict):
                        for cat_data in categories.values():
                            if isinstance(cat_data, dict):
                                words = cat_data.get('words', [])
                                if isinstance(words, list):
                                    all_words.update(words)
                            elif isinstance(cat_data, list):
                                all_words.update(cat_data)

                # Case 4: AI ê°ì§€ ë‹¨ì–´
                if isinstance(data, dict) and 'ai_detected' in data:
                    ai_detected = data.get('ai_detected', {})
                    if isinstance(ai_detected, dict):
                        approved = ai_detected.get('approved', [])
                        if isinstance(approved, list):
                            all_words.update(approved)

                return all_words, data
        except Exception as e:
            print(f"ê¸ˆì§€ë‹¨ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return set(), {}


def save_banned_words(words: Set[str], data: dict = None) -> bool:
    """ê¸ˆì§€ë‹¨ì–´ íŒŒì¼ ì €ì¥"""
    try:
        if data is None:
            data = {"words": sorted(list(words))}
        else:
            data["words"] = sorted(list(words))
        with open(BANNED_WORDS_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"ê¸ˆì§€ë‹¨ì–´ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def load_excluded_words() -> Set[str]:
    """ì˜ˆì™¸ë‹¨ì–´ íŒŒì¼ ë¡œë“œ (íƒì§€ ì œì™¸)"""
    if os.path.exists(EXCLUDED_WORDS_FILE):
        try:
            with open(EXCLUDED_WORDS_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return set(data.get('words', []))
        except Exception as e:
            print(f"ì˜ˆì™¸ë‹¨ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return set()


def save_excluded_words(words: Set[str]) -> bool:
    """ì˜ˆì™¸ë‹¨ì–´ íŒŒì¼ ì €ì¥"""
    try:
        data = {'words': sorted(list(words))}
        with open(EXCLUDED_WORDS_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"ì˜ˆì™¸ë‹¨ì–´ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def load_remove_words() -> Set[str]:
    """ì œê±°ë‹¨ì–´ íŒŒì¼ ë¡œë“œ (ìƒí’ˆëª…ì—ì„œ ë¬´ì¡°ê±´ ì‚­ì œ)"""
    if os.path.exists(REMOVE_WORDS_FILE):
        try:
            with open(REMOVE_WORDS_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return set(data.get('words', []))
        except Exception as e:
            print(f"ì œê±°ë‹¨ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return set()


def save_remove_words(words: Set[str]) -> bool:
    """ì œê±°ë‹¨ì–´ íŒŒì¼ ì €ì¥"""
    try:
        data = {'words': sorted(list(words))}
        with open(REMOVE_WORDS_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"ì œê±°ë‹¨ì–´ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def load_bait_keywords() -> List[str]:
    """ë¯¸ë¼ì˜µì…˜ í‚¤ì›Œë“œ ë¡œë“œ"""
    if os.path.exists(BAIT_KEYWORDS_FILE):
        try:
            with open(BAIT_KEYWORDS_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('keywords', DEFAULT_BAIT_KEYWORDS[:])
        except Exception as e:
            print(f"ë¯¸ë¼í‚¤ì›Œë“œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return DEFAULT_BAIT_KEYWORDS[:]


def save_bait_keywords(keywords: List[str]) -> bool:
    """ë¯¸ë¼ì˜µì…˜ í‚¤ì›Œë“œ ì €ì¥"""
    try:
        data = {'keywords': keywords}
        with open(BAIT_KEYWORDS_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"ë¯¸ë¼í‚¤ì›Œë“œ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


# ==================== Google Sheets ë™ê¸°í™” ====================

def sync_from_google_sheets(sheet_url: str, log_callback=None) -> dict:
    """
    Google Sheetsì—ì„œ ê¸ˆì§€ë‹¨ì–´/ì˜ˆì™¸ë‹¨ì–´/ì œê±°ë‹¨ì–´ ë™ê¸°í™”

    ì‹œíŠ¸ í˜•ì‹ (bulsaja_words ì‹œíŠ¸):
    - Aì—´: ê¸ˆì§€ë‹¨ì–´
    - Bì—´: ì˜ˆì™¸ë‹¨ì–´ (íƒì§€ ì œì™¸)
    - Cì—´: ì œê±°ë‹¨ì–´
    - Dì—´: ë¯¸ë¼í‚¤ì›Œë“œ (ì˜µì…˜ í•„í„°ìš©)

    Returns: {'banned': [...], 'excluded': [...], 'remove': [...], 'bait': [...], 'success': bool, 'message': str}
    """
    result = {'banned': [], 'excluded': [], 'remove': [], 'bait': [], 'success': False, 'message': ''}

    try:
        import gspread
        from google.oauth2.service_account import Credentials
    except ImportError:
        result['message'] = "gspread ë˜ëŠ” google-auth íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤"
        if log_callback:
            log_callback(f"âŒ {result['message']}")
        return result

    try:
        # ì„œë¹„ìŠ¤ ê³„ì • JSON íŒŒì¼ ì°¾ê¸°
        service_account_file = None
        for filename in os.listdir('.'):
            if filename.endswith('.json') and 'auto-smartstore' in filename.lower():
                service_account_file = filename
                break

        if not service_account_file:
            possible_files = ['auto-smartstore-update-61c3a948c45c.json', 'service_account.json', 'credentials.json']
            for pf in possible_files:
                if os.path.exists(pf):
                    service_account_file = pf
                    break

        if not service_account_file:
            result['message'] = "ì„œë¹„ìŠ¤ ê³„ì • JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            if log_callback:
                log_callback(f"âŒ {result['message']}")
            return result

        if log_callback:
            log_callback(f"ğŸ“¥ ì‹œíŠ¸ ì—°ê²° ì¤‘... ({service_account_file})")

        # Google Sheets API ì¸ì¦
        scopes = [
            'https://www.googleapis.com/auth/spreadsheets',
            'https://www.googleapis.com/auth/drive'
        ]
        creds = Credentials.from_service_account_file(service_account_file, scopes=scopes)
        gc = gspread.authorize(creds)

        # Sheet ID ì¶”ì¶œ
        if '/d/' in sheet_url:
            sheet_id = sheet_url.split('/d/')[1].split('/')[0]
        else:
            sheet_id = sheet_url

        spreadsheet = gc.open_by_key(sheet_id)

        # bulsaja_words ì‹œíŠ¸ ì°¾ê¸°
        try:
            worksheet = spreadsheet.worksheet('bulsaja_words')
        except:
            worksheet = spreadsheet.sheet1

        all_values = worksheet.get_all_values()

        banned_words = []
        excluded_words = []
        remove_words = []
        bait_keywords = []

        for row_num, row in enumerate(all_values):
            if row_num == 0:  # í—¤ë” ìŠ¤í‚µ
                continue

            # Aì—´: ê¸ˆì§€ë‹¨ì–´
            if len(row) >= 1 and row[0].strip():
                banned_words.append(row[0].strip())

            # Bì—´: ì˜ˆì™¸ë‹¨ì–´
            if len(row) >= 2 and row[1].strip():
                excluded_words.append(row[1].strip())

            # Cì—´: ì œê±°ë‹¨ì–´
            if len(row) >= 3 and row[2].strip():
                remove_words.append(row[2].strip())

            # Dì—´: ë¯¸ë¼í‚¤ì›Œë“œ
            if len(row) >= 4 and row[3].strip():
                bait_keywords.append(row[3].strip())

        result['banned'] = banned_words
        result['excluded'] = excluded_words
        result['remove'] = remove_words
        result['bait'] = bait_keywords
        result['success'] = True
        result['message'] = f"ê¸ˆì§€ {len(banned_words)}ê°œ, ì˜ˆì™¸ {len(excluded_words)}ê°œ, ì œê±° {len(remove_words)}ê°œ, ë¯¸ë¼ {len(bait_keywords)}ê°œ"

        if log_callback:
            log_callback(f"âœ… {result['message']}")

    except Exception as e:
        result['message'] = f"ë™ê¸°í™” ì‹¤íŒ¨: {e}"
        if log_callback:
            log_callback(f"âŒ {result['message']}")

    return result


# ==================== ì¸ë„¤ì¼ ë§¤ì¹­ ìœ í‹¸ ====================

def extract_image_id(url: str) -> str:
    """ì´ë¯¸ì§€ URLì—ì„œ ê³ ìœ  ID ì¶”ì¶œ (íŒŒì¼ëª…)"""
    if not url:
        return ""
    try:
        parsed = urlparse(url)
        path = parsed.path
        filename = path.split('/')[-1] if '/' in path else path
        name_part = filename.rsplit('.', 1)[0] if '.' in filename else filename
        return name_part
    except:
        return url


def match_thumbnail_to_sku(thumbnails: List[str], skus: List[Dict]) -> Optional[int]:
    """
    ëŒ€í‘œ ì¸ë„¤ì¼ê³¼ ë§¤ì¹­ë˜ëŠ” SKU ì¸ë±ìŠ¤ ì°¾ê¸°

    Args:
        thumbnails: uploadThumbnails ë°°ì—´ (ì²« ë²ˆì§¸ê°€ ëŒ€í‘œ ì´ë¯¸ì§€)
        skus: uploadSkus ë°°ì—´

    Returns:
        ë§¤ì¹­ë˜ëŠ” SKU ì¸ë±ìŠ¤ ë˜ëŠ” None
    """
    if not thumbnails or not skus:
        return None

    # ëŒ€í‘œ ì¸ë„¤ì¼ ID ì¶”ì¶œ (ì²« ë²ˆì§¸ ì´ë¯¸ì§€)
    main_thumb_id = extract_image_id(thumbnails[0])
    if not main_thumb_id:
        return None

    # ê° SKUì˜ ì´ë¯¸ì§€ì™€ ë¹„êµ
    for idx, sku in enumerate(skus):
        sku_image_url = sku.get('urlRef') or sku.get('image') or ''
        if not sku_image_url:
            continue

        sku_image_id = extract_image_id(sku_image_url)

        # ì´ë¯¸ì§€ IDê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ë§¤ì¹­
        if main_thumb_id in sku_image_id or sku_image_id in main_thumb_id:
            return idx

    # 2ì°¨ ì‹œë„: alicdn ì´ë¯¸ì§€ë¼ë¦¬ íŒŒì¼ëª… ë¹„êµ
    main_thumb_url = thumbnails[0].lower()
    for idx, sku in enumerate(skus):
        sku_image_url = (sku.get('urlRef') or sku.get('image') or '').lower()
        if not sku_image_url:
            continue
        if 'alicdn.com' in main_thumb_url and 'alicdn.com' in sku_image_url:
            main_file = main_thumb_url.split('/')[-1]
            sku_file = sku_image_url.split('/')[-1]
            if main_file == sku_file:
                return idx

    # 3ì°¨ ì‹œë„: ë¶ˆì‚¬ì CDN ê²½ë¡œì˜ ìƒí’ˆ ID ë¹„êµ
    # ì¸ë„¤ì¼: https://cdn.bulsaja.com/.../U01KEXGVBGHXQ9FPKZGX2NT18RK/...
    # SKU: https://cdn.bulsaja.com/.../U01KEXGVBGHXQ9FPKZGX2.../...
    if 'cdn.bulsaja.com' in main_thumb_url:
        # ì¸ë„¤ì¼ì—ì„œ ìƒí’ˆ ID ì¶”ì¶œ (U01Kë¡œ ì‹œì‘í•˜ëŠ” ë¶€ë¶„)
        main_parts = main_thumb_url.split('/')
        main_product_id = None
        for part in main_parts:
            if part.startswith('u01k'):
                main_product_id = part
                break

        if main_product_id:
            for idx, sku in enumerate(skus):
                sku_url = (sku.get('urlRef') or '').lower()
                if main_product_id in sku_url:
                    return idx

    return None


# ==================== ìƒí’ˆëª… ê¸°ë°˜ ëŒ€í‘œì˜µì…˜ ë§¤ì¹­ ====================

def match_option_by_product_name(product_name: str, skus: List[Dict]) -> Tuple[Optional[int], float, str]:
    """
    ìƒí’ˆëª…ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ëŒ€í‘œì˜µì…˜ ì°¾ê¸°

    íƒ€ì˜¤ë°”ì˜¤ ìƒí’ˆëª… íŒ¨í„´:
    - "ê²€ì •ìƒ‰ ê°€ì£½ ì†ŒíŒŒ 3ì¸ìš©" â†’ ìƒ‰ìƒ(ê²€ì •), ì¬ì§ˆ(ê°€ì£½), í¬ê¸°(3ì¸ìš©)
    - "í™”ì´íŠ¸ Lì‚¬ì´ì¦ˆ ë©´ í‹°ì…”ì¸ " â†’ ìƒ‰ìƒ(í™”ì´íŠ¸), ì‚¬ì´ì¦ˆ(L), ì¬ì§ˆ(ë©´)

    Args:
        product_name: ìƒí’ˆëª…
        skus: SKU ë°°ì—´

    Returns:
        (ë§¤ì¹­ëœ SKU ì¸ë±ìŠ¤, ë§¤ì¹­ë¥ , ë§¤ì¹­ ì´ìœ ) ë˜ëŠ” (None, 0, '')
    """
    if not product_name or not skus:
        return None, 0.0, ''

    product_name_lower = product_name.lower()

    # ìƒ‰ìƒ í‚¤ì›Œë“œ (í•œêµ­ì–´/ì˜ì–´/ì¤‘êµ­ì–´)
    COLOR_KEYWORDS = {
        # í•œêµ­ì–´
        'ê²€ì •', 'ê²€ì€', 'ë¸”ë™', 'í‘ìƒ‰', 'ê¹Œë§Œ',
        'í°ìƒ‰', 'í•˜ì–€', 'í™”ì´íŠ¸', 'ë°±ìƒ‰',
        'ë¹¨ê°•', 'ë¹¨ê°„', 'ë ˆë“œ', 'ì ìƒ‰',
        'íŒŒë‘', 'íŒŒë€', 'ë¸”ë£¨', 'ì²­ìƒ‰', 'ë„¤ì´ë¹„',
        'ë…¸ë‘', 'ë…¸ë€', 'ì˜ë¡œìš°', 'í™©ìƒ‰',
        'ì´ˆë¡', 'ê·¸ë¦°', 'ë…¹ìƒ‰',
        'ë¶„í™', 'í•‘í¬',
        'ë³´ë¼', 'í¼í”Œ', 'ë°”ì´ì˜¬ë ›',
        'ì£¼í™©', 'ì˜¤ë Œì§€',
        'ê°ˆìƒ‰', 'ë¸Œë¼ìš´', 'ì¹´í‚¤',
        'íšŒìƒ‰', 'ê·¸ë ˆì´', 'ì‹¤ë²„', 'ì€ìƒ‰',
        'ê¸ˆìƒ‰', 'ê³¨ë“œ',
        'ë² ì´ì§€', 'ì•„ì´ë³´ë¦¬', 'í¬ë¦¼',
        # ì˜ì–´
        'black', 'white', 'red', 'blue', 'navy', 'yellow', 'green',
        'pink', 'purple', 'orange', 'brown', 'gray', 'grey', 'silver', 'gold',
        'beige', 'ivory', 'cream', 'khaki',
        # ì¤‘êµ­ì–´
        'é»‘', 'ç™½', 'çº¢', 'è“', 'é»„', 'ç»¿', 'ç²‰', 'ç´«', 'æ©™', 'æ£•', 'ç°', 'é“¶', 'é‡‘',
    }

    # ì‚¬ì´ì¦ˆ í‚¤ì›Œë“œ
    SIZE_KEYWORDS = {
        'xs', 's', 'm', 'l', 'xl', 'xxl', 'xxxl',
        'ì†Œ', 'ì¤‘', 'ëŒ€', 'íŠ¹ëŒ€',
        'small', 'medium', 'large',
        '1ì¸ìš©', '2ì¸ìš©', '3ì¸ìš©', '4ì¸ìš©',
        'ì‹±ê¸€', 'ë”ë¸”', 'í€¸', 'í‚¹',
    }

    # ìƒí’ˆëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    found_colors = []
    found_sizes = []

    for color in COLOR_KEYWORDS:
        if color in product_name_lower:
            found_colors.append(color)

    for size in SIZE_KEYWORDS:
        if size in product_name_lower:
            found_sizes.append(size)

    # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ë§¤ì¹­ ë¶ˆê°€
    if not found_colors and not found_sizes:
        return None, 0.0, 'í‚¤ì›Œë“œì—†ìŒ'

    # ê° SKUì™€ ë§¤ì¹­ë¥  ê³„ì‚°
    best_idx = None
    best_score = 0.0
    best_reason = ''

    for idx, sku in enumerate(skus):
        option_text = (sku.get('text_ko', '') or sku.get('text', '')).lower()
        if not option_text:
            continue

        score = 0.0
        matched_keywords = []

        # ìƒ‰ìƒ ë§¤ì¹­ (ê°€ì¤‘ì¹˜ ë†’ìŒ)
        for color in found_colors:
            if color in option_text:
                score += 2.0
                matched_keywords.append(f'ìƒ‰ìƒ:{color}')

        # ì‚¬ì´ì¦ˆ ë§¤ì¹­
        for size in found_sizes:
            if size in option_text:
                score += 1.5
                matched_keywords.append(f'ì‚¬ì´ì¦ˆ:{size}')

        # ì ìˆ˜ê°€ ë†’ìœ¼ë©´ ê°±ì‹ 
        if score > best_score:
            best_score = score
            best_idx = idx
            best_reason = ', '.join(matched_keywords)

    # ìµœì†Œ ë§¤ì¹­ ì ìˆ˜ ê¸°ì¤€ (ìƒ‰ìƒ 1ê°œ ì´ìƒ ë§¤ì¹­)
    if best_score >= 2.0:
        # ë§¤ì¹­ë¥  ê³„ì‚°: ì°¾ì€ í‚¤ì›Œë“œ ìˆ˜ ëŒ€ë¹„ ë§¤ì¹­ëœ ë¹„ìœ¨
        total_keywords = len(found_colors) + len(found_sizes)
        match_rate = best_score / (total_keywords * 2.0) if total_keywords > 0 else 0
        return best_idx, min(match_rate, 1.0), best_reason

    return None, 0.0, ''


def select_main_option(product_name: str, skus: List[Dict]) -> Tuple[int, str]:
    """
    ëŒ€í‘œì˜µì…˜ ì„ íƒ (ì´ë¯¸ì§€ ìš°ì„  â†’ ìƒí’ˆëª… ë§¤ì¹­ â†’ ì²« ë²ˆì§¸ ì˜µì…˜)

    ìš°ì„ ìˆœìœ„:
    1. ìƒí’ˆëª… ê¸°ë°˜ ë§¤ì¹­ (ì´ë¯¸ì§€ ìˆëŠ” ì˜µì…˜ ìš°ì„ )
    2. ì´ë¯¸ì§€ê°€ ìˆëŠ” ì²« ë²ˆì§¸ ì˜µì…˜
    3. ì²« ë²ˆì§¸ ì˜µì…˜

    Args:
        product_name: ìƒí’ˆëª…
        skus: ë¯¸ë¼ í•„í„°ë§ëœ SKU ë°°ì—´

    Returns:
        (ì„ íƒëœ SKU ì¸ë±ìŠ¤, ì„ íƒ ë°©ë²•)
    """
    if not skus:
        return 0, 'ì˜µì…˜ì—†ìŒ'

    def has_image(sku: Dict) -> bool:
        """SKUì— ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸"""
        return bool(sku.get('urlRef') or sku.get('image') or sku.get('img'))

    # 1. ìƒí’ˆëª… ê¸°ë°˜ ë§¤ì¹­ ì‹œë„
    matched_idx, match_rate, reason = match_option_by_product_name(product_name, skus)

    if matched_idx is not None and match_rate >= 0.3:
        # ë§¤ì¹­ëœ ì˜µì…˜ì— ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if has_image(skus[matched_idx]):
            return matched_idx, f'ìƒí’ˆëª…ë§¤ì¹­({reason})'
        # ì´ë¯¸ì§€ ì—†ìœ¼ë©´ ì´ë¯¸ì§€ ìˆëŠ” ì˜µì…˜ ì¤‘ì—ì„œ ì°¾ê¸°
        for idx, sku in enumerate(skus):
            if has_image(sku):
                return idx, 'ì´ë¯¸ì§€ìš°ì„ '

    # 2. ì´ë¯¸ì§€ê°€ ìˆëŠ” ì²« ë²ˆì§¸ ì˜µì…˜
    for idx, sku in enumerate(skus):
        if has_image(sku):
            return idx, 'ì´ë¯¸ì§€ìš°ì„ '

    # 3. í´ë°±: ì²« ë²ˆì§¸ ì˜µì…˜
    return 0, 'ì²«ë²ˆì§¸ì˜µì…˜'


# ==================== ìƒí’ˆ ê²€ì‚¬ ìœ í‹¸ ====================

def check_product_safety(title: str, excluded_words: Set[str] = None,
                         use_ai_fallback: bool = False, ai_config: dict = None,
                         check_level: str = 'normal', category_name: str = None) -> dict:
    """
    ìƒí’ˆëª…ì—ì„œ ìœ„í—˜ í‚¤ì›Œë“œ ê²€ì‚¬ (ë¬¸ë§¥ ê¸°ë°˜ íŒë‹¨ + AI í´ë°±)

    ë¡œì§:
    1. ìœ„í—˜ í‚¤ì›Œë“œ íƒì§€
    2. í•´ë‹¹ í‚¤ì›Œë“œì— ëŒ€í•œ ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
       - KEYWORD_SAFE_CONTEXT_MAPì— ì •ì˜ëœ í‚¤ì›Œë“œë³„ ì»¨í…ìŠ¤íŠ¸ ìš°ì„  í™•ì¸
       - ì—†ìœ¼ë©´ ì¼ë°˜ SAFE_CONTEXT_KEYWORDSë¡œ í™•ì¸
    3. ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ â†’ í•´ë‹¹ ìœ„í—˜ í‚¤ì›Œë“œë§Œ ë¬´ì‹œ
    4. ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ ì—†ìœ¼ë©´ â†’ ìœ„í—˜ ìƒí’ˆ
    5. (ì˜µì…˜) AI í´ë°±: í”„ë¡œê·¸ë¨ íŒë‹¨ ë¶ˆê°€ ì‹œ AIì—ê²Œ ë¬¸ì˜

    ì˜ˆì‹œ:
    - "ì½˜í¬ë¦¬íŠ¸ ë°”ì´ë¸Œë ˆì´í„°" â†’ ë°”ì´ë¸Œë ˆì´í„°ì˜ ì•ˆì „ ì»¨í…ìŠ¤íŠ¸(ì½˜í¬ë¦¬íŠ¸) ìˆìŒ â†’ ì •ìƒ
    - "ì„±ì¸ìš©í’ˆ ë°”ì´ë¸Œë ˆì´í„°" â†’ ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ â†’ ìœ„í—˜

    Args:
        title: ìƒí’ˆëª…
        excluded_words: ì œì™¸í•  í‚¤ì›Œë“œ (ì´ë¯¸ ê²€ì¦ëœ í‚¤ì›Œë“œ)
        use_ai_fallback: Trueë©´ íŒë‹¨ ë¶ˆê°€ ì‹œ AIì—ê²Œ ë¬¸ì˜ (deprecated, use check_level)
        ai_config: AI ì„¤ì • (Noneì´ë©´ íŒŒì¼ì—ì„œ ë¡œë“œ)
        check_level: ê²€ìˆ˜ ë ˆë²¨
            - 'strict': ì—„ê²© (AI í™•ì¸ í•„ìˆ˜, ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ ìˆì–´ë„ AI ê²€ì¦)
            - 'normal': ë³´í†µ (í”„ë¡œê·¸ë¨ ìë™ íŒë‹¨, ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ ì ìš©)
            - 'skip': ê²€ìˆ˜ ì œì™¸ (í•­ìƒ ì•ˆì „)
        category_name: ì¹´í…Œê³ ë¦¬ëª… (ìë™ìœ¼ë¡œ check_level ê²°ì •ì— ì‚¬ìš©)

    Returns:
        {
            'is_safe': bool,
            'categories': {
                'adult': [...],
                'medical': [...],
                'child': [...],
                'prohibited': [...]
            },
            'all_found': [],
            'safe_context_found': [],  # ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ë¡œ íŒë‹¨ëœ í‚¤ì›Œë“œ
            'ai_judgment': [],  # AI íŒë‹¨ ê²°ê³¼ (strict ëª¨ë“œì¼ ë•Œ)
            'check_level': str  # ì‚¬ìš©ëœ ê²€ìˆ˜ ë ˆë²¨
        }
    """
    if excluded_words is None:
        excluded_words = set()

    # ì¹´í…Œê³ ë¦¬ëª…ìœ¼ë¡œ ê²€ìˆ˜ ë ˆë²¨ ìë™ ê²°ì • (ëª…ì‹œì  ì§€ì •ì´ ì—†ì„ ë•Œ)
    if category_name and check_level == 'normal':
        check_level = get_category_risk_level(category_name)

    # use_ai_fallback í˜¸í™˜ì„± (deprecated)
    if use_ai_fallback and check_level == 'normal':
        check_level = 'strict'

    result = {
        'is_safe': True,
        'categories': {
            'adult': [],
            'medical': [],
            'child': [],
            'prohibited': [],
            'brand': []  # ë¸Œëœë“œ (ê°€í’ˆ ìœ„í—˜)
        },
        'all_found': [],
        'safe_context_found': [],
        'ai_judgment': [],
        'check_level': check_level  # ì‚¬ìš©ëœ ê²€ìˆ˜ ë ˆë²¨ ê¸°ë¡
    }

    # skip ëª¨ë“œ: ê²€ìˆ˜ ì œì™¸ (í•­ìƒ ì•ˆì „)
    if check_level == 'skip':
        return result

    title_lower = title.lower()

    # ìƒí’ˆëª…ì—ì„œ ë°œê²¬ëœ ëª¨ë“  ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ ìˆ˜ì§‘
    found_safe_contexts = set()
    for safe_kw in SAFE_CONTEXT_KEYWORDS:
        if safe_kw in title_lower:
            found_safe_contexts.add(safe_kw)

    # AI íŒë‹¨ì´ í•„ìš”í•œ í‚¤ì›Œë“œ ìˆ˜ì§‘ (í”„ë¡œê·¸ë¨ìœ¼ë¡œ íŒë‹¨ ë¶ˆê°€)
    keywords_need_ai = []

    def check_keyword(keyword: str, category_list: list):
        """í‚¤ì›Œë“œ ì²´í¬ (ë¬¸ë§¥ íŒë‹¨ í¬í•¨)"""
        if keyword in excluded_words or keyword.lower() in excluded_words:
            return

        keyword_lower = keyword.lower()
        if keyword_lower not in title_lower:
            return

        # ìœ„í—˜ í‚¤ì›Œë“œ ë°œê²¬ë¨ â†’ ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ í™•ì¸

        # 1. í‚¤ì›Œë“œë³„ ì „ìš© ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ í™•ì¸
        keyword_specific_contexts = KEYWORD_SAFE_CONTEXT_MAP.get(keyword_lower, None)

        if keyword_specific_contexts is not None:
            # í‚¤ì›Œë“œë³„ ì „ìš© ì»¨í…ìŠ¤íŠ¸ê°€ ì •ì˜ë˜ì–´ ìˆìŒ
            if len(keyword_specific_contexts) == 0:
                # ë¹ˆ set = ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ (í•­ìƒ ìœ„í—˜)
                category_list.append(keyword)
                return

            # ì „ìš© ì»¨í…ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ë¼ë„ ìƒí’ˆëª…ì— ìˆëŠ”ì§€ ì§ì ‘ í™•ì¸
            matched_contexts = []
            for ctx in keyword_specific_contexts:
                if ctx.lower() in title_lower:
                    matched_contexts.append(ctx)

            if matched_contexts:
                # ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ ë§¤ì¹­ë¨
                if check_level == 'strict':
                    # ì—„ê²© ëª¨ë“œ: ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ ìˆì–´ë„ AI ê²€ì¦ í•„ìš”
                    keywords_need_ai.append((keyword, f"ì»¨í…ìŠ¤íŠ¸:{','.join(matched_contexts[:2])}"))
                else:
                    # ë³´í†µ ëª¨ë“œ: ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ë¡œ ì •ìƒ ì²˜ë¦¬
                    result['safe_context_found'].append(f"{keyword}â†’{','.join(matched_contexts[:2])}")
                return
            else:
                # ì „ìš© ì»¨í…ìŠ¤íŠ¸ì— ë§¤ì¹­ ì•ˆë¨ â†’ AI íŒë‹¨ í•„ìš” ë˜ëŠ” ìœ„í—˜
                if check_level == 'strict':
                    keywords_need_ai.append((keyword, "ì»¨í…ìŠ¤íŠ¸ì—†ìŒ"))
                else:
                    category_list.append(keyword)
                return

        # 2. ì¼ë°˜ ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ í™•ì¸ (í‚¤ì›Œë“œë³„ ì •ì˜ ì—†ì„ ë•Œ)
        if found_safe_contexts:
            # ì¼ë°˜ ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìŒ
            if check_level == 'strict':
                # ì—„ê²© ëª¨ë“œ: AI ê²€ì¦ í•„ìš”
                keywords_need_ai.append((keyword, f"ì¼ë°˜ì»¨í…ìŠ¤íŠ¸:{','.join(list(found_safe_contexts)[:2])}"))
            else:
                # ë³´í†µ ëª¨ë“œ: ì •ìƒìœ¼ë¡œ ì²˜ë¦¬
                result['safe_context_found'].append(f"{keyword}â†’{','.join(list(found_safe_contexts)[:2])}")
        else:
            # ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ â†’ ìœ„í—˜
            category_list.append(keyword)

    # ê° ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì²´í¬
    for keyword in ADULT_KEYWORDS:
        check_keyword(keyword, result['categories']['adult'])

    for keyword in MEDICAL_KEYWORDS:
        check_keyword(keyword, result['categories']['medical'])

    for keyword in CHILD_KEYWORDS:
        check_keyword(keyword, result['categories']['child'])

    for keyword in PROHIBITED_KEYWORDS:
        check_keyword(keyword, result['categories']['prohibited'])

    # ë¸Œëœë“œ í‚¤ì›Œë“œ ì²´í¬ (ê°€í’ˆ ìœ„í—˜)
    for keyword in BRAND_KEYWORDS:
        check_keyword(keyword, result['categories']['brand'])

    # ìºë¦­í„° í‚¤ì›Œë“œ ì²´í¬ (PPT ìŠ¬ë¼ì´ë“œ 9: ì§€ì¬ê¶Œ ìœ„í—˜)
    for keyword in CHARACTER_KEYWORDS:
        if keyword.lower() in title_lower and keyword not in excluded_words:
            result['categories']['brand'].append(f"ìºë¦­í„°:{keyword}")

    # ì—°ì˜ˆì¸/ë°©ì†¡ í‚¤ì›Œë“œ ì²´í¬ (PPT ìŠ¬ë¼ì´ë“œ 35: í¼ë¸”ë¦¬ì‹œí‹°ê¶Œ ì¹¨í•´)
    for keyword in CELEBRITY_KEYWORDS:
        if keyword.lower() in title_lower and keyword not in excluded_words:
            result['categories']['prohibited'].append(f"ì—°ì˜ˆì¸/ë°©ì†¡:{keyword}")

    # AI ê²€ì¦: strict ëª¨ë“œ ë˜ëŠ” use_ai_fallbackì¼ ë•Œ AIì—ê²Œ ë¬¸ì˜
    if (check_level == 'strict' or use_ai_fallback) and keywords_need_ai:
        for item in keywords_need_ai:
            # ìƒˆ í˜•ì‹: (keyword, context_info) ë˜ëŠ” ì´ì „ í˜•ì‹: keywordë§Œ
            if isinstance(item, tuple):
                keyword, context_info = item
            else:
                keyword = item
                context_info = ""

            is_safe, reason = check_product_safety_with_ai(title, keyword, ai_config)
            result['ai_judgment'].append(f"{keyword}({context_info}): {reason}")

            # AI í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ (reasonì— "ì‹¤íŒ¨" í¬í•¨)
            if 'API í‚¤' in reason or 'ì‹¤íŒ¨' in reason or 'ì˜¤ë¥˜' in reason:
                # ì»¨í…ìŠ¤íŠ¸ê°€ ìˆì—ˆìœ¼ë©´ ì •ìƒ ì²˜ë¦¬, ì—†ìœ¼ë©´ ìœ„í—˜ ì²˜ë¦¬
                if 'ì»¨í…ìŠ¤íŠ¸:' in context_info:
                    result['safe_context_found'].append(f"{keyword}(AIë¯¸ì‚¬ìš©)â†’{context_info}")
                else:
                    # ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ â†’ ìœ„í—˜
                    if keyword.lower() in [k.lower() for k in ADULT_KEYWORDS]:
                        result['categories']['adult'].append(keyword)
                    elif keyword.lower() in [k.lower() for k in CHILD_KEYWORDS]:
                        result['categories']['child'].append(keyword)
                    elif keyword.lower() in [k.lower() for k in BRAND_KEYWORDS]:
                        result['categories']['brand'].append(keyword)
                    else:
                        result['categories']['prohibited'].append(keyword)
            elif not is_safe:
                # AIê°€ ìœ„í—˜ìœ¼ë¡œ íŒë‹¨ â†’ ì¹´í…Œê³ ë¦¬ì— ì¶”ê°€
                if keyword.lower() in [k.lower() for k in ADULT_KEYWORDS]:
                    result['categories']['adult'].append(f"{keyword}(AI)")
                elif keyword.lower() in [k.lower() for k in CHILD_KEYWORDS]:
                    result['categories']['child'].append(f"{keyword}(AI)")
                elif keyword.lower() in [k.lower() for k in BRAND_KEYWORDS]:
                    result['categories']['brand'].append(f"{keyword}(AI)")
                else:
                    result['categories']['prohibited'].append(f"{keyword}(AI)")
            else:
                # AIê°€ ì•ˆì „ìœ¼ë¡œ íŒë‹¨
                result['safe_context_found'].append(f"{keyword}(AI)â†’{reason[:30]}")

    # ê²°ê³¼ ì§‘ê³„
    for cat_keywords in result['categories'].values():
        result['all_found'].extend(cat_keywords)

    result['is_safe'] = len(result['all_found']) == 0

    return result


def _is_context_dependent_bait(keyword: str, text: str) -> bool:
    """
    ë¬¸ë§¥ ì˜ì¡´ í‚¤ì›Œë“œì˜ ë¯¸ë¼ ì—¬ë¶€ íŒë‹¨

    ê²€ì¦ ê²°ê³¼ (2026-01-14):
    - "ì¼€ì´ë¸” ì •ë¦¬í•¨" â†’ ì •ìƒ (ì œí’ˆëª…)
    - "ì¼€ì´ë¸”ë§Œ" â†’ ë¯¸ë¼ (ë¶€ì†í’ˆë§Œ)
    - "ì¼€ì´ë¸” í¬í•¨" â†’ ì •ìƒ (êµ¬ì„±í’ˆ)
    - "ì¶©ì „ê¸°ì™€ ë°°í„°ë¦¬ 2ê°œê°€ í¬í•¨ëœ" â†’ ì •ìƒ
    """
    text_lower = text.lower()
    keyword_lower = keyword.lower()

    # 1. ì˜ˆì™¸ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì •ìƒ (í¬í•¨, ì„¸íŠ¸, êµ¬ì„± ë“±)
    for exc in BAIT_EXCEPTION_KEYWORDS:
        if exc in text_lower:
            return False  # ë¯¸ë¼ ì•„ë‹˜

    # 2. "~ë§Œ", "~ìš©", "~ì „ìš©" íŒ¨í„´ì´ë©´ ë¯¸ë¼
    for pattern in BAIT_ONLY_PATTERNS:
        # í‚¤ì›Œë“œ ë°”ë¡œ ë’¤ì— "ë§Œ" ë“±ì´ ì˜¤ëŠ”ì§€ í™•ì¸
        check_pattern = f"{keyword_lower}{pattern}"
        if check_pattern in text_lower:
            return True  # ë¯¸ë¼

    # 3. í‚¤ì›Œë“œê°€ ì˜µì…˜ëª… ëì— ìˆìœ¼ë©´ ë¯¸ë¼ ê°€ëŠ¥ì„± ë†’ìŒ
    # ì˜ˆ: "USB ì¼€ì´ë¸”" (ë) vs "ì¼€ì´ë¸” ì •ë¦¬í•¨" (ì¤‘ê°„)
    text_stripped = text_lower.strip()
    if text_stripped.endswith(keyword_lower):
        # ë‹¨, ì•ì— ìˆ˜ëŸ‰ì´ë‚˜ ìƒ‰ìƒì´ ìˆìœ¼ë©´ ì •ìƒ
        # ì˜ˆ: "ë¸”ë™ ì¼€ì´ë¸”", "2M ì¼€ì´ë¸”"
        words_before = text_stripped[:-len(keyword_lower)].strip().split()
        if words_before:
            last_word = words_before[-1]
            # ìƒ‰ìƒ/ê¸¸ì´/ìˆ˜ëŸ‰ í‘œí˜„ì´ë©´ ì •ìƒ
            if any(c in last_word for c in ['ìƒ‰', 'm', 'cm', 'ê°œ', 'ë¯¸í„°']):
                return False
        return True  # ë¯¸ë¼

    # 4. ê¸°ë³¸ì ìœ¼ë¡œ ì •ìƒìœ¼ë¡œ íŒë‹¨ (ì˜¤íƒ ë°©ì§€)
    return False


def filter_bait_options(skus: List[Dict], bait_keywords: List[str],
                        price_threshold_ratio: float = 0.15,
                        min_price_cny: float = 3.0) -> Tuple[List[Dict], List[Dict]]:
    """
    ë¯¸ë¼ì˜µì…˜ í•„í„°ë§ (í‚¤ì›Œë“œ + ê°€ê²© + ë¬¸ë§¥ ê¸°ë°˜)

    ê°œì„ ì‚¬í•­ (2026-01-14 ê²€ì¦ ê²°ê³¼ ë°˜ì˜):
    - ë¬¸ë§¥ ì˜ì¡´ í‚¤ì›Œë“œ: "ì¼€ì´ë¸”ë§Œ" = ë¯¸ë¼, "ì¼€ì´ë¸” í¬í•¨" = ì •ìƒ
    - ì˜ˆì™¸ í‚¤ì›Œë“œ í™•ì¥: í¬í•¨, ì¶”ê°€, ì„¸íŠ¸, êµ¬ì„± ë“±

    Args:
        skus: SKU ë°°ì—´
        bait_keywords: ë¯¸ë¼ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        price_threshold_ratio: ì¤‘ê°„ê°€ ëŒ€ë¹„ ì´ ë¹„ìœ¨ ì´í•˜ë©´ ë¯¸ë¼ (ê¸°ë³¸ 15%)
        min_price_cny: ì ˆëŒ€ ìµœì €ê°€ ê¸°ì¤€ (ê¸°ë³¸ 3ìœ„ì•ˆ ì´í•˜ë©´ ë¯¸ë¼)

    Returns:
        (ìœ íš¨ SKU ë¦¬ìŠ¤íŠ¸, ë¯¸ë¼ SKU ë¦¬ìŠ¤íŠ¸)
    """
    valid_skus = []
    bait_skus = []

    # 1. ê°€ê²© ê¸°ë°˜ ë¯¸ë¼ íŒë‹¨ì„ ìœ„í•œ ì¤‘ê°„ê°’(median) ê³„ì‚°
    prices = []
    for sku in skus:
        price = sku.get('_origin_price', 0) or sku.get('price', 0)
        if price and price > 0:
            prices.append(price)

    if prices:
        sorted_prices = sorted(prices)
        n = len(sorted_prices)
        if n % 2 == 0:
            median_price = (sorted_prices[n//2 - 1] + sorted_prices[n//2]) / 2
        else:
            median_price = sorted_prices[n//2]
        min_in_list = sorted_prices[0]
        max_in_list = sorted_prices[-1]
    else:
        median_price = 0
        min_in_list = 0
        max_in_list = 0

    # ê°€ê²© í¸ì°¨ê°€ í° ê²½ìš°ì—ë§Œ ìƒëŒ€ ê¸°ì¤€ ì ìš© (ìµœëŒ€/ìµœì†Œ ë¹„ìœ¨ì´ 5ë°° ì´ìƒ)
    price_variance_high = max_in_list > min_in_list * 5 if min_in_list > 0 else False
    price_threshold = median_price * price_threshold_ratio if median_price > 0 else min_price_cny

    for sku in skus:
        text = sku.get('text', '') or sku.get('_text', '')
        text_ko = sku.get('text_ko', '')
        combined_text = f"{text} {text_ko}".lower()
        price = sku.get('_origin_price', 0) or sku.get('price', 0)

        is_bait = False
        bait_reason = ""

        # 2. ê°€ê²© ê¸°ë°˜ ë¯¸ë¼ ì²´í¬ (ë¨¼ì € ì‹¤í–‰ - ê°€ê²© íƒì§€ íš¨ê³¼ ì¸¡ì •ìš©)
        if price > 0:
            # ì ˆëŒ€ ê¸°ì¤€: 3ìœ„ì•ˆ ì´í•˜ (ë°°ì†¡ë¹„/ìƒ˜í”Œ ë¯¸ë¼)
            if price < min_price_cny:
                is_bait = True
                bait_reason = f"[ì €ê°€í•„í„°]:{price:.1f}CNY"
            # ìƒëŒ€ ê¸°ì¤€: ê°€ê²© í¸ì°¨ê°€ í´ ë•Œë§Œ ì ìš© (ì¤‘ê°„ê°€ì˜ 15% ì´í•˜)
            elif price_variance_high and median_price > 0 and price < price_threshold:
                is_bait = True
                bait_reason = f"[ì €ê°€í•„í„°]:{price:.1f}CNY<{median_price:.0f}ì˜15%"

        # 3. í‚¤ì›Œë“œ ê¸°ë°˜ ë¯¸ë¼ ì²´í¬ (ê°€ê²©ìœ¼ë¡œ ì•ˆ ê±¸ë ¸ì–´ë„ í‚¤ì›Œë“œ ì²´í¬)
        if not is_bait:
            for keyword in bait_keywords:
                keyword_lower = keyword.lower()
                if keyword_lower in combined_text:
                    # 3-0. ê°•ë ¥ ë¯¸ë¼ í‚¤ì›Œë“œ (ì˜ˆì™¸ ì²´í¬ ì—†ì´ ë°”ë¡œ ë¯¸ë¼)
                    if keyword in STRONG_BAIT_KEYWORDS:
                        is_bait = True
                        bait_reason = f"í‚¤ì›Œë“œ:{keyword}(ê°•ë ¥)"
                        break

                    # 3-1. ë¬¸ë§¥ ì˜ì¡´ í‚¤ì›Œë“œì¸ì§€ í™•ì¸
                    if keyword in CONTEXT_DEPENDENT_BAIT_KEYWORDS:
                        # ë¬¸ë§¥ ê¸°ë°˜ íŒë‹¨
                        if _is_context_dependent_bait(keyword, combined_text):
                            is_bait = True
                            bait_reason = f"í‚¤ì›Œë“œ:{keyword}(ë‹¨ë…)"
                            break
                        else:
                            continue  # ë¬¸ë§¥ìƒ ì •ìƒì´ë©´ ë‹¤ìŒ í‚¤ì›Œë“œ ì²´í¬

                    # 3-2. ì¼ë°˜ í‚¤ì›Œë“œ: ì˜ˆì™¸ í‚¤ì›Œë“œ í™•ì¸
                    has_exception = any(exc in combined_text for exc in BAIT_EXCEPTION_KEYWORDS)
                    if has_exception:
                        continue  # ì˜ˆì™¸ í‚¤ì›Œë“œ ìˆìœ¼ë©´ ë‹¤ìŒ ë¯¸ë¼ í‚¤ì›Œë“œ ì²´í¬

                    is_bait = True
                    bait_reason = f"í‚¤ì›Œë“œ:{keyword}"
                    break

        if is_bait:
            sku['_bait_keyword'] = bait_reason
            bait_skus.append(sku)
        else:
            valid_skus.append(sku)

    return valid_skus, bait_skus


# ==================== ë¶ˆì‚¬ì API í´ë¼ì´ì–¸íŠ¸ ====================

# ë§ˆì¼“ ID ë§¤í•‘
MARKET_IDS = {
    "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´": 10200,
    "11ë²ˆê°€": 10201,
    "Gë§ˆì¼“/ì˜¥ì…˜": 10202,
    "ì¿ íŒ¡": 14516,
}

# ë§ˆì¼“ íƒ€ì… ë§¤í•‘
MARKET_TYPES = {
    "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´": "SMARTSTORE",
    "11ë²ˆê°€": "ST11",
    "Gë§ˆì¼“/ì˜¥ì…˜": "ESM",
    "ì¿ íŒ¡": "COUPANG",
}


class BulsajaAPIClient:
    """ë¶ˆì‚¬ì API í´ë¼ì´ì–¸íŠ¸"""
    BASE_URL = "https://api.bulsaja.com/api"

    def __init__(self, access_token: str = "", refresh_token: str = ""):
        self.access_token = access_token
        self.refresh_token = refresh_token
        self.session = requests.Session()
        # ì‚¬ìš©ìì˜ ì‹¤ì œ ë§ˆì¼“ ID ìºì‹œ (ë™ì ìœ¼ë¡œ ë¡œë“œ)
        self._user_market_ids: Dict[str, int] = {}
        if access_token:
            self._setup_session()

    def _setup_session(self):
        self.session.headers.update({
            'accept': 'application/json, text/plain, */*',
            'accept-language': 'ko,en-US;q=0.9,en;q=0.8',
            'accesstoken': self.access_token,
            'refreshtoken': self.refresh_token,
            'content-type': 'application/json',
            'origin': 'https://www.bulsaja.com',
            'referer': 'https://www.bulsaja.com/',
            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })

    def update_tokens(self, access_token: str, refresh_token: str):
        self.access_token = access_token
        self.refresh_token = refresh_token
        self._setup_session()

    def test_connection(self) -> Tuple[bool, str, int]:
        """ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            products, total = self.get_products(0, 1)
            return True, f"ì—°ê²° ì„±ê³µ (ì´ {total}ê°œ ìƒí’ˆ)", total
        except Exception as e:
            return False, str(e), 0

    def get_products(self, start_row: int = 0, end_row: int = 100, filter_model: Dict = None) -> Tuple[List[Dict], int]:
        """ìƒí’ˆ ëª©ë¡ ì¡°íšŒ"""
        url = f"{self.BASE_URL}/manage/list/serverside"
        payload = {
            "request": {
                "startRow": start_row,
                "endRow": end_row,
                "sortModel": [],
                "filterModel": filter_model or {}
            }
        }
        response = self.session.post(url, json=payload)
        response.raise_for_status()
        data = response.json()
        products = data.get('rowData', [])
        total_count = data.get('lastRow', len(products))
        return products, total_count

    def get_products_by_group(self, group_name: str, start: int = 0, limit: int = 1000,
                              status_filters: List[str] = None) -> Tuple[List[Dict], int]:
        """ê·¸ë£¹ë³„ ìƒí’ˆ ì¡°íšŒ

        status_filters: ìƒí’ˆ ìƒíƒœ í•„í„° (ì˜ˆ: ["0", "1", "2"])
            - APIì—ì„œ ê·¸ë£¹ í•„í„°ë§Œ ì ìš©í•˜ê³ , ìƒíƒœ í•„í„°ëŠ” ê²°ê³¼ì—ì„œ ì§ì ‘ í•„í„°ë§
        """
        filter_model = {}
        if group_name:
            filter_model["marketGroupName"] = {
                "filterType": "text",
                "type": "equals",
                "filter": group_name
            }

        # ìƒíƒœ í•„í„°ê°€ ìˆìœ¼ë©´ ë” ë§ì´ ê°€ì ¸ì™€ì„œ í•„í„°ë§
        fetch_limit = limit * 3 if status_filters else limit
        products, total = self.get_products(start, start + fetch_limit, filter_model)

        # ìƒíƒœ í•„í„° ì ìš© (APIì—ì„œ ë‹¤ì¤‘ ìƒíƒœ OR ì¡°ê±´ ë¯¸ì§€ì›)
        if status_filters and products:
            filtered = [p for p in products if str(p.get('status', '')) in status_filters]
            return filtered[:limit], len(filtered)

        return products[:limit], total

    def get_product_detail(self, product_id: str) -> Dict:
        """ìƒí’ˆ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        url = f"{self.BASE_URL}/manage/sourcing-product/{product_id}"
        response = self.session.get(url)
        response.raise_for_status()
        result = response.json()
        if 'data' in result:
            return result['data']
        return result

    def update_product_fields(self, product_id: str, product_data: Dict) -> Tuple[bool, str]:
        """ìƒí’ˆ ì •ë³´ ì—…ë°ì´íŠ¸"""
        url = f"{self.BASE_URL}/sourcing/uploadfields/{product_id}"
        try:
            response = self.session.put(url, json=product_data)
            response.raise_for_status()

            # ì‘ë‹µ ë‚´ìš© í™•ì¸
            try:
                result = response.json()
                if isinstance(result, dict):
                    if result.get('error') or result.get('errors'):
                        error_msg = result.get('error') or result.get('errors') or result.get('message', '')
                        return False, f"API ì˜¤ë¥˜: {str(error_msg)[:100]}"
                    if result.get('success') == False:
                        return False, f"ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')[:100]}"
                return True, "ì„±ê³µ"
            except:
                return True, "ì„±ê³µ (ì‘ë‹µ íŒŒì‹± ë¶ˆê°€)"

        except requests.exceptions.HTTPError as e:
            error_detail = ""
            try:
                error_detail = e.response.text[:200]
            except:
                pass
            return False, f"HTTP ì˜¤ë¥˜: {e.response.status_code} - {error_detail}"
        except Exception as e:
            return False, f"ì˜ˆì™¸: {str(e)}"

    def get_market_id(self, market_name: str) -> int:
        """ì‚¬ìš©ìì˜ ì‹¤ì œ ë§ˆì¼“ ID ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì‚¬ìš©)"""
        # ìºì‹œê°€ ë¹„ì–´ìˆìœ¼ë©´ APIì—ì„œ ì¡°íšŒ
        if not self._user_market_ids:
            self._user_market_ids = self.get_user_markets()
            if self._user_market_ids:
                print(f"[INFO] ë§ˆì¼“ ID ë¡œë“œë¨: {self._user_market_ids}")

        # ì‚¬ìš©ì ë§ˆì¼“ IDì—ì„œ ì°¾ê¸°
        if market_name in self._user_market_ids:
            return self._user_market_ids[market_name]

        # ëª» ì°¾ìœ¼ë©´ ê¸°ë³¸ê°’ (ê²½ê³  ì¶œë ¥)
        fallback_id = MARKET_IDS.get(market_name, 10200)
        print(f"[WARNING] '{market_name}' ë§ˆì¼“ IDë¥¼ ì°¾ì§€ ëª»í•¨. ê¸°ë³¸ê°’ {fallback_id} ì‚¬ìš©")
        return fallback_id

    def upload_product(self, product_id: str, market_name: str = "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´") -> Tuple[bool, str]:
        """ìƒí’ˆ ì—…ë¡œë“œ"""
        # ì‚¬ìš©ìì˜ ì‹¤ì œ ë§ˆì¼“ ID ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
        market_id = self.get_market_id(market_name)
        market_type = MARKET_TYPES.get(market_name, "SMARTSTORE")
        url = f"{self.BASE_URL}/market/{market_id}/upload/"
        payload = {
            "productId": product_id,
            "notices": None,
            "preventDuplicateUpload": True,
            "removeDuplicateWords": True,
            "targetMarket": market_type
        }
        try:
            response = self.session.post(url, json=payload)
            response.raise_for_status()

            # ì‘ë‹µ ë‚´ìš© í™•ì¸
            try:
                result = response.json()
                # ì‘ë‹µì— ì—ëŸ¬ê°€ ìˆëŠ”ì§€ í™•ì¸
                if isinstance(result, dict):
                    if result.get('error') or result.get('errors'):
                        error_msg = result.get('error') or result.get('errors') or result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
                        return False, f"ì—…ë¡œë“œ ì‹¤íŒ¨: {str(error_msg)[:100]}"
                    if result.get('success') == False:
                        return False, f"ì—…ë¡œë“œ ì‹¤íŒ¨: {result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')[:100]}"
                    # ìƒíƒœ í™•ì¸
                    status = result.get('status') or result.get('uploadStatus')
                    if status and status.lower() in ['failed', 'error', 'failure']:
                        return False, f"ì—…ë¡œë“œ ì‹¤íŒ¨: {result.get('message', status)[:100]}"
                return True, f"ì„±ê³µ (ì‘ë‹µ: {str(result)[:50]})"
            except:
                # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ í…ìŠ¤íŠ¸ë¡œ í™•ì¸
                text = response.text[:100] if response.text else "ì‘ë‹µ ì—†ìŒ"
                return True, f"ì„±ê³µ (raw: {text})"

        except requests.exceptions.HTTPError as e:
            error_detail = ""
            try:
                error_detail = e.response.text[:100]
            except:
                pass
            return False, f"{error_detail}"
        except Exception as e:
            return False, str(e)

    def get_market_groups(self) -> List[str]:
        """ë§ˆì¼“ ê·¸ë£¹ ëª©ë¡ ì¡°íšŒ"""
        url = f"{self.BASE_URL}/market/groups/"
        try:
            response = self.session.post(url, json={})
            response.raise_for_status()
            data = response.json()
            if isinstance(data, list):
                return [g.get('name', '') for g in data if g.get('name')]
            return []
        except Exception as e:
            print(f"ë§ˆì¼“ ê·¸ë£¹ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def get_user_markets(self) -> Dict[str, int]:
        """ì‚¬ìš©ìì˜ ë§ˆì¼“ ID ë§¤í•‘ ì¡°íšŒ (ì—°ê²°ëœ ë§ˆì¼“ ëª©ë¡ì—ì„œ ì‹¤ì œ ID ì¶”ì¶œ)"""
        url = f"{self.BASE_URL}/market/groups/"
        try:
            response = self.session.post(url, json={})
            response.raise_for_status()
            data = response.json()

            # ë””ë²„ê·¸: ì „ì²´ ì‘ë‹µ êµ¬ì¡° ì¶œë ¥ (ì²« ë²ˆì§¸ ê·¸ë£¹)
            if isinstance(data, list) and len(data) > 0:
                first_group = data[0]
                print(f"[DEBUG] /market/groups/ ì²« ë²ˆì§¸ ê·¸ë£¹ í‚¤: {list(first_group.keys())}")
                # ë§ˆì¼“ ì •ë³´ê°€ ì–´ë””ì— ìˆëŠ”ì§€ ì°¾ê¸°
                for key in first_group.keys():
                    val = first_group.get(key)
                    if isinstance(val, list) and len(val) > 0:
                        print(f"[DEBUG] {key} (list, len={len(val)}): ì²« ë²ˆì§¸ ìš”ì†Œ í‚¤ = {list(val[0].keys()) if isinstance(val[0], dict) else val[0]}")
                    elif isinstance(val, dict):
                        print(f"[DEBUG] {key} (dict): í‚¤ = {list(val.keys())}")

            market_ids = {}
            if isinstance(data, list):
                for group in data:
                    # ê° ê·¸ë£¹ì—ì„œ ë§ˆì¼“ ì •ë³´ ì¶”ì¶œ (ì—¬ëŸ¬ í•„ë“œ ì‹œë„)
                    markets = group.get('markets', []) or group.get('connectedMarkets', []) or group.get('marketList', [])

                    # ê·¸ë£¹ ìì²´ê°€ ë§ˆì¼“ ì •ë³´ë¥¼ í¬í•¨í•  ìˆ˜ë„ ìˆìŒ
                    if not markets and 'marketType' in group:
                        markets = [group]

                    for market in markets:
                        if not isinstance(market, dict):
                            continue
                        market_type = market.get('marketType', '') or market.get('type', '')
                        # IDëŠ” ì—¬ëŸ¬ í•„ë“œëª…ìœ¼ë¡œ ì¡´ì¬í•  ìˆ˜ ìˆìŒ
                        market_id = (market.get('id') or market.get('marketId') or
                                    market.get('market_id') or market.get('ID'))
                        if market_type and market_id:
                            # ë§ˆì¼“ íƒ€ì…ì„ í•œê¸€ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
                            type_name_map = {
                                'SMARTSTORE': 'ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´',
                                'ST11': '11ë²ˆê°€',
                                'ESM': 'Gë§ˆì¼“/ì˜¥ì…˜',
                                'COUPANG': 'ì¿ íŒ¡',
                            }
                            name = type_name_map.get(market_type, market_type)
                            if name not in market_ids:
                                market_ids[name] = market_id
                                print(f"[DEBUG] ë§ˆì¼“ ë°œê²¬: {name} = {market_id}")

            print(f"[DEBUG] get_user_markets ìµœì¢… ê²°ê³¼: {market_ids}")
            return market_ids
        except Exception as e:
            print(f"[DEBUG] get_user_markets ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return {}


def extract_tokens_from_browser(port: int = 9222) -> Tuple[bool, str, str, str]:
    """í¬ë¡¬ ë””ë²„ê·¸ ëª¨ë“œì—ì„œ í† í° ì¶”ì¶œ"""
    try:
        tabs_url = f"http://127.0.0.1:{port}/json"
        try:
            response = requests.get(tabs_url, timeout=3)
            tabs = response.json()
        except:
            return False, "", "", f"í¬ë¡¬ í¬íŠ¸ {port} ì—°ê²° ì‹¤íŒ¨"

        bulsaja_tab = None
        for tab in tabs:
            if 'bulsaja.com' in tab.get('url', ''):
                bulsaja_tab = tab
                break

        if not bulsaja_tab:
            return False, "", "", "ë¶ˆì‚¬ì íƒ­ ì—†ìŒ"

        ws_url = bulsaja_tab.get('webSocketDebuggerUrl')
        if not ws_url:
            return False, "", "", "WebSocket URL ì—†ìŒ"

        ws = websocket.create_connection(ws_url, timeout=5)
        cmd = {
            "id": 1,
            "method": "Runtime.evaluate",
            "params": {
                "expression": """
                    (function() {
                        var tokenStr = localStorage.getItem('token');
                        if (tokenStr) {
                            try {
                                var tokenObj = JSON.parse(tokenStr);
                                if (tokenObj.state) {
                                    return JSON.stringify({
                                        accessToken: tokenObj.state.accessToken || '',
                                        refreshToken: tokenObj.state.refreshToken || ''
                                    });
                                }
                            } catch(e) {}
                        }
                        return JSON.stringify({accessToken: '', refreshToken: ''});
                    })()
                """,
                "returnByValue": True
            }
        }
        ws.send(json.dumps(cmd))
        result = json.loads(ws.recv())
        ws.close()

        if 'result' in result and 'result' in result['result']:
            token_data = json.loads(result['result']['result'].get('value', '{}'))
            access_token = token_data.get('accessToken', '')
            refresh_token = token_data.get('refreshToken', '')
            if access_token and refresh_token:
                return True, access_token, refresh_token, ""

        return False, "", "", "í† í° íŒŒì‹± ì‹¤íŒ¨"
    except Exception as e:
        return False, "", "", f"ì˜ˆì™¸: {e}"


# ==================== ë‹¤ì¤‘ AI API ì§€ì› ëª¨ë“ˆ ====================

# AI ì„¤ì • íŒŒì¼
AI_CONFIG_FILE = "ai_config.json"

# ê¸°ë³¸ AI ì„¤ì •
DEFAULT_AI_CONFIG = {
    'provider': 'gemini',  # gemini, claude, openai
    'gemini': {
        'api_key': '',
        'model': 'gemini-2.0-flash'
    },
    'claude': {
        'api_key': '',
        'model': 'claude-3-5-sonnet-20241022'
    },
    'openai': {
        'api_key': '',
        'model': 'gpt-4o-mini'
    }
}


def load_ai_config() -> dict:
    """AI ì„¤ì • ë¡œë“œ"""
    if os.path.exists(AI_CONFIG_FILE):
        try:
            with open(AI_CONFIG_FILE, 'r', encoding='utf-8') as f:
                config = json.load(f)
                # ê¸°ë³¸ê°’ ë³‘í•©
                for key, value in DEFAULT_AI_CONFIG.items():
                    if key not in config:
                        config[key] = value
                    elif isinstance(value, dict):
                        for sub_key, sub_value in value.items():
                            if sub_key not in config[key]:
                                config[key][sub_key] = sub_value
                return config
        except Exception:
            pass
    return DEFAULT_AI_CONFIG.copy()


def save_ai_config(config: dict) -> bool:
    """AI ì„¤ì • ì €ì¥"""
    try:
        with open(AI_CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return True
    except Exception:
        return False


def call_ai_api(prompt: str, config: dict = None, timeout: int = 30) -> Tuple[bool, str, str]:
    """
    ë‹¤ì¤‘ AI API í˜¸ì¶œ (Gemini / Claude / OpenAI)

    Args:
        prompt: ì§ˆë¬¸ ë‚´ìš©
        config: AI ì„¤ì • (Noneì´ë©´ íŒŒì¼ì—ì„œ ë¡œë“œ)
        timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)

    Returns:
        (ì„±ê³µì—¬ë¶€, ì‘ë‹µí…ìŠ¤íŠ¸, ì—ëŸ¬ë©”ì‹œì§€)
    """
    if config is None:
        config = load_ai_config()

    provider = config.get('provider', 'gemini')

    if provider == 'gemini':
        return _call_gemini(prompt, config.get('gemini', {}), timeout)
    elif provider == 'claude':
        return _call_claude(prompt, config.get('claude', {}), timeout)
    elif provider == 'openai':
        return _call_openai(prompt, config.get('openai', {}), timeout)
    else:
        return False, '', f'ì§€ì›í•˜ì§€ ì•ŠëŠ” AI ì œê³µì: {provider}'


def _call_gemini(prompt: str, settings: dict, timeout: int) -> Tuple[bool, str, str]:
    """Gemini API í˜¸ì¶œ"""
    api_key = settings.get('api_key', '')
    model = settings.get('model', 'gemini-2.0-flash')

    if not api_key:
        return False, '', 'Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'

    try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
        payload = {
            'contents': [{'parts': [{'text': prompt}]}],
            'generationConfig': {
                'temperature': 0.3,
                'maxOutputTokens': 1024,
            }
        }

        response = requests.post(
            f"{url}?key={api_key}",
            headers={'Content-Type': 'application/json'},
            json=payload,
            timeout=timeout
        )

        if response.status_code != 200:
            return False, '', f'Gemini API ì˜¤ë¥˜ ({response.status_code})'

        data = response.json()
        if 'candidates' in data and data['candidates']:
            content = data['candidates'][0].get('content', {})
            parts = content.get('parts', [])
            if parts:
                return True, parts[0].get('text', ''), ''

        return False, '', 'Gemini ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨'

    except requests.exceptions.Timeout:
        return False, '', f'Gemini API íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ)'
    except Exception as e:
        return False, '', f'Gemini API ì˜¤ë¥˜: {e}'


def _call_claude(prompt: str, settings: dict, timeout: int) -> Tuple[bool, str, str]:
    """Claude API í˜¸ì¶œ"""
    api_key = settings.get('api_key', '')
    model = settings.get('model', 'claude-3-5-sonnet-20241022')

    if not api_key:
        return False, '', 'Claude API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'

    try:
        url = "https://api.anthropic.com/v1/messages"
        headers = {
            'Content-Type': 'application/json',
            'x-api-key': api_key,
            'anthropic-version': '2023-06-01'
        }
        payload = {
            'model': model,
            'max_tokens': 1024,
            'messages': [
                {'role': 'user', 'content': prompt}
            ]
        }

        response = requests.post(url, headers=headers, json=payload, timeout=timeout)

        if response.status_code != 200:
            return False, '', f'Claude API ì˜¤ë¥˜ ({response.status_code})'

        data = response.json()
        if 'content' in data and data['content']:
            return True, data['content'][0].get('text', ''), ''

        return False, '', 'Claude ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨'

    except requests.exceptions.Timeout:
        return False, '', f'Claude API íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ)'
    except Exception as e:
        return False, '', f'Claude API ì˜¤ë¥˜: {e}'


def _call_openai(prompt: str, settings: dict, timeout: int) -> Tuple[bool, str, str]:
    """OpenAI API í˜¸ì¶œ"""
    api_key = settings.get('api_key', '')
    model = settings.get('model', 'gpt-4o-mini')

    if not api_key:
        return False, '', 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'

    try:
        url = "https://api.openai.com/v1/chat/completions"
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {api_key}'
        }
        payload = {
            'model': model,
            'max_tokens': 1024,
            'temperature': 0.3,
            'messages': [
                {'role': 'user', 'content': prompt}
            ]
        }

        response = requests.post(url, headers=headers, json=payload, timeout=timeout)

        if response.status_code != 200:
            return False, '', f'OpenAI API ì˜¤ë¥˜ ({response.status_code})'

        data = response.json()
        if 'choices' in data and data['choices']:
            return True, data['choices'][0].get('message', {}).get('content', ''), ''

        return False, '', 'OpenAI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨'

    except requests.exceptions.Timeout:
        return False, '', f'OpenAI API íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ)'
    except Exception as e:
        return False, '', f'OpenAI API ì˜¤ë¥˜: {e}'


# ==================== AI ê¸°ë°˜ ìƒí’ˆ ì•ˆì „ íŒë‹¨ ====================

def check_product_safety_with_ai(title: str, dangerous_keyword: str, config: dict = None) -> Tuple[bool, str]:
    """
    AIì—ê²Œ ìƒí’ˆ ì•ˆì „ ì—¬ë¶€ ë¬¸ì˜

    í”„ë¡œê·¸ë¨ìœ¼ë¡œ íŒë‹¨ì´ ì• ë§¤í•œ ê²½ìš° (ìœ„í—˜ í‚¤ì›Œë“œ íƒì§€ but ì•ˆì „ ì»¨í…ìŠ¤íŠ¸ ë¶ˆëª…í™•)
    AIì—ê²Œ ë¬¸ì˜í•˜ì—¬ ìµœì¢… íŒë‹¨

    Args:
        title: ìƒí’ˆëª…
        dangerous_keyword: íƒì§€ëœ ìœ„í—˜ í‚¤ì›Œë“œ
        config: AI ì„¤ì •

    Returns:
        (ì•ˆì „ì—¬ë¶€, íŒë‹¨ì´ìœ )
    """
    prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ êµ¬ë§¤ëŒ€í–‰ ìƒí’ˆ ì•ˆì „ íŒë³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ìƒí’ˆëª…ì—ì„œ "{dangerous_keyword}" í‚¤ì›Œë“œê°€ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤.
ì´ ìƒí’ˆì´ ì‹¤ì œë¡œ ìœ„í—˜í•œ ìƒí’ˆì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

ìƒí’ˆëª…: {title}
íƒì§€ëœ í‚¤ì›Œë“œ: {dangerous_keyword}

íŒë‹¨ ê¸°ì¤€:
- "ë°”ì´ë¸Œë ˆì´í„°" â†’ ì½˜í¬ë¦¬íŠ¸/ê±´ì„¤ ê´€ë ¨ì´ë©´ ê³µêµ¬(ì•ˆì „), ì„±ì¸ìš©í’ˆì´ë©´ ìœ„í—˜
- "ì¹´ì‹œíŠ¸" â†’ ê°•ì•„ì§€/ì• ê²¬ ê´€ë ¨ì´ë©´ ë°˜ë ¤ë™ë¬¼ìš©(ì•ˆì „), ì•„ê¸°ìš©ì´ë©´ KCì¸ì¦ í•„ìš”(ìœ„í—˜)
- "ì§„ë™ê¸°" â†’ ë§ˆì‚¬ì§€/ê±´ì„¤ ê´€ë ¨ì´ë©´ ì•ˆì „, ì„±ì¸ìš©í’ˆì´ë©´ ìœ„í—˜

ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”:
SAFE ë˜ëŠ” DANGER
ì´ìœ : (í•œ ì¤„ ì„¤ëª…)

ì˜ˆì‹œ:
SAFE
ì´ìœ : ì½˜í¬ë¦¬íŠ¸ ë°”ì´ë¸Œë ˆì´í„°ëŠ” ê±´ì„¤ìš© ê³µêµ¬ì…ë‹ˆë‹¤."""

    success, response, error = call_ai_api(prompt, config, timeout=15)

    if not success:
        # AI í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì•ˆì „í•˜ì§€ ì•ŠìŒìœ¼ë¡œ ê¸°ë³¸ ì²˜ë¦¬
        return False, f'AI íŒë‹¨ ì‹¤íŒ¨: {error}'

    response_upper = response.upper().strip()

    if 'SAFE' in response_upper.split('\n')[0]:
        # ì´ìœ  ì¶”ì¶œ
        reason_match = response.split('ì´ìœ :')
        reason = reason_match[1].strip() if len(reason_match) > 1 else 'AI íŒë‹¨: ì•ˆì „'
        return True, f'AIâ†’ì•ˆì „: {reason[:50]}'
    else:
        reason_match = response.split('ì´ìœ :')
        reason = reason_match[1].strip() if len(reason_match) > 1 else 'AI íŒë‹¨: ìœ„í—˜'
        return False, f'AIâ†’ìœ„í—˜: {reason[:50]}'


# ==================== Gemini AI í•™ìŠµ ëª¨ë“ˆ ====================

# Gemini API ì„¤ì • (ë ˆê±°ì‹œ í˜¸í™˜ìš©, ìƒˆ ì½”ë“œëŠ” load_ai_config ì‚¬ìš©)
GEMINI_API_KEY = "AIzaSyDvkncM1ecu6R2bKOcLoqHzehmG58vz-Bw"
GEMINI_MODEL = "gemini-2.0-flash"  # ìµœì‹  ë¹ ë¥¸ ëª¨ë¸


def analyze_simulation_with_gemini(excel_path: str, log_callback=None) -> dict:
    """
    ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ Excelì„ Gemini AIë¡œ ë¶„ì„

    Args:
        excel_path: ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ Excel íŒŒì¼ ê²½ë¡œ
        log_callback: ë¡œê·¸ ì¶œë ¥ í•¨ìˆ˜

    Returns:
        {
            'success': bool,
            'report': str,  # í•œí˜ì´ì§€ ë¶„ì„ ë¦¬í¬íŠ¸
            'recommendations': {
                'add_bait_keywords': [],  # ì¶”ê°€í•  ë¯¸ë¼ í‚¤ì›Œë“œ
                'remove_bait_keywords': [],  # ì œê±°í•  ë¯¸ë¼ í‚¤ì›Œë“œ (ì˜¤íƒ)
                'add_exception_keywords': [],  # ì¶”ê°€í•  ì˜ˆì™¸ í‚¤ì›Œë“œ
                'price_threshold_suggestion': float,  # ê°€ê²© ê¸°ì¤€ ì œì•ˆ
            },
            'statistics': {
                'total_products': int,
                'bait_detected': int,
                'false_positive_suspected': int,
                'false_negative_suspected': int,
            },
            'error': str
        }
    """
    result = {
        'success': False,
        'report': '',
        'recommendations': {
            'add_bait_keywords': [],
            'remove_bait_keywords': [],
            'add_exception_keywords': [],
            'price_threshold_suggestion': None,
        },
        'statistics': {},
        'error': ''
    }

    try:
        import pandas as pd
    except ImportError:
        result['error'] = "pandas íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install pandas"
        if log_callback:
            log_callback(f"âŒ {result['error']}")
        return result

    # 1. Excel íŒŒì¼ ë¡œë“œ
    if log_callback:
        log_callback(f"ğŸ“‚ Excel íŒŒì¼ ë¡œë“œ ì¤‘: {excel_path}")

    try:
        df = pd.read_excel(excel_path)
    except Exception as e:
        result['error'] = f"Excel ë¡œë“œ ì‹¤íŒ¨: {e}"
        if log_callback:
            log_callback(f"âŒ {result['error']}")
        return result

    if log_callback:
        log_callback(f"âœ… {len(df)}ê°œ ìƒí’ˆ ë¡œë“œ ì™„ë£Œ")

    # 2. ë¶„ì„ìš© ë°ì´í„° ì¤€ë¹„
    analysis_data = _prepare_analysis_data(df)

    if log_callback:
        log_callback(f"ğŸ“Š ë¶„ì„ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
        log_callback(f"   - ë¯¸ë¼ íƒì§€: {analysis_data['bait_count']}ê±´")
        log_callback(f"   - ì˜ì‹¬ ì˜¤íƒ: {analysis_data['false_positive_count']}ê±´")

    # 3. Gemini API í˜¸ì¶œ
    if log_callback:
        log_callback(f"ğŸ¤– Gemini AI ë¶„ì„ ìš”ì²­ ì¤‘...")

    gemini_result = _call_gemini_api(analysis_data, log_callback)

    if not gemini_result['success']:
        result['error'] = gemini_result['error']
        return result

    # 4. ê²°ê³¼ íŒŒì‹±
    result['success'] = True
    result['report'] = gemini_result['report']
    result['recommendations'] = gemini_result['recommendations']
    result['statistics'] = {
        'total_products': len(df),
        'bait_detected': analysis_data['bait_count'],
        'false_positive_suspected': analysis_data['false_positive_count'],
        'false_negative_suspected': analysis_data['false_negative_count'],
    }

    if log_callback:
        log_callback(f"âœ… AI ë¶„ì„ ì™„ë£Œ!")

    return result


def _prepare_analysis_data(df) -> dict:
    """DataFrameì—ì„œ ë¶„ì„ìš© ë°ì´í„° ì¶”ì¶œ (AI í•™ìŠµìš©)"""
    data = {
        'bait_count': 0,
        'false_positive_count': 0,
        'false_negative_count': 0,
        'bait_samples': [],  # ë¯¸ë¼ë¡œ íƒì§€ëœ ìƒ˜í”Œ
        'normal_samples': [],  # â˜… ì •ìƒìœ¼ë¡œ íŒì •ëœ ì˜µì…˜ë“¤ (AIê°€ ìƒˆ ë¯¸ë¼ íŒ¨í„´ ì°¾ê¸°ìš©)
        'suspicious_samples': [],  # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì •ìƒ ì˜µì…˜ ìƒ˜í”Œ
        'price_stats': {},
        'keyword_frequency': {},
    }

    # ì»¬ëŸ¼ëª… í™•ì¸ (ë‹¤ì–‘í•œ í˜•íƒœ ì§€ì›)
    bait_col = None
    option_col = None
    price_col = None
    product_col = None

    for col in df.columns:
        col_lower = col.lower()
        if 'ë¯¸ë¼' in col or 'bait' in col_lower:
            bait_col = col
        if 'ì˜µì…˜' in col or 'option' in col_lower or 'sku' in col_lower:
            option_col = col
        if 'ê°€ê²©' in col or 'price' in col_lower or 'ì›ê°€' in col:
            price_col = col
        if 'ìƒí’ˆ' in col or 'product' in col_lower or 'ì œëª©' in col:
            product_col = col

    # ë¯¸ë¼ íƒì§€ í†µê³„
    if bait_col and bait_col in df.columns:
        bait_df = df[df[bait_col].notna() & (df[bait_col] != '')]
        data['bait_count'] = len(bait_df)

        # ë¯¸ë¼ ìƒ˜í”Œ ìˆ˜ì§‘ (ìµœëŒ€ 20ê°œ)
        for _, row in bait_df.head(20).iterrows():
            sample = {
                'option': str(row.get(option_col, '')) if option_col else '',
                'bait_reason': str(row.get(bait_col, '')),
                'price': row.get(price_col, 0) if price_col else 0,
                'product': str(row.get(product_col, ''))[:50] if product_col else '',
            }
            data['bait_samples'].append(sample)

    # ê°€ê²© ë¶„í¬
    if price_col and price_col in df.columns:
        prices = df[price_col].dropna()
        if len(prices) > 0:
            data['price_stats'] = {
                'min': float(prices.min()),
                'max': float(prices.max()),
                'median': float(prices.median()),
                'mean': float(prices.mean()),
            }

    # â˜… ì •ìƒìœ¼ë¡œ íŒì •ëœ ì˜µì…˜ë“¤ ìˆ˜ì§‘ (AIê°€ ë†“ì¹œ ë¯¸ë¼ íŒ¨í„´ ì°¾ê¸°)
    if option_col:
        normal_df = df[df[bait_col].isna() | (df[bait_col] == '')] if bait_col else df

        # ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ ë‹¤ì–‘í•œ ì˜µì…˜ ìˆ˜ì§‘ (ìµœëŒ€ 50ê°œ)
        sample_df = normal_df.sample(n=min(50, len(normal_df))) if len(normal_df) > 50 else normal_df

        for _, row in sample_df.iterrows():
            option_text = str(row.get(option_col, ''))
            if option_text and len(option_text) > 2:  # ë„ˆë¬´ ì§§ì€ ì˜µì…˜ ì œì™¸
                data['normal_samples'].append({
                    'option': option_text[:100],  # 100ì ì œí•œ
                    'price': row.get(price_col, 0) if price_col else 0,
                })

        # ì˜ì‹¬ë˜ëŠ” ì˜¤íƒ (ì •ìƒ ì˜µì…˜ ì¤‘ ë¯¸ë¼ í‚¤ì›Œë“œ í¬í•¨)
        exception_patterns = ['í¬í•¨', 'ì œê³µ', 'ë™ë´‰', 'ì„¸íŠ¸', 'êµ¬ì„±']
        for _, row in normal_df.iterrows():
            option_text = str(row.get(option_col, ''))
            if any(p in option_text for p in exception_patterns):
                data['suspicious_samples'].append({
                    'option': option_text,
                    'price': row.get(price_col, 0) if price_col else 0,
                    'reason': 'exception_keyword_found'
                })
                if len(data['suspicious_samples']) >= 10:
                    break

    return data


def _call_gemini_api(analysis_data: dict, log_callback=None) -> dict:
    """Gemini API í˜¸ì¶œ"""
    result = {
        'success': False,
        'report': '',
        'recommendations': {
            'add_bait_keywords': [],
            'remove_bait_keywords': [],
            'add_exception_keywords': [],
            'price_threshold_suggestion': None,
        },
        'error': ''
    }

    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = _build_analysis_prompt(analysis_data)

    try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent"
        headers = {
            'Content-Type': 'application/json',
        }
        payload = {
            'contents': [{
                'parts': [{'text': prompt}]
            }],
            'generationConfig': {
                'temperature': 0.3,  # ì¼ê´€ì„± ìˆëŠ” ë¶„ì„ì„ ìœ„í•´ ë‚®ê²Œ
                'maxOutputTokens': 4096,
            }
        }

        response = requests.post(
            f"{url}?key={GEMINI_API_KEY}",
            headers=headers,
            json=payload,
            timeout=60
        )

        if response.status_code != 200:
            result['error'] = f"Gemini API ì˜¤ë¥˜ ({response.status_code}): {response.text[:200]}"
            if log_callback:
                log_callback(f"âŒ {result['error']}")
            return result

        response_data = response.json()

        # ì‘ë‹µ íŒŒì‹±
        if 'candidates' in response_data and len(response_data['candidates']) > 0:
            content = response_data['candidates'][0].get('content', {})
            parts = content.get('parts', [])
            if parts:
                ai_response = parts[0].get('text', '')

                # ì‘ë‹µ íŒŒì‹± (JSON ë¸”ë¡ ì¶”ì¶œ)
                parsed = _parse_gemini_response(ai_response)
                result['success'] = True
                result['report'] = parsed.get('report', ai_response)
                result['recommendations'] = parsed.get('recommendations', result['recommendations'])
        else:
            result['error'] = "Gemini API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"

    except requests.exceptions.Timeout:
        result['error'] = "Gemini API íƒ€ì„ì•„ì›ƒ (60ì´ˆ)"
    except Exception as e:
        result['error'] = f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}"

    if result['error'] and log_callback:
        log_callback(f"âŒ {result['error']}")

    return result


def _build_analysis_prompt(analysis_data: dict) -> str:
    """AI í•™ìŠµìš© í”„ë¡¬í”„íŠ¸ ìƒì„± - ì •ìƒ ì˜µì…˜ì—ì„œ ë†“ì¹œ ë¯¸ë¼ íŒ¨í„´ ì°¾ê¸°"""

    bait_samples_str = ""
    for i, sample in enumerate(analysis_data['bait_samples'][:15], 1):
        bait_samples_str += f"  {i}. \"{sample['option']}\" (íƒì§€ì´ìœ : {sample['bait_reason']})\n"

    # â˜… ì •ìƒìœ¼ë¡œ íŒì •ëœ ì˜µì…˜ë“¤ (AIê°€ ìƒˆ ë¯¸ë¼ íŒ¨í„´ ì°¾ê¸°)
    normal_samples_str = ""
    for i, sample in enumerate(analysis_data.get('normal_samples', [])[:30], 1):
        normal_samples_str += f"  {i}. \"{sample['option']}\" (ê°€ê²©: {sample['price']})\n"

    suspicious_str = ""
    for i, sample in enumerate(analysis_data['suspicious_samples'][:10], 1):
        suspicious_str += f"  {i}. \"{sample['option']}\" (ê°€ê²©: {sample['price']})\n"

    price_info = analysis_data.get('price_stats', {})
    price_str = ""
    if price_info:
        price_str = f"""
ê°€ê²© ë¶„í¬:
- ìµœì €ê°€: {price_info.get('min', 'N/A')}
- ìµœê³ ê°€: {price_info.get('max', 'N/A')}
- ì¤‘ê°„ê°’: {price_info.get('median', 'N/A')}
- í‰ê· : {price_info.get('mean', 'N/A'):.2f}
"""

    prompt = f"""ë‹¹ì‹ ì€ íƒ€ì˜¤ë°”ì˜¤/ì•Œë¦¬ë°”ë°” ìƒí’ˆ ì˜µì…˜ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
êµ¬ë§¤ëŒ€í–‰ ì‹œìŠ¤í…œì—ì„œ "ë¯¸ë¼ ì˜µì…˜"ì„ ìë™ í•„í„°ë§í•˜ëŠ”ë°, í˜„ì¬ ì‹œìŠ¤í…œì´ ë†“ì¹œ ë¯¸ë¼ íŒ¨í„´ì„ ì°¾ì•„ì£¼ì„¸ìš”.

## ë¯¸ë¼ ì˜µì…˜ì´ë€?
íƒ€ì˜¤ë°”ì˜¤ íŒë§¤ìë“¤ì´ ì‚¬ìš©í•˜ëŠ” ê°€ì§œ ì˜µì…˜:
- ì£¼ë¬¸ì œì‘/ë§ì¶¤ì œì‘ ìœ ë„ ("ì»¤ìŠ¤í…€", "ì •ê¸ˆ", "ê³„ì•½ê¸ˆ")
- ë°°ì†¡ë¹„/ì¶”ê°€ë¹„ìš© ê²°ì œìš© ("ë°°ì†¡ë¹„", "ì„¤ì¹˜ë¹„")
- ë¬¸ì˜/ìƒë‹´ ìœ ë„ ("ë¬¸ì˜í•˜ì„¸ìš”", "ìƒë‹´í•„ìˆ˜")
- ì•ˆë‚´ë¬¸/í™ë³´ë¬¸êµ¬ ("ê°ì‚¬í•©ë‹ˆë‹¤", "íŒ”ë¡œìš°í•´ì£¼ì„¸ìš”", "ì•½ì†ë“œë¦½ë‹ˆë‹¤")
- ìƒ˜í”Œ/í…ŒìŠ¤íŠ¸ìš© ("ìƒ˜í”Œ", "ë¬´ë£Œì²´í—˜")
- í’ˆì ˆ/íŒë§¤ì¢…ë£Œ ("í’ˆì ˆ", "ì¬ê³ ì—†ìŒ")

## í˜„ì¬ íƒì§€ ê²°ê³¼

íƒì§€ëœ ë¯¸ë¼: {analysis_data['bait_count']}ê±´
{bait_samples_str if bait_samples_str else "  (ì—†ìŒ)"}

## â˜… ì •ìƒìœ¼ë¡œ íŒì •ëœ ì˜µì…˜ë“¤ (ì—¬ê¸°ì„œ ë†“ì¹œ ë¯¸ë¼ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”!)

{normal_samples_str if normal_samples_str else "  (ë°ì´í„° ì—†ìŒ)"}

{price_str}

## ë¶„ì„ ìš”ì²­

ìœ„ "ì •ìƒìœ¼ë¡œ íŒì •ëœ ì˜µì…˜ë“¤"ì„ ê²€í† í•˜ê³ :
1. **ë†“ì¹œ ë¯¸ë¼ ì˜µì…˜**ì„ ì°¾ì•„ì£¼ì„¸ìš” (ì•ˆë‚´ë¬¸, í™ë³´ë¬¸êµ¬, ë¬¸ì˜ìœ ë„ ë“±)
2. í•´ë‹¹ ì˜µì…˜ì—ì„œ **ì¶”ì¶œí•  ìˆ˜ ìˆëŠ” í‚¤ì›Œë“œ**ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”
3. ì˜¤íƒ ê°€ëŠ¥ì„±ì´ ìˆëŠ” í‚¤ì›Œë“œëŠ” ì œì™¸í•´ì£¼ì„¸ìš”

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”:

```json
{{
  "add_bait_keywords": ["ìƒˆë¡œì°¾ì€í‚¤ì›Œë“œ1", "ìƒˆë¡œì°¾ì€í‚¤ì›Œë“œ2"],
  "found_bait_options": ["ë†“ì¹œë¯¸ë¼ì˜µì…˜1", "ë†“ì¹œë¯¸ë¼ì˜µì…˜2"],
  "analysis": "ê°„ë‹¨í•œ ë¶„ì„ (2-3ë¬¸ì¥)"
}}
```
"""

    return prompt


def _parse_gemini_response(response_text: str) -> dict:
    """Gemini ì‘ë‹µ íŒŒì‹±"""
    result = {
        'report': response_text,
        'recommendations': {
            'add_bait_keywords': [],
            'remove_bait_keywords': [],
            'add_exception_keywords': [],
            'found_bait_options': [],  # â˜… ë†“ì¹œ ë¯¸ë¼ ì˜µì…˜ë“¤
            'analysis': '',
            'price_threshold_suggestion': None,
        }
    }

    # JSON ë¸”ë¡ ì¶”ì¶œ
    import re
    json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)

    if json_match:
        try:
            json_data = json.loads(json_match.group(1))
            result['recommendations'] = {
                'add_bait_keywords': json_data.get('add_bait_keywords', []),
                'remove_bait_keywords': json_data.get('remove_bait_keywords', []),
                'add_exception_keywords': json_data.get('add_exception_keywords', []),
                'found_bait_options': json_data.get('found_bait_options', []),
                'analysis': json_data.get('analysis', ''),
                'price_threshold_suggestion': json_data.get('price_threshold_suggestion'),
            }
            # ë¦¬í¬íŠ¸ì—ì„œ JSON ë¸”ë¡ ì œê±°
            result['report'] = response_text.replace(json_match.group(0), '').strip()
        except json.JSONDecodeError:
            pass

    return result


def generate_learning_report(analysis_result: dict) -> str:
    """í•™ìŠµ ê²°ê³¼ë¥¼ í•œ í˜ì´ì§€ ë¦¬í¬íŠ¸ë¡œ ìƒì„±"""

    if not analysis_result.get('success'):
        return f"âŒ ë¶„ì„ ì‹¤íŒ¨: {analysis_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"

    stats = analysis_result.get('statistics', {})
    recs = analysis_result.get('recommendations', {})

    report = f"""
{'='*60}
ğŸ”¬ ë¶ˆì‚¬ì ì‹œë®¬ë ˆì´ì…˜ AI ë¶„ì„ ë¦¬í¬íŠ¸
{'='*60}

ğŸ“ˆ ê¸°ë³¸ í†µê³„
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ ë¶„ì„ ìƒí’ˆ ìˆ˜: {stats.get('total_products', 'N/A')}ê°œ
â€¢ ë¯¸ë¼ íƒì§€ ìˆ˜: {stats.get('bait_detected', 'N/A')}ê±´
â€¢ ì˜ì‹¬ ì˜¤íƒ ìˆ˜: {stats.get('false_positive_suspected', 'N/A')}ê±´
â€¢ ì˜ì‹¬ ë¯¸íƒ ìˆ˜: {stats.get('false_negative_suspected', 'N/A')}ê±´

ğŸ¯ í‚¤ì›Œë“œ ê°œì„  ê¶Œì¥ì‚¬í•­
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â–¶ ì¶”ê°€í•  ë¯¸ë¼ í‚¤ì›Œë“œ: {', '.join(recs.get('add_bait_keywords', [])) or 'ì—†ìŒ'}
â–¶ ì œê±°í•  ë¯¸ë¼ í‚¤ì›Œë“œ: {', '.join(recs.get('remove_bait_keywords', [])) or 'ì—†ìŒ'}
â–¶ ì¶”ê°€í•  ì˜ˆì™¸ í‚¤ì›Œë“œ: {', '.join(recs.get('add_exception_keywords', [])) or 'ì—†ìŒ'}
â–¶ ê°€ê²© ê¸°ì¤€ ì œì•ˆ: {recs.get('price_threshold_suggestion') or 'í˜„í–‰ ìœ ì§€'}ìœ„ì•ˆ

ğŸ“ AI ìƒì„¸ ë¶„ì„
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
{analysis_result.get('report', 'ë¶„ì„ ë‚´ìš© ì—†ìŒ')}

{'='*60}
"""
    return report


def apply_learning_recommendations(recommendations: dict, auto_apply: bool = False, log_callback=None) -> dict:
    """
    í•™ìŠµ ê¶Œì¥ì‚¬í•­ì„ í‚¤ì›Œë“œì— ì ìš©

    Args:
        recommendations: analyze_simulation_with_geminiì˜ recommendations
        auto_apply: Trueë©´ ìë™ ì ìš©, Falseë©´ ë³€ê²½ ë‚´ìš©ë§Œ ë°˜í™˜
        log_callback: ë¡œê·¸ ì¶œë ¥ í•¨ìˆ˜

    Returns:
        {
            'changes': {
                'bait_added': [],
                'bait_removed': [],
                'exception_added': [],
            },
            'applied': bool
        }
    """
    result = {
        'changes': {
            'bait_added': [],
            'bait_removed': [],
            'exception_added': [],
        },
        'applied': False
    }

    # í˜„ì¬ í‚¤ì›Œë“œ ë¡œë“œ
    current_bait = load_bait_keywords()
    current_bait_set = set(current_bait)

    # ì¶”ê°€í•  í‚¤ì›Œë“œ
    add_keywords = recommendations.get('add_bait_keywords', [])
    for kw in add_keywords:
        if kw and kw not in current_bait_set:
            result['changes']['bait_added'].append(kw)
            if auto_apply:
                current_bait.append(kw)

    # ì œê±°í•  í‚¤ì›Œë“œ
    remove_keywords = recommendations.get('remove_bait_keywords', [])
    for kw in remove_keywords:
        if kw and kw in current_bait_set:
            result['changes']['bait_removed'].append(kw)
            if auto_apply:
                current_bait.remove(kw)

    # ì˜ˆì™¸ í‚¤ì›Œë“œ ì¶”ê°€ (BAIT_EXCEPTION_KEYWORDSëŠ” ì½”ë“œì— í•˜ë“œì½”ë”©ë˜ì–´ ìˆì–´ì„œ ë¡œê·¸ë§Œ)
    exception_keywords = recommendations.get('add_exception_keywords', [])
    for kw in exception_keywords:
        if kw and kw not in BAIT_EXCEPTION_KEYWORDS:
            result['changes']['exception_added'].append(kw)

    if auto_apply and (result['changes']['bait_added'] or result['changes']['bait_removed']):
        if save_bait_keywords(current_bait):
            result['applied'] = True
            if log_callback:
                log_callback(f"âœ… ë¯¸ë¼ í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                if result['changes']['bait_added']:
                    log_callback(f"   ì¶”ê°€: {result['changes']['bait_added']}")
                if result['changes']['bait_removed']:
                    log_callback(f"   ì œê±°: {result['changes']['bait_removed']}")
        else:
            if log_callback:
                log_callback(f"âŒ ë¯¸ë¼ í‚¤ì›Œë“œ ì €ì¥ ì‹¤íŒ¨")

    if result['changes']['exception_added'] and log_callback:
        log_callback(f"âš ï¸ ì˜ˆì™¸ í‚¤ì›Œë“œëŠ” ì½”ë“œ ìˆ˜ì • í•„ìš”: {result['changes']['exception_added']}")

    return result


# ==================== ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ====================

if __name__ == "__main__":
    # Windows ì½˜ì†” UTF-8 ì¸ì½”ë”© ì„¤ì •
    import sys
    if sys.platform == 'win32':
        sys.stdout.reconfigure(encoding='utf-8')

    print("=" * 50)
    print("ë¶ˆì‚¬ì ê³µí†µ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    # í‚¤ì›Œë“œ ë¡œë“œ í…ŒìŠ¤íŠ¸
    print("\n[í‚¤ì›Œë“œ ë¡œë“œ í…ŒìŠ¤íŠ¸]")
    banned, _ = load_banned_words()
    print(f"  ê¸ˆì§€ë‹¨ì–´: {len(banned)}ê°œ")

    excluded = load_excluded_words()
    print(f"  ì˜ˆì™¸ë‹¨ì–´: {len(excluded)}ê°œ")

    remove = load_remove_words()
    print(f"  ì œê±°ë‹¨ì–´: {len(remove)}ê°œ")

    bait = load_bait_keywords()
    print(f"  ë¯¸ë¼í‚¤ì›Œë“œ: {len(bait)}ê°œ")

    # ìƒí’ˆ ì•ˆì „ ê²€ì‚¬ í…ŒìŠ¤íŠ¸
    print("\n[ìƒí’ˆ ì•ˆì „ ê²€ì‚¬ í…ŒìŠ¤íŠ¸]")
    test_titles = [
        "ê³ ê¸‰ ì‚¬ë¬´ìš© ì˜ì ë©”ì‰¬ ì²´ì–´",
        "ìœ ì•„ìš© ê¸°ì €ê·€ íŒ¬í‹°í˜•",
        "ì„±ì¸ìš©í’ˆ ì§„ë™ê¸°",
        "ì „ë™í‚¥ë³´ë“œ ì ‘ì´ì‹",
    ]
    for title in test_titles:
        result = check_product_safety(title)
        status = "âœ… ì•ˆì „" if result['is_safe'] else f"âš ï¸ ìœ„í—˜: {result['all_found']}"
        print(f"  '{title[:20]}...' â†’ {status}")

    # Gemini API ì—°ê²° í…ŒìŠ¤íŠ¸
    print("\n[Gemini API ì—°ê²° í…ŒìŠ¤íŠ¸]")
    try:
        test_url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent"
        test_payload = {
            'contents': [{'parts': [{'text': 'ì•ˆë…•í•˜ì„¸ìš”. í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.'}]}],
            'generationConfig': {'maxOutputTokens': 50}
        }
        response = requests.post(
            f"{test_url}?key={GEMINI_API_KEY}",
            headers={'Content-Type': 'application/json'},
            json=test_payload,
            timeout=10
        )
        if response.status_code == 200:
            print(f"  âœ… Gemini API ì—°ê²° ì„±ê³µ (ëª¨ë¸: {GEMINI_MODEL})")
        else:
            print(f"  âŒ Gemini API ì˜¤ë¥˜: {response.status_code}")
    except Exception as e:
        print(f"  âŒ Gemini API ì—°ê²° ì‹¤íŒ¨: {e}")

    print("\ní…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
